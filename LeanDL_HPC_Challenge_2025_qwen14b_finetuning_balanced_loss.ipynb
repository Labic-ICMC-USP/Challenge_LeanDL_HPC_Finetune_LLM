{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "f_DAA3Uir37l",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_DAA3Uir37l",
        "outputId": "7af16ae2-c882-475b-a75f-1c6bc70de25a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: codecarbon in /home/rvsantin/miniconda3/envs/challenge_bonito/lib/python3.11/site-packages (3.0.4)\n",
            "Requirement already satisfied: arrow in /home/rvsantin/miniconda3/envs/challenge_bonito/lib/python3.11/site-packages (from codecarbon) (1.3.0)\n",
            "Requirement already satisfied: click in /home/rvsantin/miniconda3/envs/challenge_bonito/lib/python3.11/site-packages (from codecarbon) (8.2.1)\n",
            "Requirement already satisfied: fief-client[cli] in /home/rvsantin/miniconda3/envs/challenge_bonito/lib/python3.11/site-packages (from codecarbon) (0.20.0)\n",
            "Requirement already satisfied: pandas in /home/rvsantin/miniconda3/envs/challenge_bonito/lib/python3.11/site-packages (from codecarbon) (2.2.3)\n",
            "Requirement already satisfied: prometheus_client in /home/rvsantin/miniconda3/envs/challenge_bonito/lib/python3.11/site-packages (from codecarbon) (0.22.1)\n",
            "Requirement already satisfied: psutil>=6.0.0 in /home/rvsantin/miniconda3/envs/challenge_bonito/lib/python3.11/site-packages (from codecarbon) (7.0.0)\n",
            "Requirement already satisfied: py-cpuinfo in /home/rvsantin/miniconda3/envs/challenge_bonito/lib/python3.11/site-packages (from codecarbon) (9.0.0)\n",
            "Requirement already satisfied: pydantic in /home/rvsantin/miniconda3/envs/challenge_bonito/lib/python3.11/site-packages (from codecarbon) (2.11.7)\n",
            "Requirement already satisfied: pynvml in /home/rvsantin/miniconda3/envs/challenge_bonito/lib/python3.11/site-packages (from codecarbon) (12.0.0)\n",
            "Requirement already satisfied: rapidfuzz in /home/rvsantin/miniconda3/envs/challenge_bonito/lib/python3.11/site-packages (from codecarbon) (3.13.0)\n",
            "Requirement already satisfied: requests in /home/rvsantin/miniconda3/envs/challenge_bonito/lib/python3.11/site-packages (from codecarbon) (2.32.4)\n",
            "Requirement already satisfied: questionary in /home/rvsantin/miniconda3/envs/challenge_bonito/lib/python3.11/site-packages (from codecarbon) (2.1.0)\n",
            "Requirement already satisfied: rich in /home/rvsantin/miniconda3/envs/challenge_bonito/lib/python3.11/site-packages (from codecarbon) (14.1.0)\n",
            "Requirement already satisfied: typer in /home/rvsantin/miniconda3/envs/challenge_bonito/lib/python3.11/site-packages (from codecarbon) (0.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.0 in /home/rvsantin/miniconda3/envs/challenge_bonito/lib/python3.11/site-packages (from arrow->codecarbon) (2.9.0.post0)\n",
            "Requirement already satisfied: types-python-dateutil>=2.8.10 in /home/rvsantin/miniconda3/envs/challenge_bonito/lib/python3.11/site-packages (from arrow->codecarbon) (2.9.0.20250809)\n",
            "Requirement already satisfied: six>=1.5 in /home/rvsantin/miniconda3/envs/challenge_bonito/lib/python3.11/site-packages (from python-dateutil>=2.7.0->arrow->codecarbon) (1.17.0)\n",
            "Requirement already satisfied: httpx<0.28.0,>=0.21.3 in /home/rvsantin/miniconda3/envs/challenge_bonito/lib/python3.11/site-packages (from fief-client[cli]->codecarbon) (0.27.2)\n",
            "Requirement already satisfied: jwcrypto<2.0.0,>=1.4 in /home/rvsantin/miniconda3/envs/challenge_bonito/lib/python3.11/site-packages (from fief-client[cli]->codecarbon) (1.5.6)\n",
            "Requirement already satisfied: yaspin in /home/rvsantin/miniconda3/envs/challenge_bonito/lib/python3.11/site-packages (from fief-client[cli]->codecarbon) (3.1.0)\n",
            "Requirement already satisfied: anyio in /home/rvsantin/miniconda3/envs/challenge_bonito/lib/python3.11/site-packages (from httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon) (4.10.0)\n",
            "Requirement already satisfied: certifi in /home/rvsantin/miniconda3/envs/challenge_bonito/lib/python3.11/site-packages (from httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /home/rvsantin/miniconda3/envs/challenge_bonito/lib/python3.11/site-packages (from httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon) (1.0.9)\n",
            "Requirement already satisfied: idna in /home/rvsantin/miniconda3/envs/challenge_bonito/lib/python3.11/site-packages (from httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon) (3.10)\n",
            "Requirement already satisfied: sniffio in /home/rvsantin/miniconda3/envs/challenge_bonito/lib/python3.11/site-packages (from httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon) (1.3.1)\n",
            "Requirement already satisfied: h11>=0.16 in /home/rvsantin/miniconda3/envs/challenge_bonito/lib/python3.11/site-packages (from httpcore==1.*->httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon) (0.16.0)\n",
            "Requirement already satisfied: cryptography>=3.4 in /home/rvsantin/miniconda3/envs/challenge_bonito/lib/python3.11/site-packages (from jwcrypto<2.0.0,>=1.4->fief-client[cli]->codecarbon) (45.0.6)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /home/rvsantin/miniconda3/envs/challenge_bonito/lib/python3.11/site-packages (from jwcrypto<2.0.0,>=1.4->fief-client[cli]->codecarbon) (4.12.2)\n",
            "Requirement already satisfied: cffi>=1.14 in /home/rvsantin/miniconda3/envs/challenge_bonito/lib/python3.11/site-packages (from cryptography>=3.4->jwcrypto<2.0.0,>=1.4->fief-client[cli]->codecarbon) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /home/rvsantin/miniconda3/envs/challenge_bonito/lib/python3.11/site-packages (from cffi>=1.14->cryptography>=3.4->jwcrypto<2.0.0,>=1.4->fief-client[cli]->codecarbon) (2.22)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /home/rvsantin/miniconda3/envs/challenge_bonito/lib/python3.11/site-packages (from pandas->codecarbon) (2.1.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /home/rvsantin/miniconda3/envs/challenge_bonito/lib/python3.11/site-packages (from pandas->codecarbon) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /home/rvsantin/miniconda3/envs/challenge_bonito/lib/python3.11/site-packages (from pandas->codecarbon) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /home/rvsantin/miniconda3/envs/challenge_bonito/lib/python3.11/site-packages (from pydantic->codecarbon) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /home/rvsantin/miniconda3/envs/challenge_bonito/lib/python3.11/site-packages (from pydantic->codecarbon) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /home/rvsantin/miniconda3/envs/challenge_bonito/lib/python3.11/site-packages (from pydantic->codecarbon) (0.4.1)\n",
            "Requirement already satisfied: nvidia-ml-py<13.0.0a0,>=12.0.0 in /home/rvsantin/miniconda3/envs/challenge_bonito/lib/python3.11/site-packages (from pynvml->codecarbon) (12.575.51)\n",
            "Requirement already satisfied: prompt_toolkit<4.0,>=2.0 in /home/rvsantin/miniconda3/envs/challenge_bonito/lib/python3.11/site-packages (from questionary->codecarbon) (3.0.51)\n",
            "Requirement already satisfied: wcwidth in /home/rvsantin/miniconda3/envs/challenge_bonito/lib/python3.11/site-packages (from prompt_toolkit<4.0,>=2.0->questionary->codecarbon) (0.2.13)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /home/rvsantin/miniconda3/envs/challenge_bonito/lib/python3.11/site-packages (from requests->codecarbon) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/rvsantin/miniconda3/envs/challenge_bonito/lib/python3.11/site-packages (from requests->codecarbon) (2.5.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/rvsantin/miniconda3/envs/challenge_bonito/lib/python3.11/site-packages (from rich->codecarbon) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/rvsantin/miniconda3/envs/challenge_bonito/lib/python3.11/site-packages (from rich->codecarbon) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /home/rvsantin/miniconda3/envs/challenge_bonito/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->codecarbon) (0.1.2)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /home/rvsantin/miniconda3/envs/challenge_bonito/lib/python3.11/site-packages (from typer->codecarbon) (1.5.4)\n",
            "Requirement already satisfied: termcolor<2.4.0,>=2.2.0 in /home/rvsantin/miniconda3/envs/challenge_bonito/lib/python3.11/site-packages (from yaspin->fief-client[cli]->codecarbon) (2.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install codecarbon # reiniciar apos instalar este pacote se você estiver em um notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "35e297af",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "from datasets import Dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer, AutoModelForCausalLM,\n",
        "    BitsAndBytesConfig, Trainer, TrainingArguments,\n",
        "    DataCollatorForLanguageModeling, EarlyStoppingCallback,\n",
        "    DataCollatorForSeq2Seq\n",
        ")\n",
        "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
        "\n",
        "from peft import PeftModel\n",
        "import pickle\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "b3edc85d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ------------------\n",
        "# Configurações\n",
        "# ------------------\n",
        "# MODEL_NAME = \"meta-llama/Meta-Llama-3-8B\"\n",
        "MODEL_NAME = 'Qwen/Qwen3-14B-Base'\n",
        "OUTPUT_DIR = \"./qlora-aderencia-classes.balanced\"\n",
        "SEED = 42\n",
        "LABELS = [\"BAIXA\", \"MÉDIA\", \"ALTA\"]\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "torch.utils.checkpoint.use_reentrant = False\n",
        "\n",
        "# ------------------\n",
        "# Prompt\n",
        "# ------------------\n",
        "PROMPT_TMPL = \"\"\"You are a thematic relevance evaluator.\n",
        "Classify how related an academic work (title and abstract) is to a strategic theme.\n",
        "\n",
        "TITLE: {title}\n",
        "KEYWORDS: {keywords}\n",
        "ABSTRACT: {abstract}\n",
        "\n",
        "Answer with a number 0, 1, or 2 for RELEVANCE LEVEL (2-HIGH, 1-MEDIUM, 0-LOW) to the strategic theme: \"{category}\".\n",
        "\n",
        "GENERAL CRITERIA:\n",
        "- HIGH: the topic is central to the research; strong semantic coherence.\n",
        "- MEDIUM: partial/indirect or secondary relation to the topic.\n",
        "- LOW: weak or tangential relation; the topic is not the main focus of the work.\n",
        "\n",
        "ANSWER: \"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "94d7c936",
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(\"my_data.pickle\", \"rb\") as file:\n",
        "    split_train = pickle.load(file)\n",
        "    split_eval = pickle.load(file)\n",
        "    split_test = pickle.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "5980b65d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "33620 4203 4203\n"
          ]
        }
      ],
      "source": [
        "print( len(split_train) , len(split_eval), len(split_test) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "228c00e3",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f603d20a27ec448a8c20be8f636dcf2e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/33620 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1bd619d12dd5425bafe847b369d4d044",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/4203 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "\n",
        "# ------------------\n",
        "# Tokenizer\n",
        "# ------------------\n",
        "tok = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "if tok.pad_token is None:\n",
        "    tok.pad_token = tok.eos_token\n",
        "\n",
        "\n",
        "\n",
        "# ------------------\n",
        "# Função de preprocessamento\n",
        "# ------------------\n",
        "def preprocess(example, max_input_length=1024, max_description=512):\n",
        "    processed_key_words = '\\n- '.join(example[\"descricao_keyword\"].split(';'))\n",
        "    gold = str(example[\"modelo_nivel\"]).strip().upper()\n",
        "    if gold == \"MEDIA\":\n",
        "        gold = \"MÉDIA\"\n",
        "    assert gold in LABELS\n",
        "    gold_idx = LABELS.index(gold)  # 0,1,2\n",
        "\n",
        "    # Cria prompt\n",
        "    prompt = PROMPT_TMPL.format(\n",
        "        title=example[\"nome_producao\"],\n",
        "        abstract=example[\"descricao_abstract\"][:max_description],\n",
        "        keywords=processed_key_words,\n",
        "        category=example[\"tema\"]\n",
        "    )\n",
        "\n",
        "    # Tokeniza prompt\n",
        "    input_enc = tok(prompt, truncation=True, max_length=max_input_length, add_special_tokens=False)\n",
        "    input_ids = input_enc[\"input_ids\"]\n",
        "\n",
        "    # Token do próximo token (classe)\n",
        "    label_id = tok(str(gold_idx), add_special_tokens=False)[\"input_ids\"][0]\n",
        "\n",
        "    if label_id not in [15, 16, 17]:\n",
        "        print( label_id )\n",
        "\n",
        "    # labels: -100 no prompt, token da classe no final\n",
        "    labels = [-100] * len(input_ids) + [label_id]\n",
        "    input_ids_full = input_ids + [label_id]\n",
        "    attention_mask = [1] * len(input_ids_full)\n",
        "    # labels = [label_id]\n",
        "    # attention_mask = [1] * len(input_ids)\n",
        "\n",
        "    if example[\"modelo_nivel\"].replace('E','É') not in LABELS:\n",
        "        print(\"ERRO:\", example[\"modelo_nivel\"], \"->\", gold, \"(\", label_id, \")\")\n",
        "        print(\"PROMPT:\", prompt)\n",
        "        print(\"INPUT_IDS:\", input_ids)\n",
        "        print(\"LABELS:\", labels)\n",
        "        # raise ValueError(\"Label inválida\")\n",
        "\n",
        "    return {\n",
        "        \"input_ids\": input_ids_full,\n",
        "        \"attention_mask\": attention_mask,\n",
        "        \"labels\": labels\n",
        "    }\n",
        "\n",
        "# ------------------\n",
        "# Criação do Dataset\n",
        "# ------------------\n",
        "train_ds = split_train.map(preprocess, batched=False, remove_columns=split_train.column_names)\n",
        "eval_ds = split_eval.map(preprocess, batched=False, remove_columns=split_eval.column_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "a679f402",
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in range(len(train_ds)):\n",
        "    if train_ds['labels'][i][-1] not in [15,16,17]:\n",
        "        print(i)\n",
        "        print(train_ds['labels'][i][-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "10c127a5",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8f59b1a780c346628747134fa20749a0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model loaded in  cuda:0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# ------------------\n",
        "# Modelo base com quantização 4-bit\n",
        "# ------------------\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16 if torch.cuda.is_available() else torch.float32,\n",
        ")\n",
        "\n",
        "raw_model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True,\n",
        "    quantization_config=bnb_config\n",
        ")\n",
        "raw_model = prepare_model_for_kbit_training(raw_model)\n",
        "\n",
        "print( 'Model loaded in ', raw_model.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "9a59f2df",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "model\n",
            "model.embed_tokens\n",
            "model.layers\n",
            "model.layers.0\n",
            "model.layers.0.self_attn\n",
            "model.layers.0.self_attn.q_proj\n",
            "model.layers.0.self_attn.k_proj\n",
            "model.layers.0.self_attn.v_proj\n",
            "model.layers.0.self_attn.o_proj\n",
            "model.layers.0.self_attn.q_norm\n",
            "model.layers.0.self_attn.k_norm\n",
            "model.layers.0.mlp\n",
            "model.layers.0.mlp.gate_proj\n",
            "model.layers.0.mlp.up_proj\n",
            "model.layers.0.mlp.down_proj\n",
            "model.layers.0.mlp.act_fn\n",
            "model.layers.0.input_layernorm\n",
            "model.layers.0.post_attention_layernorm\n",
            "model.layers.1\n",
            "model.layers.1.self_attn\n",
            "model.layers.1.self_attn.q_proj\n",
            "model.layers.1.self_attn.k_proj\n",
            "model.layers.1.self_attn.v_proj\n",
            "model.layers.1.self_attn.o_proj\n",
            "model.layers.1.self_attn.q_norm\n",
            "model.layers.1.self_attn.k_norm\n",
            "model.layers.1.mlp\n",
            "model.layers.1.mlp.gate_proj\n",
            "model.layers.1.mlp.up_proj\n",
            "model.layers.1.mlp.down_proj\n",
            "model.layers.1.mlp.act_fn\n",
            "model.layers.1.input_layernorm\n",
            "model.layers.1.post_attention_layernorm\n",
            "model.layers.2\n",
            "model.layers.2.self_attn\n",
            "model.layers.2.self_attn.q_proj\n",
            "model.layers.2.self_attn.k_proj\n",
            "model.layers.2.self_attn.v_proj\n",
            "model.layers.2.self_attn.o_proj\n",
            "model.layers.2.self_attn.q_norm\n",
            "model.layers.2.self_attn.k_norm\n",
            "model.layers.2.mlp\n",
            "model.layers.2.mlp.gate_proj\n",
            "model.layers.2.mlp.up_proj\n",
            "model.layers.2.mlp.down_proj\n",
            "model.layers.2.mlp.act_fn\n",
            "model.layers.2.input_layernorm\n",
            "model.layers.2.post_attention_layernorm\n",
            "model.layers.3\n",
            "model.layers.3.self_attn\n",
            "model.layers.3.self_attn.q_proj\n",
            "model.layers.3.self_attn.k_proj\n",
            "model.layers.3.self_attn.v_proj\n",
            "model.layers.3.self_attn.o_proj\n",
            "model.layers.3.self_attn.q_norm\n",
            "model.layers.3.self_attn.k_norm\n",
            "model.layers.3.mlp\n",
            "model.layers.3.mlp.gate_proj\n",
            "model.layers.3.mlp.up_proj\n",
            "model.layers.3.mlp.down_proj\n",
            "model.layers.3.mlp.act_fn\n",
            "model.layers.3.input_layernorm\n",
            "model.layers.3.post_attention_layernorm\n",
            "model.layers.4\n",
            "model.layers.4.self_attn\n",
            "model.layers.4.self_attn.q_proj\n",
            "model.layers.4.self_attn.k_proj\n",
            "model.layers.4.self_attn.v_proj\n",
            "model.layers.4.self_attn.o_proj\n",
            "model.layers.4.self_attn.q_norm\n",
            "model.layers.4.self_attn.k_norm\n",
            "model.layers.4.mlp\n",
            "model.layers.4.mlp.gate_proj\n",
            "model.layers.4.mlp.up_proj\n",
            "model.layers.4.mlp.down_proj\n",
            "model.layers.4.mlp.act_fn\n",
            "model.layers.4.input_layernorm\n",
            "model.layers.4.post_attention_layernorm\n",
            "model.layers.5\n",
            "model.layers.5.self_attn\n",
            "model.layers.5.self_attn.q_proj\n",
            "model.layers.5.self_attn.k_proj\n",
            "model.layers.5.self_attn.v_proj\n",
            "model.layers.5.self_attn.o_proj\n",
            "model.layers.5.self_attn.q_norm\n",
            "model.layers.5.self_attn.k_norm\n",
            "model.layers.5.mlp\n",
            "model.layers.5.mlp.gate_proj\n",
            "model.layers.5.mlp.up_proj\n",
            "model.layers.5.mlp.down_proj\n",
            "model.layers.5.mlp.act_fn\n",
            "model.layers.5.input_layernorm\n",
            "model.layers.5.post_attention_layernorm\n",
            "model.layers.6\n",
            "model.layers.6.self_attn\n",
            "model.layers.6.self_attn.q_proj\n",
            "model.layers.6.self_attn.k_proj\n",
            "model.layers.6.self_attn.v_proj\n",
            "model.layers.6.self_attn.o_proj\n",
            "model.layers.6.self_attn.q_norm\n",
            "model.layers.6.self_attn.k_norm\n",
            "model.layers.6.mlp\n",
            "model.layers.6.mlp.gate_proj\n",
            "model.layers.6.mlp.up_proj\n",
            "model.layers.6.mlp.down_proj\n",
            "model.layers.6.mlp.act_fn\n",
            "model.layers.6.input_layernorm\n",
            "model.layers.6.post_attention_layernorm\n",
            "model.layers.7\n",
            "model.layers.7.self_attn\n",
            "model.layers.7.self_attn.q_proj\n",
            "model.layers.7.self_attn.k_proj\n",
            "model.layers.7.self_attn.v_proj\n",
            "model.layers.7.self_attn.o_proj\n",
            "model.layers.7.self_attn.q_norm\n",
            "model.layers.7.self_attn.k_norm\n",
            "model.layers.7.mlp\n",
            "model.layers.7.mlp.gate_proj\n",
            "model.layers.7.mlp.up_proj\n",
            "model.layers.7.mlp.down_proj\n",
            "model.layers.7.mlp.act_fn\n",
            "model.layers.7.input_layernorm\n",
            "model.layers.7.post_attention_layernorm\n",
            "model.layers.8\n",
            "model.layers.8.self_attn\n",
            "model.layers.8.self_attn.q_proj\n",
            "model.layers.8.self_attn.k_proj\n",
            "model.layers.8.self_attn.v_proj\n",
            "model.layers.8.self_attn.o_proj\n",
            "model.layers.8.self_attn.q_norm\n",
            "model.layers.8.self_attn.k_norm\n",
            "model.layers.8.mlp\n",
            "model.layers.8.mlp.gate_proj\n",
            "model.layers.8.mlp.up_proj\n",
            "model.layers.8.mlp.down_proj\n",
            "model.layers.8.mlp.act_fn\n",
            "model.layers.8.input_layernorm\n",
            "model.layers.8.post_attention_layernorm\n",
            "model.layers.9\n",
            "model.layers.9.self_attn\n",
            "model.layers.9.self_attn.q_proj\n",
            "model.layers.9.self_attn.k_proj\n",
            "model.layers.9.self_attn.v_proj\n",
            "model.layers.9.self_attn.o_proj\n",
            "model.layers.9.self_attn.q_norm\n",
            "model.layers.9.self_attn.k_norm\n",
            "model.layers.9.mlp\n",
            "model.layers.9.mlp.gate_proj\n",
            "model.layers.9.mlp.up_proj\n",
            "model.layers.9.mlp.down_proj\n",
            "model.layers.9.mlp.act_fn\n",
            "model.layers.9.input_layernorm\n",
            "model.layers.9.post_attention_layernorm\n",
            "model.layers.10\n",
            "model.layers.10.self_attn\n",
            "model.layers.10.self_attn.q_proj\n",
            "model.layers.10.self_attn.k_proj\n",
            "model.layers.10.self_attn.v_proj\n",
            "model.layers.10.self_attn.o_proj\n",
            "model.layers.10.self_attn.q_norm\n",
            "model.layers.10.self_attn.k_norm\n",
            "model.layers.10.mlp\n",
            "model.layers.10.mlp.gate_proj\n",
            "model.layers.10.mlp.up_proj\n",
            "model.layers.10.mlp.down_proj\n",
            "model.layers.10.mlp.act_fn\n",
            "model.layers.10.input_layernorm\n",
            "model.layers.10.post_attention_layernorm\n",
            "model.layers.11\n",
            "model.layers.11.self_attn\n",
            "model.layers.11.self_attn.q_proj\n",
            "model.layers.11.self_attn.k_proj\n",
            "model.layers.11.self_attn.v_proj\n",
            "model.layers.11.self_attn.o_proj\n",
            "model.layers.11.self_attn.q_norm\n",
            "model.layers.11.self_attn.k_norm\n",
            "model.layers.11.mlp\n",
            "model.layers.11.mlp.gate_proj\n",
            "model.layers.11.mlp.up_proj\n",
            "model.layers.11.mlp.down_proj\n",
            "model.layers.11.mlp.act_fn\n",
            "model.layers.11.input_layernorm\n",
            "model.layers.11.post_attention_layernorm\n",
            "model.layers.12\n",
            "model.layers.12.self_attn\n",
            "model.layers.12.self_attn.q_proj\n",
            "model.layers.12.self_attn.k_proj\n",
            "model.layers.12.self_attn.v_proj\n",
            "model.layers.12.self_attn.o_proj\n",
            "model.layers.12.self_attn.q_norm\n",
            "model.layers.12.self_attn.k_norm\n",
            "model.layers.12.mlp\n",
            "model.layers.12.mlp.gate_proj\n",
            "model.layers.12.mlp.up_proj\n",
            "model.layers.12.mlp.down_proj\n",
            "model.layers.12.mlp.act_fn\n",
            "model.layers.12.input_layernorm\n",
            "model.layers.12.post_attention_layernorm\n",
            "model.layers.13\n",
            "model.layers.13.self_attn\n",
            "model.layers.13.self_attn.q_proj\n",
            "model.layers.13.self_attn.k_proj\n",
            "model.layers.13.self_attn.v_proj\n",
            "model.layers.13.self_attn.o_proj\n",
            "model.layers.13.self_attn.q_norm\n",
            "model.layers.13.self_attn.k_norm\n",
            "model.layers.13.mlp\n",
            "model.layers.13.mlp.gate_proj\n",
            "model.layers.13.mlp.up_proj\n",
            "model.layers.13.mlp.down_proj\n",
            "model.layers.13.mlp.act_fn\n",
            "model.layers.13.input_layernorm\n",
            "model.layers.13.post_attention_layernorm\n",
            "model.layers.14\n",
            "model.layers.14.self_attn\n",
            "model.layers.14.self_attn.q_proj\n",
            "model.layers.14.self_attn.k_proj\n",
            "model.layers.14.self_attn.v_proj\n",
            "model.layers.14.self_attn.o_proj\n",
            "model.layers.14.self_attn.q_norm\n",
            "model.layers.14.self_attn.k_norm\n",
            "model.layers.14.mlp\n",
            "model.layers.14.mlp.gate_proj\n",
            "model.layers.14.mlp.up_proj\n",
            "model.layers.14.mlp.down_proj\n",
            "model.layers.14.mlp.act_fn\n",
            "model.layers.14.input_layernorm\n",
            "model.layers.14.post_attention_layernorm\n",
            "model.layers.15\n",
            "model.layers.15.self_attn\n",
            "model.layers.15.self_attn.q_proj\n",
            "model.layers.15.self_attn.k_proj\n",
            "model.layers.15.self_attn.v_proj\n",
            "model.layers.15.self_attn.o_proj\n",
            "model.layers.15.self_attn.q_norm\n",
            "model.layers.15.self_attn.k_norm\n",
            "model.layers.15.mlp\n",
            "model.layers.15.mlp.gate_proj\n",
            "model.layers.15.mlp.up_proj\n",
            "model.layers.15.mlp.down_proj\n",
            "model.layers.15.mlp.act_fn\n",
            "model.layers.15.input_layernorm\n",
            "model.layers.15.post_attention_layernorm\n",
            "model.layers.16\n",
            "model.layers.16.self_attn\n",
            "model.layers.16.self_attn.q_proj\n",
            "model.layers.16.self_attn.k_proj\n",
            "model.layers.16.self_attn.v_proj\n",
            "model.layers.16.self_attn.o_proj\n",
            "model.layers.16.self_attn.q_norm\n",
            "model.layers.16.self_attn.k_norm\n",
            "model.layers.16.mlp\n",
            "model.layers.16.mlp.gate_proj\n",
            "model.layers.16.mlp.up_proj\n",
            "model.layers.16.mlp.down_proj\n",
            "model.layers.16.mlp.act_fn\n",
            "model.layers.16.input_layernorm\n",
            "model.layers.16.post_attention_layernorm\n",
            "model.layers.17\n",
            "model.layers.17.self_attn\n",
            "model.layers.17.self_attn.q_proj\n",
            "model.layers.17.self_attn.k_proj\n",
            "model.layers.17.self_attn.v_proj\n",
            "model.layers.17.self_attn.o_proj\n",
            "model.layers.17.self_attn.q_norm\n",
            "model.layers.17.self_attn.k_norm\n",
            "model.layers.17.mlp\n",
            "model.layers.17.mlp.gate_proj\n",
            "model.layers.17.mlp.up_proj\n",
            "model.layers.17.mlp.down_proj\n",
            "model.layers.17.mlp.act_fn\n",
            "model.layers.17.input_layernorm\n",
            "model.layers.17.post_attention_layernorm\n",
            "model.layers.18\n",
            "model.layers.18.self_attn\n",
            "model.layers.18.self_attn.q_proj\n",
            "model.layers.18.self_attn.k_proj\n",
            "model.layers.18.self_attn.v_proj\n",
            "model.layers.18.self_attn.o_proj\n",
            "model.layers.18.self_attn.q_norm\n",
            "model.layers.18.self_attn.k_norm\n",
            "model.layers.18.mlp\n",
            "model.layers.18.mlp.gate_proj\n",
            "model.layers.18.mlp.up_proj\n",
            "model.layers.18.mlp.down_proj\n",
            "model.layers.18.mlp.act_fn\n",
            "model.layers.18.input_layernorm\n",
            "model.layers.18.post_attention_layernorm\n",
            "model.layers.19\n",
            "model.layers.19.self_attn\n",
            "model.layers.19.self_attn.q_proj\n",
            "model.layers.19.self_attn.k_proj\n",
            "model.layers.19.self_attn.v_proj\n",
            "model.layers.19.self_attn.o_proj\n",
            "model.layers.19.self_attn.q_norm\n",
            "model.layers.19.self_attn.k_norm\n",
            "model.layers.19.mlp\n",
            "model.layers.19.mlp.gate_proj\n",
            "model.layers.19.mlp.up_proj\n",
            "model.layers.19.mlp.down_proj\n",
            "model.layers.19.mlp.act_fn\n",
            "model.layers.19.input_layernorm\n",
            "model.layers.19.post_attention_layernorm\n",
            "model.layers.20\n",
            "model.layers.20.self_attn\n",
            "model.layers.20.self_attn.q_proj\n",
            "model.layers.20.self_attn.k_proj\n",
            "model.layers.20.self_attn.v_proj\n",
            "model.layers.20.self_attn.o_proj\n",
            "model.layers.20.self_attn.q_norm\n",
            "model.layers.20.self_attn.k_norm\n",
            "model.layers.20.mlp\n",
            "model.layers.20.mlp.gate_proj\n",
            "model.layers.20.mlp.up_proj\n",
            "model.layers.20.mlp.down_proj\n",
            "model.layers.20.mlp.act_fn\n",
            "model.layers.20.input_layernorm\n",
            "model.layers.20.post_attention_layernorm\n",
            "model.layers.21\n",
            "model.layers.21.self_attn\n",
            "model.layers.21.self_attn.q_proj\n",
            "model.layers.21.self_attn.k_proj\n",
            "model.layers.21.self_attn.v_proj\n",
            "model.layers.21.self_attn.o_proj\n",
            "model.layers.21.self_attn.q_norm\n",
            "model.layers.21.self_attn.k_norm\n",
            "model.layers.21.mlp\n",
            "model.layers.21.mlp.gate_proj\n",
            "model.layers.21.mlp.up_proj\n",
            "model.layers.21.mlp.down_proj\n",
            "model.layers.21.mlp.act_fn\n",
            "model.layers.21.input_layernorm\n",
            "model.layers.21.post_attention_layernorm\n",
            "model.layers.22\n",
            "model.layers.22.self_attn\n",
            "model.layers.22.self_attn.q_proj\n",
            "model.layers.22.self_attn.k_proj\n",
            "model.layers.22.self_attn.v_proj\n",
            "model.layers.22.self_attn.o_proj\n",
            "model.layers.22.self_attn.q_norm\n",
            "model.layers.22.self_attn.k_norm\n",
            "model.layers.22.mlp\n",
            "model.layers.22.mlp.gate_proj\n",
            "model.layers.22.mlp.up_proj\n",
            "model.layers.22.mlp.down_proj\n",
            "model.layers.22.mlp.act_fn\n",
            "model.layers.22.input_layernorm\n",
            "model.layers.22.post_attention_layernorm\n",
            "model.layers.23\n",
            "model.layers.23.self_attn\n",
            "model.layers.23.self_attn.q_proj\n",
            "model.layers.23.self_attn.k_proj\n",
            "model.layers.23.self_attn.v_proj\n",
            "model.layers.23.self_attn.o_proj\n",
            "model.layers.23.self_attn.q_norm\n",
            "model.layers.23.self_attn.k_norm\n",
            "model.layers.23.mlp\n",
            "model.layers.23.mlp.gate_proj\n",
            "model.layers.23.mlp.up_proj\n",
            "model.layers.23.mlp.down_proj\n",
            "model.layers.23.mlp.act_fn\n",
            "model.layers.23.input_layernorm\n",
            "model.layers.23.post_attention_layernorm\n",
            "model.layers.24\n",
            "model.layers.24.self_attn\n",
            "model.layers.24.self_attn.q_proj\n",
            "model.layers.24.self_attn.k_proj\n",
            "model.layers.24.self_attn.v_proj\n",
            "model.layers.24.self_attn.o_proj\n",
            "model.layers.24.self_attn.q_norm\n",
            "model.layers.24.self_attn.k_norm\n",
            "model.layers.24.mlp\n",
            "model.layers.24.mlp.gate_proj\n",
            "model.layers.24.mlp.up_proj\n",
            "model.layers.24.mlp.down_proj\n",
            "model.layers.24.mlp.act_fn\n",
            "model.layers.24.input_layernorm\n",
            "model.layers.24.post_attention_layernorm\n",
            "model.layers.25\n",
            "model.layers.25.self_attn\n",
            "model.layers.25.self_attn.q_proj\n",
            "model.layers.25.self_attn.k_proj\n",
            "model.layers.25.self_attn.v_proj\n",
            "model.layers.25.self_attn.o_proj\n",
            "model.layers.25.self_attn.q_norm\n",
            "model.layers.25.self_attn.k_norm\n",
            "model.layers.25.mlp\n",
            "model.layers.25.mlp.gate_proj\n",
            "model.layers.25.mlp.up_proj\n",
            "model.layers.25.mlp.down_proj\n",
            "model.layers.25.mlp.act_fn\n",
            "model.layers.25.input_layernorm\n",
            "model.layers.25.post_attention_layernorm\n",
            "model.layers.26\n",
            "model.layers.26.self_attn\n",
            "model.layers.26.self_attn.q_proj\n",
            "model.layers.26.self_attn.k_proj\n",
            "model.layers.26.self_attn.v_proj\n",
            "model.layers.26.self_attn.o_proj\n",
            "model.layers.26.self_attn.q_norm\n",
            "model.layers.26.self_attn.k_norm\n",
            "model.layers.26.mlp\n",
            "model.layers.26.mlp.gate_proj\n",
            "model.layers.26.mlp.up_proj\n",
            "model.layers.26.mlp.down_proj\n",
            "model.layers.26.mlp.act_fn\n",
            "model.layers.26.input_layernorm\n",
            "model.layers.26.post_attention_layernorm\n",
            "model.layers.27\n",
            "model.layers.27.self_attn\n",
            "model.layers.27.self_attn.q_proj\n",
            "model.layers.27.self_attn.k_proj\n",
            "model.layers.27.self_attn.v_proj\n",
            "model.layers.27.self_attn.o_proj\n",
            "model.layers.27.self_attn.q_norm\n",
            "model.layers.27.self_attn.k_norm\n",
            "model.layers.27.mlp\n",
            "model.layers.27.mlp.gate_proj\n",
            "model.layers.27.mlp.up_proj\n",
            "model.layers.27.mlp.down_proj\n",
            "model.layers.27.mlp.act_fn\n",
            "model.layers.27.input_layernorm\n",
            "model.layers.27.post_attention_layernorm\n",
            "model.layers.28\n",
            "model.layers.28.self_attn\n",
            "model.layers.28.self_attn.q_proj\n",
            "model.layers.28.self_attn.k_proj\n",
            "model.layers.28.self_attn.v_proj\n",
            "model.layers.28.self_attn.o_proj\n",
            "model.layers.28.self_attn.q_norm\n",
            "model.layers.28.self_attn.k_norm\n",
            "model.layers.28.mlp\n",
            "model.layers.28.mlp.gate_proj\n",
            "model.layers.28.mlp.up_proj\n",
            "model.layers.28.mlp.down_proj\n",
            "model.layers.28.mlp.act_fn\n",
            "model.layers.28.input_layernorm\n",
            "model.layers.28.post_attention_layernorm\n",
            "model.layers.29\n",
            "model.layers.29.self_attn\n",
            "model.layers.29.self_attn.q_proj\n",
            "model.layers.29.self_attn.k_proj\n",
            "model.layers.29.self_attn.v_proj\n",
            "model.layers.29.self_attn.o_proj\n",
            "model.layers.29.self_attn.q_norm\n",
            "model.layers.29.self_attn.k_norm\n",
            "model.layers.29.mlp\n",
            "model.layers.29.mlp.gate_proj\n",
            "model.layers.29.mlp.up_proj\n",
            "model.layers.29.mlp.down_proj\n",
            "model.layers.29.mlp.act_fn\n",
            "model.layers.29.input_layernorm\n",
            "model.layers.29.post_attention_layernorm\n",
            "model.layers.30\n",
            "model.layers.30.self_attn\n",
            "model.layers.30.self_attn.q_proj\n",
            "model.layers.30.self_attn.k_proj\n",
            "model.layers.30.self_attn.v_proj\n",
            "model.layers.30.self_attn.o_proj\n",
            "model.layers.30.self_attn.q_norm\n",
            "model.layers.30.self_attn.k_norm\n",
            "model.layers.30.mlp\n",
            "model.layers.30.mlp.gate_proj\n",
            "model.layers.30.mlp.up_proj\n",
            "model.layers.30.mlp.down_proj\n",
            "model.layers.30.mlp.act_fn\n",
            "model.layers.30.input_layernorm\n",
            "model.layers.30.post_attention_layernorm\n",
            "model.layers.31\n",
            "model.layers.31.self_attn\n",
            "model.layers.31.self_attn.q_proj\n",
            "model.layers.31.self_attn.k_proj\n",
            "model.layers.31.self_attn.v_proj\n",
            "model.layers.31.self_attn.o_proj\n",
            "model.layers.31.self_attn.q_norm\n",
            "model.layers.31.self_attn.k_norm\n",
            "model.layers.31.mlp\n",
            "model.layers.31.mlp.gate_proj\n",
            "model.layers.31.mlp.up_proj\n",
            "model.layers.31.mlp.down_proj\n",
            "model.layers.31.mlp.act_fn\n",
            "model.layers.31.input_layernorm\n",
            "model.layers.31.post_attention_layernorm\n",
            "model.layers.32\n",
            "model.layers.32.self_attn\n",
            "model.layers.32.self_attn.q_proj\n",
            "model.layers.32.self_attn.k_proj\n",
            "model.layers.32.self_attn.v_proj\n",
            "model.layers.32.self_attn.o_proj\n",
            "model.layers.32.self_attn.q_norm\n",
            "model.layers.32.self_attn.k_norm\n",
            "model.layers.32.mlp\n",
            "model.layers.32.mlp.gate_proj\n",
            "model.layers.32.mlp.up_proj\n",
            "model.layers.32.mlp.down_proj\n",
            "model.layers.32.mlp.act_fn\n",
            "model.layers.32.input_layernorm\n",
            "model.layers.32.post_attention_layernorm\n",
            "model.layers.33\n",
            "model.layers.33.self_attn\n",
            "model.layers.33.self_attn.q_proj\n",
            "model.layers.33.self_attn.k_proj\n",
            "model.layers.33.self_attn.v_proj\n",
            "model.layers.33.self_attn.o_proj\n",
            "model.layers.33.self_attn.q_norm\n",
            "model.layers.33.self_attn.k_norm\n",
            "model.layers.33.mlp\n",
            "model.layers.33.mlp.gate_proj\n",
            "model.layers.33.mlp.up_proj\n",
            "model.layers.33.mlp.down_proj\n",
            "model.layers.33.mlp.act_fn\n",
            "model.layers.33.input_layernorm\n",
            "model.layers.33.post_attention_layernorm\n",
            "model.layers.34\n",
            "model.layers.34.self_attn\n",
            "model.layers.34.self_attn.q_proj\n",
            "model.layers.34.self_attn.k_proj\n",
            "model.layers.34.self_attn.v_proj\n",
            "model.layers.34.self_attn.o_proj\n",
            "model.layers.34.self_attn.q_norm\n",
            "model.layers.34.self_attn.k_norm\n",
            "model.layers.34.mlp\n",
            "model.layers.34.mlp.gate_proj\n",
            "model.layers.34.mlp.up_proj\n",
            "model.layers.34.mlp.down_proj\n",
            "model.layers.34.mlp.act_fn\n",
            "model.layers.34.input_layernorm\n",
            "model.layers.34.post_attention_layernorm\n",
            "model.layers.35\n",
            "model.layers.35.self_attn\n",
            "model.layers.35.self_attn.q_proj\n",
            "model.layers.35.self_attn.k_proj\n",
            "model.layers.35.self_attn.v_proj\n",
            "model.layers.35.self_attn.o_proj\n",
            "model.layers.35.self_attn.q_norm\n",
            "model.layers.35.self_attn.k_norm\n",
            "model.layers.35.mlp\n",
            "model.layers.35.mlp.gate_proj\n",
            "model.layers.35.mlp.up_proj\n",
            "model.layers.35.mlp.down_proj\n",
            "model.layers.35.mlp.act_fn\n",
            "model.layers.35.input_layernorm\n",
            "model.layers.35.post_attention_layernorm\n",
            "model.layers.36\n",
            "model.layers.36.self_attn\n",
            "model.layers.36.self_attn.q_proj\n",
            "model.layers.36.self_attn.k_proj\n",
            "model.layers.36.self_attn.v_proj\n",
            "model.layers.36.self_attn.o_proj\n",
            "model.layers.36.self_attn.q_norm\n",
            "model.layers.36.self_attn.k_norm\n",
            "model.layers.36.mlp\n",
            "model.layers.36.mlp.gate_proj\n",
            "model.layers.36.mlp.up_proj\n",
            "model.layers.36.mlp.down_proj\n",
            "model.layers.36.mlp.act_fn\n",
            "model.layers.36.input_layernorm\n",
            "model.layers.36.post_attention_layernorm\n",
            "model.layers.37\n",
            "model.layers.37.self_attn\n",
            "model.layers.37.self_attn.q_proj\n",
            "model.layers.37.self_attn.k_proj\n",
            "model.layers.37.self_attn.v_proj\n",
            "model.layers.37.self_attn.o_proj\n",
            "model.layers.37.self_attn.q_norm\n",
            "model.layers.37.self_attn.k_norm\n",
            "model.layers.37.mlp\n",
            "model.layers.37.mlp.gate_proj\n",
            "model.layers.37.mlp.up_proj\n",
            "model.layers.37.mlp.down_proj\n",
            "model.layers.37.mlp.act_fn\n",
            "model.layers.37.input_layernorm\n",
            "model.layers.37.post_attention_layernorm\n",
            "model.layers.38\n",
            "model.layers.38.self_attn\n",
            "model.layers.38.self_attn.q_proj\n",
            "model.layers.38.self_attn.k_proj\n",
            "model.layers.38.self_attn.v_proj\n",
            "model.layers.38.self_attn.o_proj\n",
            "model.layers.38.self_attn.q_norm\n",
            "model.layers.38.self_attn.k_norm\n",
            "model.layers.38.mlp\n",
            "model.layers.38.mlp.gate_proj\n",
            "model.layers.38.mlp.up_proj\n",
            "model.layers.38.mlp.down_proj\n",
            "model.layers.38.mlp.act_fn\n",
            "model.layers.38.input_layernorm\n",
            "model.layers.38.post_attention_layernorm\n",
            "model.layers.39\n",
            "model.layers.39.self_attn\n",
            "model.layers.39.self_attn.q_proj\n",
            "model.layers.39.self_attn.k_proj\n",
            "model.layers.39.self_attn.v_proj\n",
            "model.layers.39.self_attn.o_proj\n",
            "model.layers.39.self_attn.q_norm\n",
            "model.layers.39.self_attn.k_norm\n",
            "model.layers.39.mlp\n",
            "model.layers.39.mlp.gate_proj\n",
            "model.layers.39.mlp.up_proj\n",
            "model.layers.39.mlp.down_proj\n",
            "model.layers.39.mlp.act_fn\n",
            "model.layers.39.input_layernorm\n",
            "model.layers.39.post_attention_layernorm\n",
            "model.norm\n",
            "model.rotary_emb\n",
            "lm_head\n"
          ]
        }
      ],
      "source": [
        "for name, module in raw_model.named_modules():\n",
        "    print(name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "807d3e18",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['model.layers.36.self_attn.q_proj', 'model.layers.36.self_attn.k_proj', 'model.layers.36.self_attn.v_proj', 'model.layers.36.self_attn.o_proj', 'model.layers.36.mlp.up_proj', 'model.layers.36.mlp.down_proj', 'model.layers.37.self_attn.q_proj', 'model.layers.37.self_attn.k_proj', 'model.layers.37.self_attn.v_proj', 'model.layers.37.self_attn.o_proj', 'model.layers.37.mlp.up_proj', 'model.layers.37.mlp.down_proj', 'model.layers.38.self_attn.q_proj', 'model.layers.38.self_attn.k_proj', 'model.layers.38.self_attn.v_proj', 'model.layers.38.self_attn.o_proj', 'model.layers.38.mlp.up_proj', 'model.layers.38.mlp.down_proj', 'model.layers.39.self_attn.q_proj', 'model.layers.39.self_attn.k_proj', 'model.layers.39.self_attn.v_proj', 'model.layers.39.self_attn.o_proj', 'model.layers.39.mlp.up_proj', 'model.layers.39.mlp.down_proj']\n"
          ]
        }
      ],
      "source": [
        "# ------------------\n",
        "# LoRA\n",
        "# ------------------\n",
        "\n",
        "# pegar nomes das últimas camadas\n",
        "n_last = 4\n",
        "num_total_layers = len(raw_model.model.layers)\n",
        "target_modules = []\n",
        "for i in range(num_total_layers - n_last, num_total_layers):\n",
        "    for proj in [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"]:\n",
        "        target_modules.append(f\"model.layers.{i}.self_attn.{proj}\")\n",
        "    for proj in [\"up_proj\", \"down_proj\"]:  # se quiser também adaptar o MLP\n",
        "        target_modules.append(f\"model.layers.{i}.mlp.{proj}\")\n",
        "print( target_modules )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "77e86f99",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "lora_config = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=16,\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        "    target_modules=target_modules\n",
        ")\n",
        "model = get_peft_model(raw_model, lora_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "c1e9467b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dispositivo: NVIDIA RTX A5000\n",
            "Suporta bf16? True\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(\"Dispositivo:\", torch.cuda.get_device_name(0))\n",
        "    print(\"Suporta bf16?\", torch.cuda.is_bf16_supported())\n",
        "else:\n",
        "    print(\"Nenhuma GPU disponível\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "eeed91c8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MEDIA: 10369\n",
            "BAIXA: 16091\n",
            "ALTA: 7160\n",
            "Contagem de rótulos: [16091, 10369, 7160]\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "\n",
        "# pega todos os rótulos\n",
        "labels = split_train[\"modelo_nivel\"]\n",
        "\n",
        "# conta quantos de cada\n",
        "contagem = Counter(labels)\n",
        "\n",
        "# imprime\n",
        "for k, v in contagem.items():\n",
        "    print(f\"{k}: {v}\")\n",
        "\n",
        "class_counts = [contagem[x.replace('É','E')] for x in LABELS]\n",
        "print(\"Contagem de rótulos:\", class_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "8dfafbd4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# IDs dos tokens \"0\",\"1\",\"2\"\n",
        "id_0 = tok(\"0\", add_special_tokens=False).input_ids[0]\n",
        "id_1 = tok(\"1\", add_special_tokens=False).input_ids[0]\n",
        "id_2 = tok(\"2\", add_special_tokens=False).input_ids[0]\n",
        "\n",
        "vocab_size = model.config.vocab_size\n",
        "weights = torch.zeros(vocab_size, device=model.device)\n",
        "\n",
        "# inverso da frequência (ajustado para só 3 classes)\n",
        "class_counts = torch.tensor(class_counts, dtype=torch.float, device=model.device)\n",
        "class_weights = 1.0 / class_counts\n",
        "class_weights = class_weights / class_weights.sum() * len(class_counts)\n",
        "\n",
        "# coloca nos índices corretos do vocab\n",
        "weights[id_0] = class_weights[0]\n",
        "weights[id_1] = class_weights[1]\n",
        "weights[id_2] = class_weights[2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "ebef6d01",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_1823863/2806503771.py:101: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = WeightedTrainer(\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n",
            "/home/rvsantin/miniconda3/envs/challenge_bonito/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='6726' max='11210' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 6726/11210 49:09:46 < 32:47:06, 0.04 it/s, Epoch 6/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>8.097600</td>\n",
              "      <td>0.872778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>8.943300</td>\n",
              "      <td>0.874344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>7.916100</td>\n",
              "      <td>0.799221</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>7.813300</td>\n",
              "      <td>0.791155</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>7.053200</td>\n",
              "      <td>0.816951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>6.547400</td>\n",
              "      <td>0.815776</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/rvsantin/miniconda3/envs/challenge_bonito/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/home/rvsantin/miniconda3/envs/challenge_bonito/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/home/rvsantin/miniconda3/envs/challenge_bonito/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/home/rvsantin/miniconda3/envs/challenge_bonito/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/home/rvsantin/miniconda3/envs/challenge_bonito/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Tempo total de execução: 177013.12 segundos\n",
            "Treino finalizado. Modelo salvo em ./qlora-aderencia-classes.balanced\n"
          ]
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "from typing import Any, Optional, Union\n",
        "\n",
        "# Supondo que você já tenha contado os exemplos por classe\n",
        "# class_counts = [100, 300, 50]  # Exemplo para 3 classes\n",
        "# class_weights = [1.0 / c for c in class_counts]  # inversamente proporcional à frequência\n",
        "# class_weights = torch.tensor(class_weights, dtype=torch.float).to(\"cuda\")\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss(weight=weights)\n",
        "\n",
        "\n",
        "class WeightedTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False,\n",
        "        num_items_in_batch: Optional[torch.Tensor] = None):\n",
        "        labels = inputs.get(\"labels\")\n",
        "\n",
        "        # print(inputs)\n",
        "        \n",
        "        # Forward normal\n",
        "        outputs = model(input_ids=inputs['input_ids'], attention_mask=inputs['attention_mask'])\n",
        "        logits = outputs.get(\"logits\")\n",
        "\n",
        "        # Índice do último token válido em cada exemplo\n",
        "        last_idx = inputs['attention_mask'].sum(dim=1) - 1 # [batch_size]\n",
        "\n",
        "        # Logits do último token\n",
        "        batch_size = logits.size(0)\n",
        "        last_logits = logits[torch.arange(batch_size), last_idx-1, :]  # [batch_size, vocab_size]\n",
        "\n",
        "        # print( 'input ids shape', inputs['input_ids'].shape)\n",
        "        # print( 'batch size', batch_size)\n",
        "        # print( 'last idx', last_idx)\n",
        "\n",
        "        # Labels do último token\n",
        "        last_labels = labels[torch.arange(batch_size), last_idx]     # [batch_size]\n",
        "\n",
        "\n",
        "\n",
        "        # print( last_logits.shape )\n",
        "        # pred_ids = torch.argmax(last_logits, dim=-1)  # shape: [batch_size]\n",
        "\n",
        "        # # converte os IDs de volta para strings\n",
        "        # pred_tokens = [tok.decode([i]) for i in pred_ids]\n",
        "        # print( 'previstos', pred_ids, pred_tokens )\n",
        "        # print( 'reais', last_labels )\n",
        "\n",
        "        # decoded_texts = []\n",
        "        # input_ids = inputs['input_ids']\n",
        "        # for i in range(input_ids.size(0)):\n",
        "        #     # pega do início até last_idx[i] (inclusive)\n",
        "        #     tokens = input_ids[i, : last_idx[i]]  # +1 porque slice é exclusive\n",
        "        #     decoded = tok.decode(tokens)\n",
        "        #     decoded_texts.append(decoded)\n",
        "\n",
        "        # # printar\n",
        "        # for i, text in enumerate(decoded_texts):\n",
        "        #     print(f\"Exemplo {i}: {text}\")\n",
        "\n",
        "\n",
        "        # Calcula a loss\n",
        "        loss = loss_fn(last_logits, last_labels)\n",
        "\n",
        "\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "    \n",
        "def train_all():\n",
        "\n",
        "    # ------------------\n",
        "    # Data collator para Causal LM\n",
        "    # ------------------\n",
        "    collator = DataCollatorForSeq2Seq(tokenizer=tok, padding=True)\n",
        "\n",
        "    # ------------------\n",
        "    # TrainingArguments\n",
        "    # ------------------\n",
        "    args = TrainingArguments(\n",
        "        output_dir=OUTPUT_DIR,\n",
        "        num_train_epochs=10,\n",
        "        per_device_train_batch_size=3,\n",
        "        per_device_eval_batch_size=4,\n",
        "        gradient_accumulation_steps=10,\n",
        "        learning_rate=2e-4,\n",
        "        warmup_ratio=0.03,\n",
        "        logging_steps=20,\n",
        "        eval_strategy=\"epoch\",\n",
        "        save_strategy=\"epoch\",\n",
        "        save_total_limit=2,\n",
        "        bf16=torch.cuda.is_available(),\n",
        "        optim=\"paged_adamw_32bit\",\n",
        "        seed=SEED,\n",
        "        report_to=\"none\",\n",
        "        dataloader_num_workers=4,\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model=\"loss\",\n",
        "        greater_is_better=False\n",
        "    )\n",
        "\n",
        "    # ------------------\n",
        "    # Trainer\n",
        "    # ------------------\n",
        "    trainer = WeightedTrainer(\n",
        "        model=model,\n",
        "        args=args,\n",
        "        train_dataset=train_ds,\n",
        "        eval_dataset=eval_ds,\n",
        "        tokenizer=tok,\n",
        "        data_collator=collator,\n",
        "        callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
        "    )\n",
        "\n",
        "    # ------------------\n",
        "    # Treino\n",
        "    # ------------------\n",
        "    start_time = time.time()\n",
        "\n",
        "    trainer.train()\n",
        "\n",
        "    end_time = time.time()\n",
        "    elapsed_time = end_time - start_time\n",
        "    print(f\"\\nTempo total de execução: {elapsed_time:.2f} segundos\")\n",
        "\n",
        "    trainer.save_model(OUTPUT_DIR)\n",
        "    tok.save_pretrained(OUTPUT_DIR)\n",
        "\n",
        "    print(\"Treino finalizado. Modelo salvo em\", OUTPUT_DIR)\n",
        "\n",
        "\n",
        "train_all()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ddf70329",
      "metadata": {},
      "outputs": [],
      "source": [
        "del model\n",
        "del raw_model\n",
        "loss_fn = None\n",
        "# del trainer\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "b4b30119",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1b1af652c5e54b23b770385bdcca1ec5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "checkpoint_dir= os.path.join(OUTPUT_DIR, \"checkpoint-4484\")  # ajuste conforme necessário\n",
        "# ------------------\n",
        "# Modelo base com quantização 4-bit\n",
        "# ------------------\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16 if torch.cuda.is_available() else torch.float32,\n",
        ")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True,\n",
        "    quantization_config=bnb_config\n",
        ")\n",
        "\n",
        "# Aplicar o LoRA / PEFT checkpoint\n",
        "model = PeftModel.from_pretrained(\n",
        "    model,\n",
        "    checkpoint_dir,\n",
        "    device_map=\"auto\",           # mantém a mesma distribuição\n",
        ")\n",
        "\n",
        "tok = AutoTokenizer.from_pretrained(checkpoint_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "e918b787",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "cff43310",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted class: ('1', {'0': 0.20361328125, '1': 0.466064453125, '2': 0.330322265625})\n"
          ]
        }
      ],
      "source": [
        "# ------------------\n",
        "# Predict (next token)\n",
        "# ------------------\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# tokens de interesse\n",
        "target_tokens = [tok.encode(\"0\", add_special_tokens=False)[0], tok.encode(\"1\", add_special_tokens=False)[0], tok.encode(\"2\", add_special_tokens=False)[0]]\n",
        "\n",
        "def predict_class(prompt_text):\n",
        "    # tokeniza\n",
        "    tokenized = tok(prompt_text, return_tensors=\"pt\")\n",
        "    input_ids = tokenized.input_ids.cuda()\n",
        "    attention_mask = tokenized.attention_mask.cuda()\n",
        "\n",
        "    # forward no modelo (sem generate)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        # logits do último token\n",
        "        last_token_logits = outputs.logits[0, -1, :]\n",
        "        # softmax para probabilidades\n",
        "        probs = F.softmax(last_token_logits, dim=-1)\n",
        "\n",
        "    # pegar probabilidades apenas para os tokens 0,1,2\n",
        "    target_probs = {tok.decode([t]): probs[t].item() for t in target_tokens}\n",
        "\n",
        "    # escolher token mais provável\n",
        "    pred_token = max(target_probs, key=target_probs.get)\n",
        "\n",
        "    return pred_token, target_probs\n",
        "\n",
        "\n",
        "# Exemplo\n",
        "example = split_test[0]\n",
        "processed_key_words = '\\n- '.join(example[\"descricao_keyword\"].split(';'))\n",
        "\n",
        "    # Cria prompt\n",
        "example_prompt = PROMPT_TMPL.format(\n",
        "        title=example[\"nome_producao\"],\n",
        "        abstract=example[\"descricao_abstract\"],\n",
        "        keywords=processed_key_words,\n",
        "        category=example[\"tema\"]\n",
        "    )\n",
        "print(\"Predicted class:\", predict_class(example_prompt))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "95824f38",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name: scikit-learn\n",
            "Version: 1.7.1\n",
            "Summary: A set of python modules for machine learning and data mining\n",
            "Home-page: https://scikit-learn.org\n",
            "Author: \n",
            "Author-email: \n",
            "License-Expression: BSD-3-Clause\n",
            "Location: /home/rvsantin/miniconda3/envs/challenge_bonito/lib/python3.11/site-packages\n",
            "Requires: joblib, numpy, scipy, threadpoolctl\n",
            "Required-by: \n"
          ]
        }
      ],
      "source": [
        "!pip show scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "2e6d049d",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[codecarbon WARNING @ 10:19:37] Multiple instances of codecarbon are allowed to run at the same time.\n",
            "[codecarbon INFO @ 10:19:37] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 10:19:37] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 10:19:38] We saw that you have a Intel(R) Core(TM) i9-14900KF but we don't know it. Please contact us.\n",
            "[codecarbon WARNING @ 10:19:38] We will use the default power consumption of 4 W per thread for your 32 CPU, so 128W.\n",
            "[codecarbon WARNING @ 10:19:38] No CPU tracking mode found. Falling back on estimation based on TDP for CPU. \n",
            " Linux OS detected: Please ensure RAPL files exist at /sys/class/powercap/intel-rapl/subsystem to measure CPU\n",
            "\n",
            "[codecarbon INFO @ 10:19:38] CPU Model on constant consumption mode: Intel(R) Core(TM) i9-14900KF\n",
            "[codecarbon WARNING @ 10:19:38] No CPU tracking mode found. Falling back on CPU load mode.\n",
            "[codecarbon INFO @ 10:19:38] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 10:19:38] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 10:19:38] The below tracking methods have been set up:\n",
            "                RAM Tracking Method: RAM power estimation model\n",
            "                CPU Tracking Method: cpu_load\n",
            "                GPU Tracking Method: pynvml\n",
            "            \n",
            "[codecarbon INFO @ 10:19:38] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 10:19:38]   Platform system: Linux-6.9.3-76060903-generic-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 10:19:38]   Python version: 3.11.5\n",
            "[codecarbon INFO @ 10:19:38]   CodeCarbon version: 3.0.4\n",
            "[codecarbon INFO @ 10:19:38]   Available RAM : 125.634 GB\n",
            "[codecarbon INFO @ 10:19:38]   CPU count: 32 thread(s) in 1 physical CPU(s)\n",
            "[codecarbon INFO @ 10:19:38]   CPU model: Intel(R) Core(TM) i9-14900KF\n",
            "[codecarbon INFO @ 10:19:38]   GPU count: 1\n",
            "[codecarbon INFO @ 10:19:38]   GPU model: 1 x NVIDIA RTX A5000\n",
            "[codecarbon INFO @ 10:19:41] Emissions data (if any) will be saved to file /exp/rvsantin/projetos/challenge_bonito/balanced_fine_tuning_emissions.csv\n",
            "Inferindo:   1%|          | 23/4203 [00:14<38:29,  1.81it/s][codecarbon INFO @ 10:19:57] Energy consumed for RAM : 0.000164 kWh. RAM Power : 38.0 W\n",
            "Inferindo:   1%|          | 24/4203 [00:15<40:11,  1.73it/s][codecarbon INFO @ 10:19:57] Delta energy consumed for CPU with cpu_load : 0.000055 kWh, power : 12.859882595840004 W\n",
            "[codecarbon INFO @ 10:19:57] Energy consumed for All CPU : 0.000055 kWh\n",
            "[codecarbon INFO @ 10:19:57] Energy consumed for all GPUs : 0.000982 kWh. Total GPU Power : 220.86967943505272 W\n",
            "[codecarbon INFO @ 10:19:57] 0.001201 kWh of electricity used since the beginning.\n",
            "Inferindo:   1%|          | 47/4203 [00:29<45:32,  1.52it/s][codecarbon INFO @ 10:20:12] Energy consumed for RAM : 0.000317 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 10:20:12] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.864505001599998 W\n",
            "[codecarbon INFO @ 10:20:12] Energy consumed for All CPU : 0.000107 kWh\n",
            "[codecarbon INFO @ 10:20:12] Energy consumed for all GPUs : 0.001936 kWh. Total GPU Power : 229.01935534342712 W\n",
            "[codecarbon INFO @ 10:20:12] 0.002360 kWh of electricity used since the beginning.\n",
            "Inferindo:   2%|▏         | 68/4203 [00:44<50:56,  1.35it/s][codecarbon INFO @ 10:20:27] Energy consumed for RAM : 0.000470 kWh. RAM Power : 38.0 W\n",
            "Inferindo:   2%|▏         | 69/4203 [00:45<49:13,  1.40it/s][codecarbon INFO @ 10:20:27] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.865033769600002 W\n",
            "[codecarbon INFO @ 10:20:27] Energy consumed for All CPU : 0.000159 kWh\n",
            "[codecarbon INFO @ 10:20:27] Energy consumed for all GPUs : 0.002893 kWh. Total GPU Power : 229.6217887011896 W\n",
            "[codecarbon INFO @ 10:20:27] 0.003522 kWh of electricity used since the beginning.\n",
            "Inferindo:   2%|▏         | 89/4203 [00:59<47:22,  1.45it/s][codecarbon INFO @ 10:20:42] Energy consumed for RAM : 0.000623 kWh. RAM Power : 38.0 W\n",
            "Inferindo:   2%|▏         | 90/4203 [01:00<48:52,  1.40it/s][codecarbon INFO @ 10:20:42] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.864938160800003 W\n",
            "[codecarbon INFO @ 10:20:42] Energy consumed for All CPU : 0.000211 kWh\n",
            "[codecarbon INFO @ 10:20:42] Energy consumed for all GPUs : 0.003851 kWh. Total GPU Power : 230.07179954233192 W\n",
            "[codecarbon INFO @ 10:20:42] 0.004685 kWh of electricity used since the beginning.\n",
            "Inferindo:   3%|▎         | 110/4203 [01:14<51:21,  1.33it/s][codecarbon INFO @ 10:20:57] Energy consumed for RAM : 0.000776 kWh. RAM Power : 38.0 W\n",
            "Inferindo:   3%|▎         | 111/4203 [01:15<48:09,  1.42it/s][codecarbon INFO @ 10:20:57] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.861574911200002 W\n",
            "[codecarbon INFO @ 10:20:57] Energy consumed for All CPU : 0.000263 kWh\n",
            "[codecarbon INFO @ 10:20:57] Energy consumed for all GPUs : 0.004805 kWh. Total GPU Power : 228.9451502841274 W\n",
            "[codecarbon INFO @ 10:20:57] 0.005843 kWh of electricity used since the beginning.\n",
            "Inferindo:   3%|▎         | 133/4203 [01:29<46:58,  1.44it/s][codecarbon INFO @ 10:21:12] Energy consumed for RAM : 0.000929 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 10:21:12] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.881843278400002 W\n",
            "[codecarbon INFO @ 10:21:12] Energy consumed for All CPU : 0.000314 kWh\n",
            "[codecarbon INFO @ 10:21:12] Energy consumed for all GPUs : 0.005759 kWh. Total GPU Power : 229.04852272300246 W\n",
            "[codecarbon INFO @ 10:21:12] 0.007002 kWh of electricity used since the beginning.\n",
            "Inferindo:   4%|▎         | 154/4203 [01:44<46:39,  1.45it/s][codecarbon INFO @ 10:21:27] Energy consumed for RAM : 0.001082 kWh. RAM Power : 38.0 W\n",
            "Inferindo:   4%|▎         | 155/4203 [01:45<46:20,  1.46it/s][codecarbon INFO @ 10:21:27] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.875390501600002 W\n",
            "[codecarbon INFO @ 10:21:27] Energy consumed for All CPU : 0.000366 kWh\n",
            "[codecarbon INFO @ 10:21:27] Energy consumed for all GPUs : 0.006710 kWh. Total GPU Power : 228.27278322539507 W\n",
            "[codecarbon INFO @ 10:21:27] 0.008158 kWh of electricity used since the beginning.\n",
            "Inferindo:   4%|▍         | 177/4203 [01:59<38:12,  1.76it/s][codecarbon INFO @ 10:21:42] Energy consumed for RAM : 0.001235 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 10:21:42] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.8694429776 W\n",
            "[codecarbon INFO @ 10:21:42] Energy consumed for All CPU : 0.000418 kWh\n",
            "[codecarbon INFO @ 10:21:42] Energy consumed for all GPUs : 0.007660 kWh. Total GPU Power : 227.98241826785858 W\n",
            "[codecarbon INFO @ 10:21:42] 0.009313 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 10:21:42] 0.007568 g.CO2eq/s mean an estimation of 238.66792761118626 kg.CO2eq/year\n",
            "Inferindo:   5%|▍         | 199/4203 [02:14<48:22,  1.38it/s][codecarbon INFO @ 10:21:57] Energy consumed for RAM : 0.001388 kWh. RAM Power : 38.0 W\n",
            "Inferindo:   5%|▍         | 200/4203 [02:15<48:08,  1.39it/s][codecarbon INFO @ 10:21:57] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.870978672800002 W\n",
            "[codecarbon INFO @ 10:21:57] Energy consumed for All CPU : 0.000470 kWh\n",
            "[codecarbon INFO @ 10:21:57] Energy consumed for all GPUs : 0.008616 kWh. Total GPU Power : 229.54446123708456 W\n",
            "[codecarbon INFO @ 10:21:57] 0.010473 kWh of electricity used since the beginning.\n",
            "Inferindo:   5%|▌         | 220/4203 [02:29<44:47,  1.48it/s][codecarbon INFO @ 10:22:12] Energy consumed for RAM : 0.001541 kWh. RAM Power : 38.0 W\n",
            "Inferindo:   5%|▌         | 221/4203 [02:30<44:47,  1.48it/s][codecarbon INFO @ 10:22:12] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.888691277600003 W\n",
            "[codecarbon INFO @ 10:22:12] Energy consumed for All CPU : 0.000522 kWh\n",
            "[codecarbon INFO @ 10:22:12] Energy consumed for all GPUs : 0.009573 kWh. Total GPU Power : 229.69458712371548 W\n",
            "[codecarbon INFO @ 10:22:12] 0.011635 kWh of electricity used since the beginning.\n",
            "Inferindo:   6%|▌         | 242/4203 [02:44<43:50,  1.51it/s][codecarbon INFO @ 10:22:27] Energy consumed for RAM : 0.001694 kWh. RAM Power : 38.0 W\n",
            "Inferindo:   6%|▌         | 243/4203 [02:45<42:17,  1.56it/s][codecarbon INFO @ 10:22:27] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.889214480000001 W\n",
            "[codecarbon INFO @ 10:22:27] Energy consumed for All CPU : 0.000574 kWh\n",
            "[codecarbon INFO @ 10:22:27] Energy consumed for all GPUs : 0.010526 kWh. Total GPU Power : 228.81652994228457 W\n",
            "[codecarbon INFO @ 10:22:27] 0.012793 kWh of electricity used since the beginning.\n",
            "Inferindo:   6%|▋         | 263/4203 [02:59<43:11,  1.52it/s][codecarbon INFO @ 10:22:42] Energy consumed for RAM : 0.001847 kWh. RAM Power : 38.0 W\n",
            "Inferindo:   6%|▋         | 264/4203 [03:00<43:14,  1.52it/s][codecarbon INFO @ 10:22:42] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.886061578400003 W\n",
            "[codecarbon INFO @ 10:22:42] Energy consumed for All CPU : 0.000626 kWh\n",
            "[codecarbon INFO @ 10:22:42] Energy consumed for all GPUs : 0.011478 kWh. Total GPU Power : 228.61926830831192 W\n",
            "[codecarbon INFO @ 10:22:42] 0.013951 kWh of electricity used since the beginning.\n",
            "Inferindo:   7%|▋         | 284/4203 [03:14<46:31,  1.40it/s][codecarbon INFO @ 10:22:57] Energy consumed for RAM : 0.002000 kWh. RAM Power : 38.0 W\n",
            "Inferindo:   7%|▋         | 285/4203 [03:15<44:12,  1.48it/s][codecarbon INFO @ 10:22:57] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.9275916464 W\n",
            "[codecarbon INFO @ 10:22:57] Energy consumed for All CPU : 0.000678 kWh\n",
            "[codecarbon INFO @ 10:22:57] Energy consumed for all GPUs : 0.012435 kWh. Total GPU Power : 229.61056189567935 W\n",
            "[codecarbon INFO @ 10:22:57] 0.015112 kWh of electricity used since the beginning.\n",
            "Inferindo:   7%|▋         | 304/4203 [03:28<44:59,  1.44it/s][codecarbon INFO @ 10:23:12] Energy consumed for RAM : 0.002153 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 10:23:12] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.876818765600001 W\n",
            "[codecarbon INFO @ 10:23:12] Energy consumed for All CPU : 0.000730 kWh\n",
            "[codecarbon INFO @ 10:23:12] Energy consumed for all GPUs : 0.013387 kWh. Total GPU Power : 228.59876917327574 W\n",
            "[codecarbon INFO @ 10:23:12] 0.016269 kWh of electricity used since the beginning.\n",
            "Inferindo:   8%|▊         | 325/4203 [03:44<41:40,  1.55it/s]  [codecarbon INFO @ 10:23:27] Energy consumed for RAM : 0.002306 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 10:23:27] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.880459632800003 W\n",
            "[codecarbon INFO @ 10:23:27] Energy consumed for All CPU : 0.000781 kWh\n",
            "[codecarbon INFO @ 10:23:27] Energy consumed for all GPUs : 0.014336 kWh. Total GPU Power : 227.83026492916792 W\n",
            "[codecarbon INFO @ 10:23:27] 0.017423 kWh of electricity used since the beginning.\n",
            "Inferindo:   8%|▊         | 347/4203 [03:59<43:17,  1.48it/s][codecarbon INFO @ 10:23:42] Energy consumed for RAM : 0.002459 kWh. RAM Power : 38.0 W\n",
            "Inferindo:   8%|▊         | 348/4203 [04:00<40:44,  1.58it/s][codecarbon INFO @ 10:23:42] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.882199275200001 W\n",
            "[codecarbon INFO @ 10:23:42] Energy consumed for All CPU : 0.000833 kWh\n",
            "[codecarbon INFO @ 10:23:42] Energy consumed for all GPUs : 0.015287 kWh. Total GPU Power : 228.317764977822 W\n",
            "[codecarbon INFO @ 10:23:42] 0.018579 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 10:23:42] 0.007595 g.CO2eq/s mean an estimation of 239.5041398249688 kg.CO2eq/year\n",
            "Inferindo:   9%|▉         | 369/4203 [04:14<42:33,  1.50it/s][codecarbon INFO @ 10:23:57] Energy consumed for RAM : 0.002612 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 10:23:57] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.859834440800004 W\n",
            "[codecarbon INFO @ 10:23:57] Energy consumed for All CPU : 0.000885 kWh\n",
            "[codecarbon INFO @ 10:23:57] Energy consumed for all GPUs : 0.016243 kWh. Total GPU Power : 229.43537843774257 W\n",
            "[codecarbon INFO @ 10:23:57] 0.019740 kWh of electricity used since the beginning.\n",
            "Inferindo:   9%|▉         | 392/4203 [04:29<39:45,  1.60it/s][codecarbon INFO @ 10:24:12] Energy consumed for RAM : 0.002765 kWh. RAM Power : 38.0 W\n",
            "Inferindo:   9%|▉         | 393/4203 [04:30<39:10,  1.62it/s][codecarbon INFO @ 10:24:12] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.941910920000005 W\n",
            "[codecarbon INFO @ 10:24:12] Energy consumed for All CPU : 0.000937 kWh\n",
            "[codecarbon INFO @ 10:24:12] Energy consumed for all GPUs : 0.017196 kWh. Total GPU Power : 228.76425036009175 W\n",
            "[codecarbon INFO @ 10:24:12] 0.020898 kWh of electricity used since the beginning.\n",
            "Inferindo:  10%|▉         | 413/4203 [04:44<46:28,  1.36it/s][codecarbon INFO @ 10:24:27] Energy consumed for RAM : 0.002918 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  10%|▉         | 414/4203 [04:45<43:12,  1.46it/s][codecarbon INFO @ 10:24:27] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.883069258400003 W\n",
            "[codecarbon INFO @ 10:24:27] Energy consumed for All CPU : 0.000989 kWh\n",
            "[codecarbon INFO @ 10:24:27] Energy consumed for all GPUs : 0.018148 kWh. Total GPU Power : 228.4577069662638 W\n",
            "[codecarbon INFO @ 10:24:27] 0.022055 kWh of electricity used since the beginning.\n",
            "Inferindo:  10%|█         | 435/4203 [04:59<45:03,  1.39it/s][codecarbon INFO @ 10:24:42] Energy consumed for RAM : 0.003071 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  10%|█         | 436/4203 [05:00<41:41,  1.51it/s][codecarbon INFO @ 10:24:42] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.854615952800005 W\n",
            "[codecarbon INFO @ 10:24:42] Energy consumed for All CPU : 0.001041 kWh\n",
            "[codecarbon INFO @ 10:24:42] Energy consumed for all GPUs : 0.019103 kWh. Total GPU Power : 229.25139896102507 W\n",
            "[codecarbon INFO @ 10:24:42] 0.023215 kWh of electricity used since the beginning.\n",
            "Inferindo:  11%|█         | 456/4203 [05:14<45:13,  1.38it/s][codecarbon INFO @ 10:24:57] Energy consumed for RAM : 0.003224 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  11%|█         | 457/4203 [05:15<41:56,  1.49it/s][codecarbon INFO @ 10:24:57] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.856657181600003 W\n",
            "[codecarbon INFO @ 10:24:57] Energy consumed for All CPU : 0.001093 kWh\n",
            "[codecarbon INFO @ 10:24:57] Energy consumed for all GPUs : 0.020056 kWh. Total GPU Power : 228.85821826816886 W\n",
            "[codecarbon INFO @ 10:24:57] 0.024372 kWh of electricity used since the beginning.\n",
            "Inferindo:  11%|█▏        | 479/4203 [05:29<40:17,  1.54it/s][codecarbon INFO @ 10:25:12] Energy consumed for RAM : 0.003377 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 10:25:12] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.852526368800005 W\n",
            "[codecarbon INFO @ 10:25:12] Energy consumed for All CPU : 0.001144 kWh\n",
            "[codecarbon INFO @ 10:25:12] Energy consumed for all GPUs : 0.021007 kWh. Total GPU Power : 228.20294369297508 W\n",
            "[codecarbon INFO @ 10:25:12] 0.025528 kWh of electricity used since the beginning.\n",
            "Inferindo:  12%|█▏        | 499/4203 [05:44<47:36,  1.30it/s][codecarbon INFO @ 10:25:27] Energy consumed for RAM : 0.003530 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  12%|█▏        | 500/4203 [05:45<43:30,  1.42it/s][codecarbon INFO @ 10:25:27] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.850621968800002 W\n",
            "[codecarbon INFO @ 10:25:27] Energy consumed for All CPU : 0.001196 kWh\n",
            "[codecarbon INFO @ 10:25:27] Energy consumed for all GPUs : 0.021964 kWh. Total GPU Power : 229.73500177725433 W\n",
            "[codecarbon INFO @ 10:25:27] 0.026690 kWh of electricity used since the beginning.\n",
            "Inferindo:  12%|█▏        | 520/4203 [05:59<42:01,  1.46it/s][codecarbon INFO @ 10:25:42] Energy consumed for RAM : 0.003683 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  12%|█▏        | 521/4203 [06:00<45:52,  1.34it/s][codecarbon INFO @ 10:25:42] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.864202220000003 W\n",
            "[codecarbon INFO @ 10:25:42] Energy consumed for All CPU : 0.001248 kWh\n",
            "[codecarbon INFO @ 10:25:42] Energy consumed for all GPUs : 0.022917 kWh. Total GPU Power : 228.81417143671092 W\n",
            "[codecarbon INFO @ 10:25:42] 0.027848 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 10:25:42] 0.007596 g.CO2eq/s mean an estimation of 239.54509409459308 kg.CO2eq/year\n",
            "Inferindo:  13%|█▎        | 541/4203 [06:14<41:39,  1.46it/s][codecarbon INFO @ 10:25:57] Energy consumed for RAM : 0.003836 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  13%|█▎        | 542/4203 [06:15<43:12,  1.41it/s][codecarbon INFO @ 10:25:57] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.850765436000003 W\n",
            "[codecarbon INFO @ 10:25:57] Energy consumed for All CPU : 0.001300 kWh\n",
            "[codecarbon INFO @ 10:25:57] Energy consumed for all GPUs : 0.023871 kWh. Total GPU Power : 228.85649917423 W\n",
            "[codecarbon INFO @ 10:25:57] 0.029006 kWh of electricity used since the beginning.\n",
            "Inferindo:  13%|█▎        | 564/4203 [06:29<36:15,  1.67it/s][codecarbon INFO @ 10:26:12] Energy consumed for RAM : 0.003989 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 10:26:12] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.857636237600003 W\n",
            "[codecarbon INFO @ 10:26:12] Energy consumed for All CPU : 0.001351 kWh\n",
            "[codecarbon INFO @ 10:26:12] Energy consumed for all GPUs : 0.024824 kWh. Total GPU Power : 228.9397050235302 W\n",
            "[codecarbon INFO @ 10:26:12] 0.030164 kWh of electricity used since the beginning.\n",
            "Inferindo:  14%|█▍        | 585/4203 [06:44<44:10,  1.37it/s][codecarbon INFO @ 10:26:27] Energy consumed for RAM : 0.004142 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  14%|█▍        | 586/4203 [06:45<41:31,  1.45it/s][codecarbon INFO @ 10:26:27] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.859162536800003 W\n",
            "[codecarbon INFO @ 10:26:27] Energy consumed for All CPU : 0.001403 kWh\n",
            "[codecarbon INFO @ 10:26:27] Energy consumed for all GPUs : 0.025781 kWh. Total GPU Power : 229.56127084364556 W\n",
            "[codecarbon INFO @ 10:26:27] 0.031326 kWh of electricity used since the beginning.\n",
            "Inferindo:  14%|█▍        | 607/4203 [06:59<41:37,  1.44it/s][codecarbon INFO @ 10:26:42] Energy consumed for RAM : 0.004295 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  14%|█▍        | 608/4203 [07:00<42:46,  1.40it/s][codecarbon INFO @ 10:26:42] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.862467214400002 W\n",
            "[codecarbon INFO @ 10:26:42] Energy consumed for All CPU : 0.001455 kWh\n",
            "[codecarbon INFO @ 10:26:42] Energy consumed for all GPUs : 0.026734 kWh. Total GPU Power : 228.85571462696234 W\n",
            "[codecarbon INFO @ 10:26:42] 0.032484 kWh of electricity used since the beginning.\n",
            "Inferindo:  15%|█▍        | 629/4203 [07:14<44:52,  1.33it/s][codecarbon INFO @ 10:26:57] Energy consumed for RAM : 0.004448 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  15%|█▍        | 630/4203 [07:15<42:11,  1.41it/s][codecarbon INFO @ 10:26:57] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.856011147200004 W\n",
            "[codecarbon INFO @ 10:26:57] Energy consumed for All CPU : 0.001507 kWh\n",
            "[codecarbon INFO @ 10:26:57] Energy consumed for all GPUs : 0.027687 kWh. Total GPU Power : 228.8542737068565 W\n",
            "[codecarbon INFO @ 10:26:57] 0.033642 kWh of electricity used since the beginning.\n",
            "Inferindo:  15%|█▌        | 651/4203 [07:29<41:39,  1.42it/s][codecarbon INFO @ 10:27:12] Energy consumed for RAM : 0.004601 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  16%|█▌        | 652/4203 [07:30<41:41,  1.42it/s][codecarbon INFO @ 10:27:12] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.9147880016 W\n",
            "[codecarbon INFO @ 10:27:12] Energy consumed for All CPU : 0.001559 kWh\n",
            "[codecarbon INFO @ 10:27:12] Energy consumed for all GPUs : 0.028642 kWh. Total GPU Power : 229.221532487641 W\n",
            "[codecarbon INFO @ 10:27:12] 0.034802 kWh of electricity used since the beginning.\n",
            "Inferindo:  16%|█▌        | 674/4203 [07:44<38:17,  1.54it/s][codecarbon INFO @ 10:27:27] Energy consumed for RAM : 0.004754 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  16%|█▌        | 675/4203 [07:45<40:04,  1.47it/s][codecarbon INFO @ 10:27:27] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.857053484000001 W\n",
            "[codecarbon INFO @ 10:27:27] Energy consumed for All CPU : 0.001610 kWh\n",
            "[codecarbon INFO @ 10:27:27] Energy consumed for all GPUs : 0.029597 kWh. Total GPU Power : 229.1286450387039 W\n",
            "[codecarbon INFO @ 10:27:27] 0.035961 kWh of electricity used since the beginning.\n",
            "Inferindo:  17%|█▋        | 695/4203 [07:59<38:28,  1.52it/s][codecarbon INFO @ 10:27:42] Energy consumed for RAM : 0.004907 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  17%|█▋        | 696/4203 [08:00<38:24,  1.52it/s][codecarbon INFO @ 10:27:42] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.859475052800004 W\n",
            "[codecarbon INFO @ 10:27:42] Energy consumed for All CPU : 0.001662 kWh\n",
            "[codecarbon INFO @ 10:27:42] Energy consumed for all GPUs : 0.030548 kWh. Total GPU Power : 228.31646018237916 W\n",
            "[codecarbon INFO @ 10:27:42] 0.037117 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 10:27:42] 0.007597 g.CO2eq/s mean an estimation of 239.5647682505569 kg.CO2eq/year\n",
            "Inferindo:  17%|█▋        | 719/4203 [08:14<38:08,  1.52it/s][codecarbon INFO @ 10:27:57] Energy consumed for RAM : 0.005060 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 10:27:57] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.862875339200002 W\n",
            "[codecarbon INFO @ 10:27:57] Energy consumed for All CPU : 0.001714 kWh\n",
            "[codecarbon INFO @ 10:27:57] Energy consumed for all GPUs : 0.031502 kWh. Total GPU Power : 228.99866908844 W\n",
            "[codecarbon INFO @ 10:27:57] 0.038276 kWh of electricity used since the beginning.\n",
            "Inferindo:  18%|█▊        | 742/4203 [08:29<36:01,  1.60it/s][codecarbon INFO @ 10:28:12] Energy consumed for RAM : 0.005213 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  18%|█▊        | 743/4203 [08:30<35:15,  1.64it/s][codecarbon INFO @ 10:28:12] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.865411164800003 W\n",
            "[codecarbon INFO @ 10:28:12] Energy consumed for All CPU : 0.001766 kWh\n",
            "[codecarbon INFO @ 10:28:12] Energy consumed for all GPUs : 0.032457 kWh. Total GPU Power : 229.24597236334128 W\n",
            "[codecarbon INFO @ 10:28:12] 0.039436 kWh of electricity used since the beginning.\n",
            "Inferindo:  18%|█▊        | 766/4203 [08:44<34:11,  1.68it/s][codecarbon INFO @ 10:28:27] Energy consumed for RAM : 0.005366 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  18%|█▊        | 767/4203 [08:45<33:57,  1.69it/s][codecarbon INFO @ 10:28:27] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.951161480000003 W\n",
            "[codecarbon INFO @ 10:28:27] Energy consumed for All CPU : 0.001818 kWh\n",
            "[codecarbon INFO @ 10:28:27] Energy consumed for all GPUs : 0.033408 kWh. Total GPU Power : 228.32732973487785 W\n",
            "[codecarbon INFO @ 10:28:27] 0.040592 kWh of electricity used since the beginning.\n",
            "Inferindo:  19%|█▉        | 789/4203 [08:59<34:25,  1.65it/s][codecarbon INFO @ 10:28:42] Energy consumed for RAM : 0.005519 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  19%|█▉        | 790/4203 [09:00<33:57,  1.67it/s][codecarbon INFO @ 10:28:42] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.867809060000003 W\n",
            "[codecarbon INFO @ 10:28:42] Energy consumed for All CPU : 0.001870 kWh\n",
            "[codecarbon INFO @ 10:28:42] Energy consumed for all GPUs : 0.034357 kWh. Total GPU Power : 227.73018085136724 W\n",
            "[codecarbon INFO @ 10:28:42] 0.041745 kWh of electricity used since the beginning.\n",
            "Inferindo:  19%|█▉        | 810/4203 [09:14<40:18,  1.40it/s][codecarbon INFO @ 10:28:57] Energy consumed for RAM : 0.005672 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  19%|█▉        | 811/4203 [09:15<40:00,  1.41it/s][codecarbon INFO @ 10:28:57] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.867977007200002 W\n",
            "[codecarbon INFO @ 10:28:57] Energy consumed for All CPU : 0.001922 kWh\n",
            "[codecarbon INFO @ 10:28:57] Energy consumed for all GPUs : 0.035312 kWh. Total GPU Power : 229.1858200868529 W\n",
            "[codecarbon INFO @ 10:28:57] 0.042905 kWh of electricity used since the beginning.\n",
            "Inferindo:  20%|█▉        | 832/4203 [09:29<42:17,  1.33it/s][codecarbon INFO @ 10:29:12] Energy consumed for RAM : 0.005825 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  20%|█▉        | 833/4203 [09:30<41:13,  1.36it/s][codecarbon INFO @ 10:29:12] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.873220673600004 W\n",
            "[codecarbon INFO @ 10:29:12] Energy consumed for All CPU : 0.001973 kWh\n",
            "[codecarbon INFO @ 10:29:12] Energy consumed for all GPUs : 0.036266 kWh. Total GPU Power : 229.19095725082033 W\n",
            "[codecarbon INFO @ 10:29:12] 0.044065 kWh of electricity used since the beginning.\n",
            "Inferindo:  20%|██        | 854/4203 [09:44<40:36,  1.37it/s][codecarbon INFO @ 10:29:27] Energy consumed for RAM : 0.005978 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  20%|██        | 855/4203 [09:45<37:28,  1.49it/s][codecarbon INFO @ 10:29:27] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.872111232800005 W\n",
            "[codecarbon INFO @ 10:29:27] Energy consumed for All CPU : 0.002025 kWh\n",
            "[codecarbon INFO @ 10:29:27] Energy consumed for all GPUs : 0.037219 kWh. Total GPU Power : 228.6863727710857 W\n",
            "[codecarbon INFO @ 10:29:27] 0.045222 kWh of electricity used since the beginning.\n",
            "Inferindo:  21%|██        | 876/4203 [09:59<33:35,  1.65it/s][codecarbon INFO @ 10:29:42] Energy consumed for RAM : 0.006131 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  21%|██        | 877/4203 [10:00<37:16,  1.49it/s][codecarbon INFO @ 10:29:42] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.853619537600004 W\n",
            "[codecarbon INFO @ 10:29:42] Energy consumed for All CPU : 0.002077 kWh\n",
            "[codecarbon INFO @ 10:29:42] Energy consumed for all GPUs : 0.038170 kWh. Total GPU Power : 228.27161515367303 W\n",
            "[codecarbon INFO @ 10:29:42] 0.046378 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 10:29:42] 0.007590 g.CO2eq/s mean an estimation of 239.3498197505305 kg.CO2eq/year\n",
            "Inferindo:  21%|██▏       | 899/4203 [10:14<36:28,  1.51it/s][codecarbon INFO @ 10:29:57] Energy consumed for RAM : 0.006284 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  21%|██▏       | 900/4203 [10:15<33:04,  1.66it/s][codecarbon INFO @ 10:29:57] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.853420306400004 W\n",
            "[codecarbon INFO @ 10:29:57] Energy consumed for All CPU : 0.002129 kWh\n",
            "[codecarbon INFO @ 10:29:57] Energy consumed for all GPUs : 0.039126 kWh. Total GPU Power : 229.4722897109043 W\n",
            "[codecarbon INFO @ 10:29:57] 0.047539 kWh of electricity used since the beginning.\n",
            "Inferindo:  22%|██▏       | 922/4203 [10:29<34:05,  1.60it/s][codecarbon INFO @ 10:30:12] Energy consumed for RAM : 0.006437 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  22%|██▏       | 923/4203 [10:30<34:35,  1.58it/s][codecarbon INFO @ 10:30:12] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.857138969600003 W\n",
            "[codecarbon INFO @ 10:30:12] Energy consumed for All CPU : 0.002181 kWh\n",
            "[codecarbon INFO @ 10:30:12] Energy consumed for all GPUs : 0.040078 kWh. Total GPU Power : 228.4571081480912 W\n",
            "[codecarbon INFO @ 10:30:12] 0.048695 kWh of electricity used since the beginning.\n",
            "Inferindo:  23%|██▎       | 946/4203 [10:45<34:23,  1.58it/s][codecarbon INFO @ 10:30:27] Energy consumed for RAM : 0.006590 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 10:30:27] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.854989582400004 W\n",
            "[codecarbon INFO @ 10:30:27] Energy consumed for All CPU : 0.002232 kWh\n",
            "[codecarbon INFO @ 10:30:27] Energy consumed for all GPUs : 0.041034 kWh. Total GPU Power : 229.4985258279267 W\n",
            "[codecarbon INFO @ 10:30:27] 0.049856 kWh of electricity used since the beginning.\n",
            "Inferindo:  23%|██▎       | 968/4203 [10:59<33:27,  1.61it/s][codecarbon INFO @ 10:30:42] Energy consumed for RAM : 0.006743 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  23%|██▎       | 969/4203 [11:00<34:36,  1.56it/s][codecarbon INFO @ 10:30:42] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.853554276800004 W\n",
            "[codecarbon INFO @ 10:30:42] Energy consumed for All CPU : 0.002284 kWh\n",
            "[codecarbon INFO @ 10:30:42] Energy consumed for all GPUs : 0.041986 kWh. Total GPU Power : 228.52247490547052 W\n",
            "[codecarbon INFO @ 10:30:42] 0.051013 kWh of electricity used since the beginning.\n",
            "Inferindo:  24%|██▎       | 992/4203 [11:14<32:41,  1.64it/s][codecarbon INFO @ 10:30:57] Energy consumed for RAM : 0.006896 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  24%|██▎       | 993/4203 [11:15<33:27,  1.60it/s][codecarbon INFO @ 10:30:57] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.850055357600002 W\n",
            "[codecarbon INFO @ 10:30:57] Energy consumed for All CPU : 0.002336 kWh\n",
            "[codecarbon INFO @ 10:30:57] Energy consumed for all GPUs : 0.042938 kWh. Total GPU Power : 228.52986587429177 W\n",
            "[codecarbon INFO @ 10:30:57] 0.052169 kWh of electricity used since the beginning.\n",
            "Inferindo:  24%|██▍       | 1014/4203 [11:29<33:18,  1.60it/s][codecarbon INFO @ 10:31:12] Energy consumed for RAM : 0.007049 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  24%|██▍       | 1015/4203 [11:30<34:32,  1.54it/s][codecarbon INFO @ 10:31:12] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.853060371200003 W\n",
            "[codecarbon INFO @ 10:31:12] Energy consumed for All CPU : 0.002388 kWh\n",
            "[codecarbon INFO @ 10:31:12] Energy consumed for all GPUs : 0.043893 kWh. Total GPU Power : 229.3419000888065 W\n",
            "[codecarbon INFO @ 10:31:12] 0.053329 kWh of electricity used since the beginning.\n",
            "Inferindo:  25%|██▍       | 1037/4203 [11:44<36:57,  1.43it/s][codecarbon INFO @ 10:31:27] Energy consumed for RAM : 0.007202 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  25%|██▍       | 1038/4203 [11:45<41:15,  1.28it/s][codecarbon INFO @ 10:31:27] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.858844044800001 W\n",
            "[codecarbon INFO @ 10:31:27] Energy consumed for All CPU : 0.002439 kWh\n",
            "[codecarbon INFO @ 10:31:27] Energy consumed for all GPUs : 0.044848 kWh. Total GPU Power : 229.17853690903533 W\n",
            "[codecarbon INFO @ 10:31:27] 0.054489 kWh of electricity used since the beginning.\n",
            "Inferindo:  25%|██▌       | 1059/4203 [11:59<36:49,  1.42it/s][codecarbon INFO @ 10:31:42] Energy consumed for RAM : 0.007355 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  25%|██▌       | 1060/4203 [12:00<35:04,  1.49it/s][codecarbon INFO @ 10:31:42] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.865471544000005 W\n",
            "[codecarbon INFO @ 10:31:42] Energy consumed for All CPU : 0.002491 kWh\n",
            "[codecarbon INFO @ 10:31:42] Energy consumed for all GPUs : 0.045803 kWh. Total GPU Power : 229.23665298416532 W\n",
            "[codecarbon INFO @ 10:31:42] 0.055649 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 10:31:42] 0.007598 g.CO2eq/s mean an estimation of 239.61273168183996 kg.CO2eq/year\n",
            "Inferindo:  26%|██▌       | 1083/4203 [12:14<33:38,  1.55it/s][codecarbon INFO @ 10:31:57] Energy consumed for RAM : 0.007508 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  26%|██▌       | 1084/4203 [12:15<32:24,  1.60it/s][codecarbon INFO @ 10:31:57] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.876238056800002 W\n",
            "[codecarbon INFO @ 10:31:57] Energy consumed for All CPU : 0.002543 kWh\n",
            "[codecarbon INFO @ 10:31:57] Energy consumed for all GPUs : 0.046757 kWh. Total GPU Power : 229.0483091462344 W\n",
            "[codecarbon INFO @ 10:31:57] 0.056808 kWh of electricity used since the beginning.\n",
            "Inferindo:  26%|██▋       | 1105/4203 [12:29<35:45,  1.44it/s][codecarbon INFO @ 10:32:12] Energy consumed for RAM : 0.007661 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  26%|██▋       | 1106/4203 [12:30<35:06,  1.47it/s][codecarbon INFO @ 10:32:12] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.851190099200002 W\n",
            "[codecarbon INFO @ 10:32:12] Energy consumed for All CPU : 0.002595 kWh\n",
            "[codecarbon INFO @ 10:32:12] Energy consumed for all GPUs : 0.047713 kWh. Total GPU Power : 229.30424502299667 W\n",
            "[codecarbon INFO @ 10:32:12] 0.057968 kWh of electricity used since the beginning.\n",
            "Inferindo:  27%|██▋       | 1129/4203 [12:44<31:17,  1.64it/s][codecarbon INFO @ 10:32:27] Energy consumed for RAM : 0.007814 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  27%|██▋       | 1130/4203 [12:45<29:15,  1.75it/s][codecarbon INFO @ 10:32:27] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.8531328176 W\n",
            "[codecarbon INFO @ 10:32:27] Energy consumed for All CPU : 0.002646 kWh\n",
            "[codecarbon INFO @ 10:32:27] Energy consumed for all GPUs : 0.048667 kWh. Total GPU Power : 228.98313332535022 W\n",
            "[codecarbon INFO @ 10:32:27] 0.059127 kWh of electricity used since the beginning.\n",
            "Inferindo:  27%|██▋       | 1151/4203 [12:59<37:14,  1.37it/s][codecarbon INFO @ 10:32:42] Energy consumed for RAM : 0.007967 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  27%|██▋       | 1152/4203 [13:00<38:51,  1.31it/s][codecarbon INFO @ 10:32:42] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.854739195200002 W\n",
            "[codecarbon INFO @ 10:32:42] Energy consumed for All CPU : 0.002698 kWh\n",
            "[codecarbon INFO @ 10:32:42] Energy consumed for all GPUs : 0.049619 kWh. Total GPU Power : 228.69317031690844 W\n",
            "[codecarbon INFO @ 10:32:42] 0.060284 kWh of electricity used since the beginning.\n",
            "Inferindo:  28%|██▊       | 1174/4203 [13:14<33:57,  1.49it/s][codecarbon INFO @ 10:32:57] Energy consumed for RAM : 0.008120 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  28%|██▊       | 1175/4203 [13:15<33:35,  1.50it/s][codecarbon INFO @ 10:32:57] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.851452352000003 W\n",
            "[codecarbon INFO @ 10:32:57] Energy consumed for All CPU : 0.002750 kWh\n",
            "[codecarbon INFO @ 10:32:57] Energy consumed for all GPUs : 0.050572 kWh. Total GPU Power : 228.82188418228935 W\n",
            "[codecarbon INFO @ 10:32:57] 0.061442 kWh of electricity used since the beginning.\n",
            "Inferindo:  28%|██▊       | 1197/4203 [13:30<34:15,  1.46it/s][codecarbon INFO @ 10:33:12] Energy consumed for RAM : 0.008273 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 10:33:12] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.887677798400002 W\n",
            "[codecarbon INFO @ 10:33:12] Energy consumed for All CPU : 0.002802 kWh\n",
            "[codecarbon INFO @ 10:33:12] Energy consumed for all GPUs : 0.051526 kWh. Total GPU Power : 228.98487960540248 W\n",
            "[codecarbon INFO @ 10:33:12] 0.062601 kWh of electricity used since the beginning.\n",
            "Inferindo:  29%|██▉       | 1218/4203 [13:44<35:29,  1.40it/s][codecarbon INFO @ 10:33:27] Energy consumed for RAM : 0.008426 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  29%|██▉       | 1219/4203 [13:45<32:50,  1.51it/s][codecarbon INFO @ 10:33:27] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.849035592800002 W\n",
            "[codecarbon INFO @ 10:33:27] Energy consumed for All CPU : 0.002854 kWh\n",
            "[codecarbon INFO @ 10:33:27] Energy consumed for all GPUs : 0.052480 kWh. Total GPU Power : 228.97624990750114 W\n",
            "[codecarbon INFO @ 10:33:27] 0.063760 kWh of electricity used since the beginning.\n",
            "Inferindo:  30%|██▉       | 1241/4203 [13:59<30:52,  1.60it/s][codecarbon INFO @ 10:33:42] Energy consumed for RAM : 0.008579 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  30%|██▉       | 1242/4203 [14:00<32:46,  1.51it/s][codecarbon INFO @ 10:33:42] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.848408912000002 W\n",
            "[codecarbon INFO @ 10:33:42] Energy consumed for All CPU : 0.002905 kWh\n",
            "[codecarbon INFO @ 10:33:42] Energy consumed for all GPUs : 0.053433 kWh. Total GPU Power : 228.63468833362978 W\n",
            "[codecarbon INFO @ 10:33:42] 0.064917 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 10:33:42] 0.007596 g.CO2eq/s mean an estimation of 239.5355046500827 kg.CO2eq/year\n",
            "Inferindo:  30%|███       | 1264/4203 [14:14<32:44,  1.50it/s][codecarbon INFO @ 10:33:57] Energy consumed for RAM : 0.008732 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 10:33:57] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.846187424000004 W\n",
            "[codecarbon INFO @ 10:33:57] Energy consumed for All CPU : 0.002957 kWh\n",
            "[codecarbon INFO @ 10:33:57] Energy consumed for all GPUs : 0.054386 kWh. Total GPU Power : 228.82268217100452 W\n",
            "[codecarbon INFO @ 10:33:57] 0.066075 kWh of electricity used since the beginning.\n",
            "Inferindo:  31%|███       | 1285/4203 [14:29<36:27,  1.33it/s][codecarbon INFO @ 10:34:12] Energy consumed for RAM : 0.008885 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  31%|███       | 1286/4203 [14:30<33:56,  1.43it/s][codecarbon INFO @ 10:34:12] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.8523501272 W\n",
            "[codecarbon INFO @ 10:34:12] Energy consumed for All CPU : 0.003009 kWh\n",
            "[codecarbon INFO @ 10:34:12] Energy consumed for all GPUs : 0.055341 kWh. Total GPU Power : 229.2627652105188 W\n",
            "[codecarbon INFO @ 10:34:12] 0.067235 kWh of electricity used since the beginning.\n",
            "Inferindo:  31%|███       | 1307/4203 [14:44<35:17,  1.37it/s][codecarbon INFO @ 10:34:27] Energy consumed for RAM : 0.009038 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  31%|███       | 1308/4203 [14:45<34:37,  1.39it/s][codecarbon INFO @ 10:34:27] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.8479099376 W\n",
            "[codecarbon INFO @ 10:34:27] Energy consumed for All CPU : 0.003061 kWh\n",
            "[codecarbon INFO @ 10:34:27] Energy consumed for all GPUs : 0.056295 kWh. Total GPU Power : 229.01566230623789 W\n",
            "[codecarbon INFO @ 10:34:27] 0.068394 kWh of electricity used since the beginning.\n",
            "Inferindo:  32%|███▏      | 1330/4203 [15:00<30:50,  1.55it/s][codecarbon INFO @ 10:34:42] Energy consumed for RAM : 0.009191 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 10:34:42] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.853213616000003 W\n",
            "[codecarbon INFO @ 10:34:42] Energy consumed for All CPU : 0.003112 kWh\n",
            "[codecarbon INFO @ 10:34:42] Energy consumed for all GPUs : 0.057248 kWh. Total GPU Power : 228.55838101835266 W\n",
            "[codecarbon INFO @ 10:34:42] 0.069551 kWh of electricity used since the beginning.\n",
            "Inferindo:  32%|███▏      | 1351/4203 [15:14<37:58,  1.25it/s][codecarbon INFO @ 10:34:57] Energy consumed for RAM : 0.009344 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  32%|███▏      | 1352/4203 [15:15<36:12,  1.31it/s][codecarbon INFO @ 10:34:57] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.848797647200001 W\n",
            "[codecarbon INFO @ 10:34:57] Energy consumed for All CPU : 0.003164 kWh\n",
            "[codecarbon INFO @ 10:34:57] Energy consumed for all GPUs : 0.058202 kWh. Total GPU Power : 229.07231156074636 W\n",
            "[codecarbon INFO @ 10:34:57] 0.070710 kWh of electricity used since the beginning.\n",
            "Inferindo:  33%|███▎      | 1374/4203 [15:29<34:01,  1.39it/s][codecarbon INFO @ 10:35:12] Energy consumed for RAM : 0.009497 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  33%|███▎      | 1375/4203 [15:30<32:13,  1.46it/s][codecarbon INFO @ 10:35:12] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.855131962400002 W\n",
            "[codecarbon INFO @ 10:35:12] Energy consumed for All CPU : 0.003216 kWh\n",
            "[codecarbon INFO @ 10:35:12] Energy consumed for all GPUs : 0.059157 kWh. Total GPU Power : 229.3559388553869 W\n",
            "[codecarbon INFO @ 10:35:12] 0.071870 kWh of electricity used since the beginning.\n",
            "Inferindo:  33%|███▎      | 1396/4203 [15:44<32:05,  1.46it/s][codecarbon INFO @ 10:35:27] Energy consumed for RAM : 0.009650 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  33%|███▎      | 1397/4203 [15:45<32:06,  1.46it/s][codecarbon INFO @ 10:35:27] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.856271384000001 W\n",
            "[codecarbon INFO @ 10:35:27] Energy consumed for All CPU : 0.003268 kWh\n",
            "[codecarbon INFO @ 10:35:27] Energy consumed for all GPUs : 0.060115 kWh. Total GPU Power : 229.8326988250231 W\n",
            "[codecarbon INFO @ 10:35:27] 0.073032 kWh of electricity used since the beginning.\n",
            "Inferindo:  34%|███▎      | 1418/4203 [15:59<30:09,  1.54it/s][codecarbon INFO @ 10:35:42] Energy consumed for RAM : 0.009803 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  34%|███▍      | 1419/4203 [16:00<29:03,  1.60it/s][codecarbon INFO @ 10:35:42] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.850616619199998 W\n",
            "[codecarbon INFO @ 10:35:42] Energy consumed for All CPU : 0.003319 kWh\n",
            "[codecarbon INFO @ 10:35:42] Energy consumed for all GPUs : 0.061068 kWh. Total GPU Power : 228.8990094123243 W\n",
            "[codecarbon INFO @ 10:35:42] 0.074190 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 10:35:42] 0.007600 g.CO2eq/s mean an estimation of 239.67086253475733 kg.CO2eq/year\n",
            "Inferindo:  34%|███▍      | 1440/4203 [16:14<31:50,  1.45it/s][codecarbon INFO @ 10:35:57] Energy consumed for RAM : 0.009956 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  34%|███▍      | 1441/4203 [16:15<30:16,  1.52it/s][codecarbon INFO @ 10:35:57] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.846160596800003 W\n",
            "[codecarbon INFO @ 10:35:57] Energy consumed for All CPU : 0.003371 kWh\n",
            "[codecarbon INFO @ 10:35:57] Energy consumed for all GPUs : 0.062023 kWh. Total GPU Power : 229.22047542863817 W\n",
            "[codecarbon INFO @ 10:35:57] 0.075350 kWh of electricity used since the beginning.\n",
            "Inferindo:  35%|███▍      | 1462/4203 [16:29<32:54,  1.39it/s][codecarbon INFO @ 10:36:12] Energy consumed for RAM : 0.010109 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  35%|███▍      | 1463/4203 [16:30<31:50,  1.43it/s][codecarbon INFO @ 10:36:12] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.843897248000001 W\n",
            "[codecarbon INFO @ 10:36:12] Energy consumed for All CPU : 0.003423 kWh\n",
            "[codecarbon INFO @ 10:36:12] Energy consumed for all GPUs : 0.062977 kWh. Total GPU Power : 228.9462771858649 W\n",
            "[codecarbon INFO @ 10:36:12] 0.076508 kWh of electricity used since the beginning.\n",
            "Inferindo:  35%|███▌      | 1486/4203 [16:44<26:09,  1.73it/s][codecarbon INFO @ 10:36:27] Energy consumed for RAM : 0.010262 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 10:36:27] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.849681684799998 W\n",
            "[codecarbon INFO @ 10:36:27] Energy consumed for All CPU : 0.003475 kWh\n",
            "Inferindo:  35%|███▌      | 1487/4203 [16:45<26:06,  1.73it/s][codecarbon INFO @ 10:36:27] Energy consumed for all GPUs : 0.063928 kWh. Total GPU Power : 228.20013201778883 W\n",
            "[codecarbon INFO @ 10:36:27] 0.077664 kWh of electricity used since the beginning.\n",
            "Inferindo:  36%|███▌      | 1508/4203 [17:00<31:19,  1.43it/s][codecarbon INFO @ 10:36:42] Energy consumed for RAM : 0.010415 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 10:36:42] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.8506546928 W\n",
            "[codecarbon INFO @ 10:36:42] Energy consumed for All CPU : 0.003526 kWh\n",
            "[codecarbon INFO @ 10:36:42] Energy consumed for all GPUs : 0.064881 kWh. Total GPU Power : 228.80316062382886 W\n",
            "[codecarbon INFO @ 10:36:42] 0.078822 kWh of electricity used since the beginning.\n",
            "Inferindo:  36%|███▋      | 1529/4203 [17:14<33:40,  1.32it/s][codecarbon INFO @ 10:36:57] Energy consumed for RAM : 0.010568 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 10:36:57] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.844552772 W\n",
            "[codecarbon INFO @ 10:36:57] Energy consumed for All CPU : 0.003578 kWh\n",
            "[codecarbon INFO @ 10:36:57] Energy consumed for all GPUs : 0.065835 kWh. Total GPU Power : 229.15766335914012 W\n",
            "[codecarbon INFO @ 10:36:57] 0.079981 kWh of electricity used since the beginning.\n",
            "Inferindo:  37%|███▋      | 1550/4203 [17:29<28:47,  1.54it/s][codecarbon INFO @ 10:37:12] Energy consumed for RAM : 0.010721 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  37%|███▋      | 1551/4203 [17:30<27:12,  1.62it/s][codecarbon INFO @ 10:37:12] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.8528082848 W\n",
            "[codecarbon INFO @ 10:37:12] Energy consumed for All CPU : 0.003630 kWh\n",
            "[codecarbon INFO @ 10:37:12] Energy consumed for all GPUs : 0.066789 kWh. Total GPU Power : 228.89379184689315 W\n",
            "[codecarbon INFO @ 10:37:12] 0.081139 kWh of electricity used since the beginning.\n",
            "Inferindo:  37%|███▋      | 1572/4203 [17:44<31:28,  1.39it/s][codecarbon INFO @ 10:37:27] Energy consumed for RAM : 0.010874 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 10:37:27] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.8474427728 W\n",
            "[codecarbon INFO @ 10:37:27] Energy consumed for All CPU : 0.003681 kWh\n",
            "[codecarbon INFO @ 10:37:27] Energy consumed for all GPUs : 0.067742 kWh. Total GPU Power : 228.80584367439587 W\n",
            "[codecarbon INFO @ 10:37:27] 0.082297 kWh of electricity used since the beginning.\n",
            "Inferindo:  38%|███▊      | 1593/4203 [17:59<30:59,  1.40it/s][codecarbon INFO @ 10:37:42] Energy consumed for RAM : 0.011027 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  38%|███▊      | 1594/4203 [18:00<28:40,  1.52it/s][codecarbon INFO @ 10:37:42] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.856499782400002 W\n",
            "[codecarbon INFO @ 10:37:42] Energy consumed for All CPU : 0.003733 kWh\n",
            "Inferindo:  38%|███▊      | 1595/4203 [18:00<25:21,  1.71it/s][codecarbon INFO @ 10:37:42] Energy consumed for all GPUs : 0.068698 kWh. Total GPU Power : 229.47874623556322 W\n",
            "[codecarbon INFO @ 10:37:42] 0.083458 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 10:37:43] 0.007595 g.CO2eq/s mean an estimation of 239.5203927064563 kg.CO2eq/year\n",
            "Inferindo:  38%|███▊      | 1617/4203 [18:14<28:07,  1.53it/s][codecarbon INFO @ 10:37:57] Energy consumed for RAM : 0.011180 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  38%|███▊      | 1618/4203 [18:15<27:14,  1.58it/s][codecarbon INFO @ 10:37:57] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.852789068000002 W\n",
            "[codecarbon INFO @ 10:37:57] Energy consumed for All CPU : 0.003785 kWh\n",
            "[codecarbon INFO @ 10:37:57] Energy consumed for all GPUs : 0.069652 kWh. Total GPU Power : 229.0183133372111 W\n",
            "[codecarbon INFO @ 10:37:57] 0.084617 kWh of electricity used since the beginning.\n",
            "Inferindo:  39%|███▉      | 1639/4203 [18:29<29:16,  1.46it/s][codecarbon INFO @ 10:38:12] Energy consumed for RAM : 0.011333 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  39%|███▉      | 1640/4203 [18:30<27:33,  1.55it/s][codecarbon INFO @ 10:38:12] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.864959991200003 W\n",
            "[codecarbon INFO @ 10:38:12] Energy consumed for All CPU : 0.003837 kWh\n",
            "[codecarbon INFO @ 10:38:12] Energy consumed for all GPUs : 0.070605 kWh. Total GPU Power : 228.83883305898019 W\n",
            "[codecarbon INFO @ 10:38:12] 0.085775 kWh of electricity used since the beginning.\n",
            "Inferindo:  40%|███▉      | 1662/4203 [18:44<28:47,  1.47it/s][codecarbon INFO @ 10:38:27] Energy consumed for RAM : 0.011486 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  40%|███▉      | 1663/4203 [18:45<27:29,  1.54it/s][codecarbon INFO @ 10:38:27] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.848704536800001 W\n",
            "[codecarbon INFO @ 10:38:27] Energy consumed for All CPU : 0.003889 kWh\n",
            "[codecarbon INFO @ 10:38:27] Energy consumed for all GPUs : 0.071559 kWh. Total GPU Power : 229.01539189241552 W\n",
            "[codecarbon INFO @ 10:38:28] 0.086934 kWh of electricity used since the beginning.\n",
            "Inferindo:  40%|████      | 1683/4203 [18:59<29:11,  1.44it/s][codecarbon INFO @ 10:38:42] Energy consumed for RAM : 0.011639 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  40%|████      | 1684/4203 [19:00<30:14,  1.39it/s][codecarbon INFO @ 10:38:42] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.857246264 W\n",
            "[codecarbon INFO @ 10:38:42] Energy consumed for All CPU : 0.003940 kWh\n",
            "[codecarbon INFO @ 10:38:42] Energy consumed for all GPUs : 0.072514 kWh. Total GPU Power : 229.05522516272197 W\n",
            "[codecarbon INFO @ 10:38:42] 0.088093 kWh of electricity used since the beginning.\n",
            "Inferindo:  41%|████      | 1705/4203 [19:14<27:26,  1.52it/s][codecarbon INFO @ 10:38:57] Energy consumed for RAM : 0.011792 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 10:38:57] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.8548176248 W\n",
            "[codecarbon INFO @ 10:38:57] Energy consumed for All CPU : 0.003992 kWh\n",
            "[codecarbon INFO @ 10:38:57] Energy consumed for all GPUs : 0.073466 kWh. Total GPU Power : 228.57959385595345 W\n",
            "[codecarbon INFO @ 10:38:57] 0.089250 kWh of electricity used since the beginning.\n",
            "Inferindo:  41%|████      | 1725/4203 [19:29<32:04,  1.29it/s][codecarbon INFO @ 10:39:12] Energy consumed for RAM : 0.011945 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  41%|████      | 1726/4203 [19:30<30:33,  1.35it/s][codecarbon INFO @ 10:39:12] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.861853032800001 W\n",
            "[codecarbon INFO @ 10:39:12] Energy consumed for All CPU : 0.004044 kWh\n",
            "[codecarbon INFO @ 10:39:12] Energy consumed for all GPUs : 0.074419 kWh. Total GPU Power : 228.82090356600418 W\n",
            "[codecarbon INFO @ 10:39:12] 0.090408 kWh of electricity used since the beginning.\n",
            "Inferindo:  42%|████▏     | 1748/4203 [19:44<30:13,  1.35it/s][codecarbon INFO @ 10:39:27] Energy consumed for RAM : 0.012098 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 10:39:27] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.863150962400002 W\n",
            "[codecarbon INFO @ 10:39:27] Energy consumed for All CPU : 0.004096 kWh\n",
            "[codecarbon INFO @ 10:39:28] Energy consumed for all GPUs : 0.075370 kWh. Total GPU Power : 228.35527227627992 W\n",
            "[codecarbon INFO @ 10:39:28] 0.091564 kWh of electricity used since the beginning.\n",
            "Inferindo:  42%|████▏     | 1769/4203 [19:59<29:01,  1.40it/s][codecarbon INFO @ 10:39:42] Energy consumed for RAM : 0.012251 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  42%|████▏     | 1770/4203 [20:00<28:59,  1.40it/s][codecarbon INFO @ 10:39:42] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.865723090400001 W\n",
            "[codecarbon INFO @ 10:39:42] Energy consumed for All CPU : 0.004147 kWh\n",
            "[codecarbon INFO @ 10:39:43] Energy consumed for all GPUs : 0.076322 kWh. Total GPU Power : 228.3206144109248 W\n",
            "[codecarbon INFO @ 10:39:43] 0.092720 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 10:39:43] 0.007591 g.CO2eq/s mean an estimation of 239.3765217599784 kg.CO2eq/year\n",
            "Inferindo:  43%|████▎     | 1792/4203 [20:14<23:42,  1.70it/s][codecarbon INFO @ 10:39:57] Energy consumed for RAM : 0.012404 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 10:39:57] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.861297819200002 W\n",
            "[codecarbon INFO @ 10:39:57] Energy consumed for All CPU : 0.004199 kWh\n",
            "[codecarbon INFO @ 10:39:58] Energy consumed for all GPUs : 0.077270 kWh. Total GPU Power : 227.6910899133085 W\n",
            "[codecarbon INFO @ 10:39:58] 0.093873 kWh of electricity used since the beginning.\n",
            "Inferindo:  43%|████▎     | 1815/4203 [20:29<24:28,  1.63it/s][codecarbon INFO @ 10:40:12] Energy consumed for RAM : 0.012557 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  43%|████▎     | 1816/4203 [20:30<24:03,  1.65it/s][codecarbon INFO @ 10:40:12] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.862925775200003 W\n",
            "[codecarbon INFO @ 10:40:12] Energy consumed for All CPU : 0.004251 kWh\n",
            "[codecarbon INFO @ 10:40:13] Energy consumed for all GPUs : 0.078230 kWh. Total GPU Power : 230.30194679593808 W\n",
            "[codecarbon INFO @ 10:40:13] 0.095037 kWh of electricity used since the beginning.\n",
            "Inferindo:  44%|████▎     | 1838/4203 [20:44<28:01,  1.41it/s][codecarbon INFO @ 10:40:27] Energy consumed for RAM : 0.012710 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  44%|████▍     | 1839/4203 [20:45<27:47,  1.42it/s][codecarbon INFO @ 10:40:27] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.855957024799999 W\n",
            "[codecarbon INFO @ 10:40:27] Energy consumed for All CPU : 0.004303 kWh\n",
            "[codecarbon INFO @ 10:40:28] Energy consumed for all GPUs : 0.079184 kWh. Total GPU Power : 229.00352587308464 W\n",
            "[codecarbon INFO @ 10:40:28] 0.096196 kWh of electricity used since the beginning.\n",
            "Inferindo:  44%|████▍     | 1860/4203 [20:59<26:27,  1.48it/s][codecarbon INFO @ 10:40:42] Energy consumed for RAM : 0.012863 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  44%|████▍     | 1861/4203 [21:00<30:14,  1.29it/s][codecarbon INFO @ 10:40:42] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.849326206400002 W\n",
            "[codecarbon INFO @ 10:40:42] Energy consumed for All CPU : 0.004355 kWh\n",
            "[codecarbon INFO @ 10:40:43] Energy consumed for all GPUs : 0.080134 kWh. Total GPU Power : 228.2368898164433 W\n",
            "[codecarbon INFO @ 10:40:43] 0.097351 kWh of electricity used since the beginning.\n",
            "Inferindo:  45%|████▍     | 1883/4203 [21:14<26:31,  1.46it/s][codecarbon INFO @ 10:40:57] Energy consumed for RAM : 0.013016 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  45%|████▍     | 1884/4203 [21:15<25:18,  1.53it/s][codecarbon INFO @ 10:40:57] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.850643259200003 W\n",
            "[codecarbon INFO @ 10:40:57] Energy consumed for All CPU : 0.004406 kWh\n",
            "[codecarbon INFO @ 10:40:58] Energy consumed for all GPUs : 0.081085 kWh. Total GPU Power : 228.1181522527566 W\n",
            "[codecarbon INFO @ 10:40:58] 0.098507 kWh of electricity used since the beginning.\n",
            "Inferindo:  45%|████▌     | 1906/4203 [21:29<23:55,  1.60it/s][codecarbon INFO @ 10:41:12] Energy consumed for RAM : 0.013169 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  45%|████▌     | 1907/4203 [21:30<22:49,  1.68it/s][codecarbon INFO @ 10:41:12] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.856257020000005 W\n",
            "[codecarbon INFO @ 10:41:12] Energy consumed for All CPU : 0.004458 kWh\n",
            "[codecarbon INFO @ 10:41:13] Energy consumed for all GPUs : 0.082040 kWh. Total GPU Power : 229.29301220288863 W\n",
            "[codecarbon INFO @ 10:41:13] 0.099667 kWh of electricity used since the beginning.\n",
            "Inferindo:  46%|████▌     | 1930/4203 [21:44<22:34,  1.68it/s][codecarbon INFO @ 10:41:27] Energy consumed for RAM : 0.013322 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  46%|████▌     | 1931/4203 [21:45<22:13,  1.70it/s][codecarbon INFO @ 10:41:27] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.849551940800001 W\n",
            "[codecarbon INFO @ 10:41:27] Energy consumed for All CPU : 0.004510 kWh\n",
            "[codecarbon INFO @ 10:41:28] Energy consumed for all GPUs : 0.082993 kWh. Total GPU Power : 228.89514436708478 W\n",
            "[codecarbon INFO @ 10:41:28] 0.100825 kWh of electricity used since the beginning.\n",
            "Inferindo:  46%|████▋     | 1953/4203 [22:00<20:55,  1.79it/s][codecarbon INFO @ 10:41:42] Energy consumed for RAM : 0.013475 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 10:41:43] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.8485102376 W\n",
            "[codecarbon INFO @ 10:41:43] Energy consumed for All CPU : 0.004562 kWh\n",
            "[codecarbon INFO @ 10:41:43] Energy consumed for all GPUs : 0.083946 kWh. Total GPU Power : 228.61531911444607 W\n",
            "[codecarbon INFO @ 10:41:43] 0.101982 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 10:41:43] 0.007591 g.CO2eq/s mean an estimation of 239.3872370149289 kg.CO2eq/year\n",
            "Inferindo:  47%|████▋     | 1975/4203 [22:14<25:51,  1.44it/s][codecarbon INFO @ 10:41:57] Energy consumed for RAM : 0.013628 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  47%|████▋     | 1976/4203 [22:15<27:19,  1.36it/s][codecarbon INFO @ 10:41:58] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.8519371784 W\n",
            "[codecarbon INFO @ 10:41:58] Energy consumed for All CPU : 0.004613 kWh\n",
            "[codecarbon INFO @ 10:41:58] Energy consumed for all GPUs : 0.084900 kWh. Total GPU Power : 229.00648969194998 W\n",
            "[codecarbon INFO @ 10:41:58] 0.103141 kWh of electricity used since the beginning.\n",
            "Inferindo:  48%|████▊     | 1997/4203 [22:29<24:42,  1.49it/s][codecarbon INFO @ 10:42:12] Energy consumed for RAM : 0.013781 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  48%|████▊     | 1998/4203 [22:30<25:33,  1.44it/s][codecarbon INFO @ 10:42:13] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.846895364 W\n",
            "[codecarbon INFO @ 10:42:13] Energy consumed for All CPU : 0.004665 kWh\n",
            "[codecarbon INFO @ 10:42:13] Energy consumed for all GPUs : 0.085851 kWh. Total GPU Power : 228.2452927722133 W\n",
            "[codecarbon INFO @ 10:42:13] 0.104297 kWh of electricity used since the beginning.\n",
            "Inferindo:  48%|████▊     | 2019/4203 [22:44<24:45,  1.47it/s][codecarbon INFO @ 10:42:27] Energy consumed for RAM : 0.013934 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  48%|████▊     | 2020/4203 [22:45<23:32,  1.55it/s][codecarbon INFO @ 10:42:28] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.8451506456 W\n",
            "[codecarbon INFO @ 10:42:28] Energy consumed for All CPU : 0.004717 kWh\n",
            "[codecarbon INFO @ 10:42:28] Energy consumed for all GPUs : 0.086798 kWh. Total GPU Power : 227.44249068582278 W\n",
            "[codecarbon INFO @ 10:42:28] 0.105449 kWh of electricity used since the beginning.\n",
            "Inferindo:  49%|████▊     | 2042/4203 [22:59<23:25,  1.54it/s][codecarbon INFO @ 10:42:42] Energy consumed for RAM : 0.014087 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  49%|████▊     | 2043/4203 [23:00<24:35,  1.46it/s][codecarbon INFO @ 10:42:43] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.848165818400004 W\n",
            "[codecarbon INFO @ 10:42:43] Energy consumed for All CPU : 0.004768 kWh\n",
            "[codecarbon INFO @ 10:42:43] Energy consumed for all GPUs : 0.087744 kWh. Total GPU Power : 227.1319091640313 W\n",
            "[codecarbon INFO @ 10:42:43] 0.106600 kWh of electricity used since the beginning.\n",
            "Inferindo:  49%|████▉     | 2065/4203 [23:14<24:51,  1.43it/s][codecarbon INFO @ 10:42:57] Energy consumed for RAM : 0.014240 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 10:42:58] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.847338840799999 W\n",
            "[codecarbon INFO @ 10:42:58] Energy consumed for All CPU : 0.004820 kWh\n",
            "[codecarbon INFO @ 10:42:58] Energy consumed for all GPUs : 0.088700 kWh. Total GPU Power : 229.25243985449436 W\n",
            "[codecarbon INFO @ 10:42:58] 0.107760 kWh of electricity used since the beginning.\n",
            "Inferindo:  50%|████▉     | 2087/4203 [23:29<22:48,  1.55it/s][codecarbon INFO @ 10:43:12] Energy consumed for RAM : 0.014393 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 10:43:13] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.849966567200003 W\n",
            "[codecarbon INFO @ 10:43:13] Energy consumed for All CPU : 0.004872 kWh\n",
            "[codecarbon INFO @ 10:43:13] Energy consumed for all GPUs : 0.089653 kWh. Total GPU Power : 228.9390690981616 W\n",
            "[codecarbon INFO @ 10:43:13] 0.108918 kWh of electricity used since the beginning.\n",
            "Inferindo:  50%|█████     | 2109/4203 [23:44<22:08,  1.58it/s][codecarbon INFO @ 10:43:27] Energy consumed for RAM : 0.014546 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 10:43:28] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.8432910368 W\n",
            "[codecarbon INFO @ 10:43:28] Energy consumed for All CPU : 0.004924 kWh\n",
            "[codecarbon INFO @ 10:43:28] Energy consumed for all GPUs : 0.090605 kWh. Total GPU Power : 228.40563618354616 W\n",
            "[codecarbon INFO @ 10:43:28] 0.110074 kWh of electricity used since the beginning.\n",
            "Inferindo:  51%|█████     | 2130/4203 [23:59<25:48,  1.34it/s][codecarbon INFO @ 10:43:42] Energy consumed for RAM : 0.014699 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  51%|█████     | 2131/4203 [24:00<24:54,  1.39it/s][codecarbon INFO @ 10:43:43] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.8449207568 W\n",
            "[codecarbon INFO @ 10:43:43] Energy consumed for All CPU : 0.004975 kWh\n",
            "[codecarbon INFO @ 10:43:43] Energy consumed for all GPUs : 0.091559 kWh. Total GPU Power : 229.12866339592838 W\n",
            "[codecarbon INFO @ 10:43:43] 0.111233 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 10:43:43] 0.007582 g.CO2eq/s mean an estimation of 239.10427637355372 kg.CO2eq/year\n",
            "Inferindo:  51%|█████     | 2152/4203 [24:14<22:18,  1.53it/s][codecarbon INFO @ 10:43:57] Energy consumed for RAM : 0.014852 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  51%|█████     | 2153/4203 [24:15<22:44,  1.50it/s][codecarbon INFO @ 10:43:58] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.854870631200003 W\n",
            "[codecarbon INFO @ 10:43:58] Energy consumed for All CPU : 0.005027 kWh\n",
            "[codecarbon INFO @ 10:43:58] Energy consumed for all GPUs : 0.092514 kWh. Total GPU Power : 229.1368349835694 W\n",
            "[codecarbon INFO @ 10:43:58] 0.112393 kWh of electricity used since the beginning.\n",
            "Inferindo:  52%|█████▏    | 2175/4203 [24:29<24:28,  1.38it/s][codecarbon INFO @ 10:44:12] Energy consumed for RAM : 0.015005 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  52%|█████▏    | 2176/4203 [24:30<22:52,  1.48it/s][codecarbon INFO @ 10:44:13] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.846001462400002 W\n",
            "[codecarbon INFO @ 10:44:13] Energy consumed for All CPU : 0.005079 kWh\n",
            "[codecarbon INFO @ 10:44:13] Energy consumed for all GPUs : 0.093465 kWh. Total GPU Power : 228.28683261991242 W\n",
            "[codecarbon INFO @ 10:44:13] 0.113549 kWh of electricity used since the beginning.\n",
            "Inferindo:  52%|█████▏    | 2198/4203 [24:44<19:00,  1.76it/s][codecarbon INFO @ 10:44:27] Energy consumed for RAM : 0.015158 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  52%|█████▏    | 2199/4203 [24:45<20:22,  1.64it/s][codecarbon INFO @ 10:44:28] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.843829762400002 W\n",
            "[codecarbon INFO @ 10:44:28] Energy consumed for All CPU : 0.005131 kWh\n",
            "[codecarbon INFO @ 10:44:28] Energy consumed for all GPUs : 0.094416 kWh. Total GPU Power : 228.24574079421214 W\n",
            "[codecarbon INFO @ 10:44:28] 0.114704 kWh of electricity used since the beginning.\n",
            "Inferindo:  53%|█████▎    | 2221/4203 [24:59<21:17,  1.55it/s][codecarbon INFO @ 10:44:42] Energy consumed for RAM : 0.015311 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  53%|█████▎    | 2222/4203 [25:00<20:45,  1.59it/s][codecarbon INFO @ 10:44:43] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.847740334400001 W\n",
            "[codecarbon INFO @ 10:44:43] Energy consumed for All CPU : 0.005182 kWh\n",
            "[codecarbon INFO @ 10:44:43] Energy consumed for all GPUs : 0.095372 kWh. Total GPU Power : 229.3944782679388 W\n",
            "[codecarbon INFO @ 10:44:43] 0.115865 kWh of electricity used since the beginning.\n",
            "Inferindo:  53%|█████▎    | 2244/4203 [25:15<21:21,  1.53it/s][codecarbon INFO @ 10:44:57] Energy consumed for RAM : 0.015464 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 10:44:58] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.846125388800003 W\n",
            "[codecarbon INFO @ 10:44:58] Energy consumed for All CPU : 0.005234 kWh\n",
            "[codecarbon INFO @ 10:44:58] Energy consumed for all GPUs : 0.096325 kWh. Total GPU Power : 228.82054901358183 W\n",
            "[codecarbon INFO @ 10:44:58] 0.117023 kWh of electricity used since the beginning.\n",
            "Inferindo:  54%|█████▍    | 2265/4203 [25:29<20:55,  1.54it/s][codecarbon INFO @ 10:45:12] Energy consumed for RAM : 0.015617 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  54%|█████▍    | 2266/4203 [25:30<22:46,  1.42it/s][codecarbon INFO @ 10:45:13] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.845973828800002 W\n",
            "[codecarbon INFO @ 10:45:13] Energy consumed for All CPU : 0.005286 kWh\n",
            "[codecarbon INFO @ 10:45:13] Energy consumed for all GPUs : 0.097282 kWh. Total GPU Power : 229.82239900534702 W\n",
            "[codecarbon INFO @ 10:45:13] 0.118185 kWh of electricity used since the beginning.\n",
            "Inferindo:  54%|█████▍    | 2286/4203 [25:44<23:40,  1.35it/s][codecarbon INFO @ 10:45:27] Energy consumed for RAM : 0.015770 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  54%|█████▍    | 2287/4203 [25:45<23:23,  1.37it/s][codecarbon INFO @ 10:45:28] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.8459315144 W\n",
            "[codecarbon INFO @ 10:45:28] Energy consumed for All CPU : 0.005338 kWh\n",
            "[codecarbon INFO @ 10:45:28] Energy consumed for all GPUs : 0.098237 kWh. Total GPU Power : 229.14645579616854 W\n",
            "[codecarbon INFO @ 10:45:28] 0.119344 kWh of electricity used since the beginning.\n",
            "Inferindo:  55%|█████▍    | 2307/4203 [25:59<23:19,  1.35it/s][codecarbon INFO @ 10:45:42] Energy consumed for RAM : 0.015923 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  55%|█████▍    | 2308/4203 [26:00<22:21,  1.41it/s][codecarbon INFO @ 10:45:43] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.843641748800003 W\n",
            "[codecarbon INFO @ 10:45:43] Energy consumed for All CPU : 0.005389 kWh\n",
            "[codecarbon INFO @ 10:45:43] Energy consumed for all GPUs : 0.099191 kWh. Total GPU Power : 229.0184634872312 W\n",
            "[codecarbon INFO @ 10:45:43] 0.120503 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 10:45:43] 0.007597 g.CO2eq/s mean an estimation of 239.5707571865395 kg.CO2eq/year\n",
            "Inferindo:  55%|█████▌    | 2328/4203 [26:14<22:49,  1.37it/s][codecarbon INFO @ 10:45:57] Energy consumed for RAM : 0.016076 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  55%|█████▌    | 2329/4203 [26:15<22:38,  1.38it/s][codecarbon INFO @ 10:45:58] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.849579120799998 W\n",
            "[codecarbon INFO @ 10:45:58] Energy consumed for All CPU : 0.005441 kWh\n",
            "[codecarbon INFO @ 10:45:58] Energy consumed for all GPUs : 0.100143 kWh. Total GPU Power : 228.37352044970285 W\n",
            "[codecarbon INFO @ 10:45:58] 0.121659 kWh of electricity used since the beginning.\n",
            "Inferindo:  56%|█████▌    | 2351/4203 [26:29<21:40,  1.42it/s][codecarbon INFO @ 10:46:12] Energy consumed for RAM : 0.016229 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 10:46:13] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.841971536000003 W\n",
            "[codecarbon INFO @ 10:46:13] Energy consumed for All CPU : 0.005493 kWh\n",
            "[codecarbon INFO @ 10:46:13] Energy consumed for all GPUs : 0.101095 kWh. Total GPU Power : 228.67298499804878 W\n",
            "[codecarbon INFO @ 10:46:13] 0.122817 kWh of electricity used since the beginning.\n",
            "Inferindo:  56%|█████▋    | 2372/4203 [26:44<18:58,  1.61it/s][codecarbon INFO @ 10:46:27] Energy consumed for RAM : 0.016382 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  56%|█████▋    | 2374/4203 [26:45<19:05,  1.60it/s][codecarbon INFO @ 10:46:28] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.849034743199999 W\n",
            "[codecarbon INFO @ 10:46:28] Energy consumed for All CPU : 0.005544 kWh\n",
            "[codecarbon INFO @ 10:46:28] Energy consumed for all GPUs : 0.102051 kWh. Total GPU Power : 229.45346433943413 W\n",
            "[codecarbon INFO @ 10:46:28] 0.123977 kWh of electricity used since the beginning.\n",
            "Inferindo:  57%|█████▋    | 2396/4203 [27:00<16:47,  1.79it/s][codecarbon INFO @ 10:46:42] Energy consumed for RAM : 0.016535 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 10:46:43] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.847183810400002 W\n",
            "[codecarbon INFO @ 10:46:43] Energy consumed for All CPU : 0.005596 kWh\n",
            "[codecarbon INFO @ 10:46:43] Energy consumed for all GPUs : 0.103005 kWh. Total GPU Power : 229.08873077617469 W\n",
            "[codecarbon INFO @ 10:46:43] 0.125136 kWh of electricity used since the beginning.\n",
            "Inferindo:  58%|█████▊    | 2418/4203 [27:14<19:53,  1.50it/s][codecarbon INFO @ 10:46:57] Energy consumed for RAM : 0.016688 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  58%|█████▊    | 2419/4203 [27:15<19:36,  1.52it/s][codecarbon INFO @ 10:46:58] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.8429281712 W\n",
            "[codecarbon INFO @ 10:46:58] Energy consumed for All CPU : 0.005648 kWh\n",
            "[codecarbon INFO @ 10:46:58] Energy consumed for all GPUs : 0.103957 kWh. Total GPU Power : 228.36988539854323 W\n",
            "[codecarbon INFO @ 10:46:58] 0.126292 kWh of electricity used since the beginning.\n",
            "Inferindo:  58%|█████▊    | 2438/4203 [27:29<20:07,  1.46it/s][codecarbon INFO @ 10:47:12] Energy consumed for RAM : 0.016841 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  58%|█████▊    | 2439/4203 [27:30<21:25,  1.37it/s][codecarbon INFO @ 10:47:13] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.845250164 W\n",
            "[codecarbon INFO @ 10:47:13] Energy consumed for All CPU : 0.005700 kWh\n",
            "[codecarbon INFO @ 10:47:13] Energy consumed for all GPUs : 0.104908 kWh. Total GPU Power : 228.4183432639648 W\n",
            "[codecarbon INFO @ 10:47:13] 0.127449 kWh of electricity used since the beginning.\n",
            "Inferindo:  59%|█████▊    | 2461/4203 [27:44<22:12,  1.31it/s][codecarbon INFO @ 10:47:27] Energy consumed for RAM : 0.016994 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  59%|█████▊    | 2462/4203 [27:45<21:15,  1.36it/s][codecarbon INFO @ 10:47:28] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.854668246400001 W\n",
            "[codecarbon INFO @ 10:47:28] Energy consumed for All CPU : 0.005751 kWh\n",
            "[codecarbon INFO @ 10:47:28] Energy consumed for all GPUs : 0.105861 kWh. Total GPU Power : 228.7659044025464 W\n",
            "[codecarbon INFO @ 10:47:28] 0.128606 kWh of electricity used since the beginning.\n",
            "Inferindo:  59%|█████▉    | 2483/4203 [27:59<18:41,  1.53it/s][codecarbon INFO @ 10:47:42] Energy consumed for RAM : 0.017147 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  59%|█████▉    | 2484/4203 [28:00<18:43,  1.53it/s][codecarbon INFO @ 10:47:43] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.845537263999999 W\n",
            "[codecarbon INFO @ 10:47:43] Energy consumed for All CPU : 0.005803 kWh\n",
            "[codecarbon INFO @ 10:47:43] Energy consumed for all GPUs : 0.106813 kWh. Total GPU Power : 228.4456112776496 W\n",
            "[codecarbon INFO @ 10:47:43] 0.129763 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 10:47:43] 0.007589 g.CO2eq/s mean an estimation of 239.3175498239437 kg.CO2eq/year\n",
            "Inferindo:  60%|█████▉    | 2504/4203 [28:14<19:26,  1.46it/s][codecarbon INFO @ 10:47:57] Energy consumed for RAM : 0.017300 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  60%|█████▉    | 2505/4203 [28:15<21:39,  1.31it/s][codecarbon INFO @ 10:47:58] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.842546038400004 W\n",
            "[codecarbon INFO @ 10:47:58] Energy consumed for All CPU : 0.005855 kWh\n",
            "[codecarbon INFO @ 10:47:58] Energy consumed for all GPUs : 0.107765 kWh. Total GPU Power : 228.50884941586668 W\n",
            "[codecarbon INFO @ 10:47:58] 0.130920 kWh of electricity used since the beginning.\n",
            "Inferindo:  60%|██████    | 2528/4203 [28:29<18:52,  1.48it/s][codecarbon INFO @ 10:48:12] Energy consumed for RAM : 0.017453 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  60%|██████    | 2529/4203 [28:30<17:41,  1.58it/s][codecarbon INFO @ 10:48:13] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.842749712 W\n",
            "[codecarbon INFO @ 10:48:13] Energy consumed for All CPU : 0.005906 kWh\n",
            "[codecarbon INFO @ 10:48:13] Energy consumed for all GPUs : 0.108719 kWh. Total GPU Power : 228.99209062157988 W\n",
            "[codecarbon INFO @ 10:48:13] 0.132078 kWh of electricity used since the beginning.\n",
            "Inferindo:  61%|██████    | 2551/4203 [28:44<20:04,  1.37it/s][codecarbon INFO @ 10:48:27] Energy consumed for RAM : 0.017606 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  61%|██████    | 2552/4203 [28:45<19:48,  1.39it/s][codecarbon INFO @ 10:48:28] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.850614538399999 W\n",
            "[codecarbon INFO @ 10:48:28] Energy consumed for All CPU : 0.005958 kWh\n",
            "[codecarbon INFO @ 10:48:28] Energy consumed for all GPUs : 0.109672 kWh. Total GPU Power : 228.68645368268233 W\n",
            "[codecarbon INFO @ 10:48:28] 0.133236 kWh of electricity used since the beginning.\n",
            "Inferindo:  61%|██████    | 2574/4203 [28:59<18:41,  1.45it/s][codecarbon INFO @ 10:48:42] Energy consumed for RAM : 0.017759 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 10:48:43] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.847181492 W\n",
            "[codecarbon INFO @ 10:48:43] Energy consumed for All CPU : 0.006010 kWh\n",
            "[codecarbon INFO @ 10:48:43] Energy consumed for all GPUs : 0.110624 kWh. Total GPU Power : 228.4921459232755 W\n",
            "[codecarbon INFO @ 10:48:43] 0.134392 kWh of electricity used since the beginning.\n",
            "Inferindo:  62%|██████▏   | 2595/4203 [29:14<17:14,  1.55it/s][codecarbon INFO @ 10:48:57] Energy consumed for RAM : 0.017912 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  62%|██████▏   | 2596/4203 [29:15<19:09,  1.40it/s][codecarbon INFO @ 10:48:58] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.8435176784 W\n",
            "[codecarbon INFO @ 10:48:58] Energy consumed for All CPU : 0.006062 kWh\n",
            "[codecarbon INFO @ 10:48:58] Energy consumed for all GPUs : 0.111577 kWh. Total GPU Power : 228.76186352045994 W\n",
            "[codecarbon INFO @ 10:48:58] 0.135550 kWh of electricity used since the beginning.\n",
            "Inferindo:  62%|██████▏   | 2618/4203 [29:29<17:27,  1.51it/s][codecarbon INFO @ 10:49:12] Energy consumed for RAM : 0.018065 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  62%|██████▏   | 2619/4203 [29:30<16:26,  1.61it/s][codecarbon INFO @ 10:49:13] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.866128270400004 W\n",
            "[codecarbon INFO @ 10:49:13] Energy consumed for All CPU : 0.006113 kWh\n",
            "[codecarbon INFO @ 10:49:13] Energy consumed for all GPUs : 0.112530 kWh. Total GPU Power : 228.8083787344808 W\n",
            "[codecarbon INFO @ 10:49:13] 0.136708 kWh of electricity used since the beginning.\n",
            "Inferindo:  63%|██████▎   | 2640/4203 [29:44<17:47,  1.46it/s][codecarbon INFO @ 10:49:27] Energy consumed for RAM : 0.018218 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  63%|██████▎   | 2641/4203 [29:45<17:20,  1.50it/s][codecarbon INFO @ 10:49:28] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.8415819728 W\n",
            "[codecarbon INFO @ 10:49:28] Energy consumed for All CPU : 0.006165 kWh\n",
            "[codecarbon INFO @ 10:49:28] Energy consumed for all GPUs : 0.113484 kWh. Total GPU Power : 229.0032381420314 W\n",
            "[codecarbon INFO @ 10:49:28] 0.137867 kWh of electricity used since the beginning.\n",
            "Inferindo:  63%|██████▎   | 2662/4203 [29:59<16:18,  1.58it/s][codecarbon INFO @ 10:49:42] Energy consumed for RAM : 0.018371 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  63%|██████▎   | 2663/4203 [30:00<17:53,  1.43it/s][codecarbon INFO @ 10:49:43] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.882820368800003 W\n",
            "[codecarbon INFO @ 10:49:43] Energy consumed for All CPU : 0.006217 kWh\n",
            "[codecarbon INFO @ 10:49:43] Energy consumed for all GPUs : 0.114436 kWh. Total GPU Power : 228.5696047838632 W\n",
            "[codecarbon INFO @ 10:49:43] 0.139024 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 10:49:43] 0.007590 g.CO2eq/s mean an estimation of 239.35713447782513 kg.CO2eq/year\n",
            "Inferindo:  64%|██████▍   | 2685/4203 [30:14<16:41,  1.52it/s][codecarbon INFO @ 10:49:57] Energy consumed for RAM : 0.018524 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  64%|██████▍   | 2686/4203 [30:15<16:39,  1.52it/s][codecarbon INFO @ 10:49:58] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.849893227999997 W\n",
            "[codecarbon INFO @ 10:49:58] Energy consumed for All CPU : 0.006269 kWh\n",
            "[codecarbon INFO @ 10:49:58] Energy consumed for all GPUs : 0.115396 kWh. Total GPU Power : 230.34801612744772 W\n",
            "[codecarbon INFO @ 10:49:58] 0.140189 kWh of electricity used since the beginning.\n",
            "Inferindo:  64%|██████▍   | 2709/4203 [30:29<16:13,  1.53it/s][codecarbon INFO @ 10:50:12] Energy consumed for RAM : 0.018677 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  64%|██████▍   | 2710/4203 [30:30<16:12,  1.53it/s][codecarbon INFO @ 10:50:13] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.852294939200002 W\n",
            "[codecarbon INFO @ 10:50:13] Energy consumed for All CPU : 0.006321 kWh\n",
            "[codecarbon INFO @ 10:50:13] Energy consumed for all GPUs : 0.116349 kWh. Total GPU Power : 228.91132498458632 W\n",
            "[codecarbon INFO @ 10:50:13] 0.141347 kWh of electricity used since the beginning.\n",
            "Inferindo:  65%|██████▌   | 2733/4203 [30:44<14:55,  1.64it/s][codecarbon INFO @ 10:50:27] Energy consumed for RAM : 0.018830 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  65%|██████▌   | 2734/4203 [30:45<16:15,  1.51it/s][codecarbon INFO @ 10:50:28] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.842240391200002 W\n",
            "[codecarbon INFO @ 10:50:28] Energy consumed for All CPU : 0.006372 kWh\n",
            "[codecarbon INFO @ 10:50:28] Energy consumed for all GPUs : 0.117303 kWh. Total GPU Power : 228.8435809367111 W\n",
            "[codecarbon INFO @ 10:50:28] 0.142505 kWh of electricity used since the beginning.\n",
            "Inferindo:  66%|██████▌   | 2756/4203 [30:59<17:10,  1.40it/s][codecarbon INFO @ 10:50:42] Energy consumed for RAM : 0.018983 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  66%|██████▌   | 2757/4203 [31:00<16:47,  1.44it/s][codecarbon INFO @ 10:50:43] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.840997692800004 W\n",
            "[codecarbon INFO @ 10:50:43] Energy consumed for All CPU : 0.006424 kWh\n",
            "[codecarbon INFO @ 10:50:43] Energy consumed for all GPUs : 0.118256 kWh. Total GPU Power : 228.78848261765359 W\n",
            "[codecarbon INFO @ 10:50:43] 0.143663 kWh of electricity used since the beginning.\n",
            "Inferindo:  66%|██████▌   | 2778/4203 [31:14<15:36,  1.52it/s][codecarbon INFO @ 10:50:57] Energy consumed for RAM : 0.019136 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  66%|██████▌   | 2779/4203 [31:15<15:09,  1.56it/s][codecarbon INFO @ 10:50:58] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.8490477536 W\n",
            "[codecarbon INFO @ 10:50:58] Energy consumed for All CPU : 0.006476 kWh\n",
            "[codecarbon INFO @ 10:50:58] Energy consumed for all GPUs : 0.119209 kWh. Total GPU Power : 228.7884021056122 W\n",
            "[codecarbon INFO @ 10:50:58] 0.144821 kWh of electricity used since the beginning.\n",
            "Inferindo:  67%|██████▋   | 2801/4203 [31:29<16:15,  1.44it/s][codecarbon INFO @ 10:51:12] Energy consumed for RAM : 0.019289 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  67%|██████▋   | 2802/4203 [31:30<15:44,  1.48it/s][codecarbon INFO @ 10:51:13] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.852692760800004 W\n",
            "[codecarbon INFO @ 10:51:13] Energy consumed for All CPU : 0.006527 kWh\n",
            "[codecarbon INFO @ 10:51:13] Energy consumed for all GPUs : 0.120163 kWh. Total GPU Power : 228.97730903782235 W\n",
            "[codecarbon INFO @ 10:51:13] 0.145979 kWh of electricity used since the beginning.\n",
            "Inferindo:  67%|██████▋   | 2823/4203 [31:44<15:13,  1.51it/s][codecarbon INFO @ 10:51:27] Energy consumed for RAM : 0.019442 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  67%|██████▋   | 2824/4203 [31:45<15:26,  1.49it/s][codecarbon INFO @ 10:51:28] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.854106812 W\n",
            "[codecarbon INFO @ 10:51:28] Energy consumed for All CPU : 0.006579 kWh\n",
            "[codecarbon INFO @ 10:51:28] Energy consumed for all GPUs : 0.121118 kWh. Total GPU Power : 229.20891077069504 W\n",
            "[codecarbon INFO @ 10:51:28] 0.147139 kWh of electricity used since the beginning.\n",
            "Inferindo:  68%|██████▊   | 2847/4203 [31:59<14:39,  1.54it/s][codecarbon INFO @ 10:51:42] Energy consumed for RAM : 0.019595 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 10:51:43] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.863068702400001 W\n",
            "[codecarbon INFO @ 10:51:43] Energy consumed for All CPU : 0.006631 kWh\n",
            "[codecarbon INFO @ 10:51:43] Energy consumed for all GPUs : 0.122072 kWh. Total GPU Power : 228.98540040253403 W\n",
            "[codecarbon INFO @ 10:51:43] 0.148298 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 10:51:43] 0.007600 g.CO2eq/s mean an estimation of 239.67576609857704 kg.CO2eq/year\n",
            "Inferindo:  68%|██████▊   | 2871/4203 [32:15<13:45,  1.61it/s][codecarbon INFO @ 10:51:57] Energy consumed for RAM : 0.019748 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  68%|██████▊   | 2872/4203 [32:15<13:01,  1.70it/s][codecarbon INFO @ 10:51:58] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.851957489600004 W\n",
            "[codecarbon INFO @ 10:51:58] Energy consumed for All CPU : 0.006683 kWh\n",
            "[codecarbon INFO @ 10:51:58] Energy consumed for all GPUs : 0.123023 kWh. Total GPU Power : 228.25445337602417 W\n",
            "[codecarbon INFO @ 10:51:58] 0.149453 kWh of electricity used since the beginning.\n",
            "Inferindo:  69%|██████▉   | 2895/4203 [32:30<13:23,  1.63it/s][codecarbon INFO @ 10:52:12] Energy consumed for RAM : 0.019901 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 10:52:13] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.848766752000001 W\n",
            "[codecarbon INFO @ 10:52:13] Energy consumed for All CPU : 0.006735 kWh\n",
            "[codecarbon INFO @ 10:52:13] Energy consumed for all GPUs : 0.123975 kWh. Total GPU Power : 228.67983331217206 W\n",
            "[codecarbon INFO @ 10:52:13] 0.150611 kWh of electricity used since the beginning.\n",
            "Inferindo:  69%|██████▉   | 2918/4203 [32:44<14:03,  1.52it/s][codecarbon INFO @ 10:52:27] Energy consumed for RAM : 0.020054 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 10:52:28] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.85852718 W\n",
            "[codecarbon INFO @ 10:52:28] Energy consumed for All CPU : 0.006786 kWh\n",
            "[codecarbon INFO @ 10:52:28] Energy consumed for all GPUs : 0.124930 kWh. Total GPU Power : 229.09747290671035 W\n",
            "[codecarbon INFO @ 10:52:28] 0.151770 kWh of electricity used since the beginning.\n",
            "Inferindo:  70%|██████▉   | 2941/4203 [32:59<13:07,  1.60it/s][codecarbon INFO @ 10:52:42] Energy consumed for RAM : 0.020207 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 10:52:43] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.8472528728 W\n",
            "[codecarbon INFO @ 10:52:43] Energy consumed for All CPU : 0.006838 kWh\n",
            "[codecarbon INFO @ 10:52:43] Energy consumed for all GPUs : 0.125883 kWh. Total GPU Power : 228.77574657693887 W\n",
            "[codecarbon INFO @ 10:52:43] 0.152928 kWh of electricity used since the beginning.\n",
            "Inferindo:  71%|███████   | 2964/4203 [33:15<14:42,  1.40it/s][codecarbon INFO @ 10:52:57] Energy consumed for RAM : 0.020360 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 10:52:58] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.853425087200003 W\n",
            "[codecarbon INFO @ 10:52:58] Energy consumed for All CPU : 0.006890 kWh\n",
            "[codecarbon INFO @ 10:52:58] Energy consumed for all GPUs : 0.126833 kWh. Total GPU Power : 228.17309304765004 W\n",
            "[codecarbon INFO @ 10:52:58] 0.154083 kWh of electricity used since the beginning.\n",
            "Inferindo:  71%|███████   | 2986/4203 [33:29<12:16,  1.65it/s][codecarbon INFO @ 10:53:12] Energy consumed for RAM : 0.020513 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  71%|███████   | 2987/4203 [33:30<12:48,  1.58it/s][codecarbon INFO @ 10:53:13] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.867341938400003 W\n",
            "[codecarbon INFO @ 10:53:13] Energy consumed for All CPU : 0.006942 kWh\n",
            "[codecarbon INFO @ 10:53:13] Energy consumed for all GPUs : 0.127786 kWh. Total GPU Power : 228.82584929662113 W\n",
            "[codecarbon INFO @ 10:53:13] 0.155241 kWh of electricity used since the beginning.\n",
            "Inferindo:  72%|███████▏  | 3010/4203 [33:44<12:21,  1.61it/s][codecarbon INFO @ 10:53:27] Energy consumed for RAM : 0.020666 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  72%|███████▏  | 3011/4203 [33:45<11:57,  1.66it/s][codecarbon INFO @ 10:53:28] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.869606878399999 W\n",
            "[codecarbon INFO @ 10:53:28] Energy consumed for All CPU : 0.006993 kWh\n",
            "[codecarbon INFO @ 10:53:28] Energy consumed for all GPUs : 0.128741 kWh. Total GPU Power : 229.04095011322497 W\n",
            "[codecarbon INFO @ 10:53:28] 0.156400 kWh of electricity used since the beginning.\n",
            "Inferindo:  72%|███████▏  | 3033/4203 [33:59<14:48,  1.32it/s][codecarbon INFO @ 10:53:42] Energy consumed for RAM : 0.020819 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 10:53:43] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.870536211200003 W\n",
            "[codecarbon INFO @ 10:53:43] Energy consumed for All CPU : 0.007045 kWh\n",
            "[codecarbon INFO @ 10:53:43] Energy consumed for all GPUs : 0.129692 kWh. Total GPU Power : 228.36224390613415 W\n",
            "[codecarbon INFO @ 10:53:43] 0.157556 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 10:53:43] 0.007588 g.CO2eq/s mean an estimation of 239.28232178505232 kg.CO2eq/year\n",
            "Inferindo:  73%|███████▎  | 3056/4203 [34:14<10:17,  1.86it/s][codecarbon INFO @ 10:53:57] Energy consumed for RAM : 0.020972 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  73%|███████▎  | 3057/4203 [34:15<11:20,  1.68it/s][codecarbon INFO @ 10:53:58] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.861423156800003 W\n",
            "[codecarbon INFO @ 10:53:58] Energy consumed for All CPU : 0.007097 kWh\n",
            "[codecarbon INFO @ 10:53:58] Energy consumed for all GPUs : 0.130643 kWh. Total GPU Power : 228.16136888829155 W\n",
            "[codecarbon INFO @ 10:53:58] 0.158711 kWh of electricity used since the beginning.\n",
            "Inferindo:  73%|███████▎  | 3080/4203 [34:29<10:33,  1.77it/s][codecarbon INFO @ 10:54:12] Energy consumed for RAM : 0.021125 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  73%|███████▎  | 3081/4203 [34:30<11:05,  1.69it/s][codecarbon INFO @ 10:54:13] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.848063657600001 W\n",
            "[codecarbon INFO @ 10:54:13] Energy consumed for All CPU : 0.007149 kWh\n",
            "[codecarbon INFO @ 10:54:13] Energy consumed for all GPUs : 0.131596 kWh. Total GPU Power : 228.94836895014558 W\n",
            "[codecarbon INFO @ 10:54:13] 0.159870 kWh of electricity used since the beginning.\n",
            "Inferindo:  74%|███████▍  | 3102/4203 [34:44<12:47,  1.43it/s][codecarbon INFO @ 10:54:27] Energy consumed for RAM : 0.021278 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  74%|███████▍  | 3103/4203 [34:45<12:08,  1.51it/s][codecarbon INFO @ 10:54:28] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.854014911200004 W\n",
            "[codecarbon INFO @ 10:54:28] Energy consumed for All CPU : 0.007201 kWh\n",
            "[codecarbon INFO @ 10:54:28] Energy consumed for all GPUs : 0.132550 kWh. Total GPU Power : 228.8310796872031 W\n",
            "[codecarbon INFO @ 10:54:28] 0.161028 kWh of electricity used since the beginning.\n",
            "Inferindo:  74%|███████▍  | 3125/4203 [34:59<11:37,  1.54it/s][codecarbon INFO @ 10:54:42] Energy consumed for RAM : 0.021431 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 10:54:43] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.8648187704 W\n",
            "[codecarbon INFO @ 10:54:43] Energy consumed for All CPU : 0.007252 kWh\n",
            "[codecarbon INFO @ 10:54:43] Energy consumed for all GPUs : 0.133503 kWh. Total GPU Power : 228.80774796661572 W\n",
            "[codecarbon INFO @ 10:54:43] 0.162186 kWh of electricity used since the beginning.\n",
            "Inferindo:  75%|███████▍  | 3148/4203 [35:14<10:40,  1.65it/s][codecarbon INFO @ 10:54:57] Energy consumed for RAM : 0.021584 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  75%|███████▍  | 3149/4203 [35:15<12:00,  1.46it/s][codecarbon INFO @ 10:54:58] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.851051830400001 W\n",
            "[codecarbon INFO @ 10:54:58] Energy consumed for All CPU : 0.007304 kWh\n",
            "[codecarbon INFO @ 10:54:58] Energy consumed for all GPUs : 0.134463 kWh. Total GPU Power : 230.46800056109086 W\n",
            "[codecarbon INFO @ 10:54:58] 0.163351 kWh of electricity used since the beginning.\n",
            "Inferindo:  75%|███████▌  | 3171/4203 [35:29<11:48,  1.46it/s][codecarbon INFO @ 10:55:12] Energy consumed for RAM : 0.021737 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 10:55:13] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.855457049600002 W\n",
            "[codecarbon INFO @ 10:55:13] Energy consumed for All CPU : 0.007356 kWh\n",
            "[codecarbon INFO @ 10:55:13] Energy consumed for all GPUs : 0.135418 kWh. Total GPU Power : 229.2651602438796 W\n",
            "[codecarbon INFO @ 10:55:13] 0.164511 kWh of electricity used since the beginning.\n",
            "Inferindo:  76%|███████▌  | 3194/4203 [35:44<09:55,  1.69it/s][codecarbon INFO @ 10:55:27] Energy consumed for RAM : 0.021890 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  76%|███████▌  | 3195/4203 [35:45<10:32,  1.59it/s][codecarbon INFO @ 10:55:28] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.840835412000002 W\n",
            "[codecarbon INFO @ 10:55:28] Energy consumed for All CPU : 0.007408 kWh\n",
            "[codecarbon INFO @ 10:55:28] Energy consumed for all GPUs : 0.136371 kWh. Total GPU Power : 228.83720015146085 W\n",
            "[codecarbon INFO @ 10:55:28] 0.165669 kWh of electricity used since the beginning.\n",
            "Inferindo:  77%|███████▋  | 3217/4203 [35:59<11:08,  1.48it/s][codecarbon INFO @ 10:55:42] Energy consumed for RAM : 0.022043 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  77%|███████▋  | 3218/4203 [36:00<10:50,  1.51it/s][codecarbon INFO @ 10:55:43] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.849029962400003 W\n",
            "[codecarbon INFO @ 10:55:43] Energy consumed for All CPU : 0.007459 kWh\n",
            "[codecarbon INFO @ 10:55:43] Energy consumed for all GPUs : 0.137323 kWh. Total GPU Power : 228.54859586074022 W\n",
            "[codecarbon INFO @ 10:55:43] 0.166826 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 10:55:43] 0.007597 g.CO2eq/s mean an estimation of 239.57202261361297 kg.CO2eq/year\n",
            "Inferindo:  77%|███████▋  | 3240/4203 [36:14<09:26,  1.70it/s][codecarbon INFO @ 10:55:57] Energy consumed for RAM : 0.022196 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  77%|███████▋  | 3241/4203 [36:15<10:25,  1.54it/s][codecarbon INFO @ 10:55:58] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.857351816000001 W\n",
            "[codecarbon INFO @ 10:55:58] Energy consumed for All CPU : 0.007511 kWh\n",
            "[codecarbon INFO @ 10:55:58] Energy consumed for all GPUs : 0.138277 kWh. Total GPU Power : 228.85245705375175 W\n",
            "[codecarbon INFO @ 10:55:58] 0.167984 kWh of electricity used since the beginning.\n",
            "Inferindo:  78%|███████▊  | 3265/4203 [36:29<09:43,  1.61it/s][codecarbon INFO @ 10:56:12] Energy consumed for RAM : 0.022349 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 10:56:13] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.868678546400002 W\n",
            "[codecarbon INFO @ 10:56:13] Energy consumed for All CPU : 0.007563 kWh\n",
            "[codecarbon INFO @ 10:56:13] Energy consumed for all GPUs : 0.139230 kWh. Total GPU Power : 228.82262275398537 W\n",
            "[codecarbon INFO @ 10:56:13] 0.169142 kWh of electricity used since the beginning.\n",
            "Inferindo:  78%|███████▊  | 3287/4203 [36:44<09:18,  1.64it/s][codecarbon INFO @ 10:56:27] Energy consumed for RAM : 0.022502 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  78%|███████▊  | 3288/4203 [36:45<09:04,  1.68it/s][codecarbon INFO @ 10:56:28] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.859638111200002 W\n",
            "[codecarbon INFO @ 10:56:28] Energy consumed for All CPU : 0.007615 kWh\n",
            "[codecarbon INFO @ 10:56:28] Energy consumed for all GPUs : 0.140181 kWh. Total GPU Power : 228.34796974685645 W\n",
            "[codecarbon INFO @ 10:56:28] 0.170298 kWh of electricity used since the beginning.\n",
            "Inferindo:  79%|███████▉  | 3310/4203 [36:59<09:08,  1.63it/s][codecarbon INFO @ 10:56:42] Energy consumed for RAM : 0.022655 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  79%|███████▉  | 3311/4203 [37:00<10:10,  1.46it/s][codecarbon INFO @ 10:56:43] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.858413261600003 W\n",
            "[codecarbon INFO @ 10:56:43] Energy consumed for All CPU : 0.007666 kWh\n",
            "[codecarbon INFO @ 10:56:43] Energy consumed for all GPUs : 0.141136 kWh. Total GPU Power : 229.23784323110772 W\n",
            "[codecarbon INFO @ 10:56:43] 0.171458 kWh of electricity used since the beginning.\n",
            "Inferindo:  79%|███████▉  | 3333/4203 [37:14<08:53,  1.63it/s][codecarbon INFO @ 10:56:57] Energy consumed for RAM : 0.022808 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  79%|███████▉  | 3334/4203 [37:15<09:05,  1.59it/s][codecarbon INFO @ 10:56:58] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.861128432000001 W\n",
            "[codecarbon INFO @ 10:56:58] Energy consumed for All CPU : 0.007718 kWh\n",
            "[codecarbon INFO @ 10:56:58] Energy consumed for all GPUs : 0.142090 kWh. Total GPU Power : 228.85399226638785 W\n",
            "[codecarbon INFO @ 10:56:58] 0.172616 kWh of electricity used since the beginning.\n",
            "Inferindo:  80%|███████▉  | 3356/4203 [37:29<09:20,  1.51it/s][codecarbon INFO @ 10:57:12] Energy consumed for RAM : 0.022961 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  80%|███████▉  | 3357/4203 [37:30<09:15,  1.52it/s][codecarbon INFO @ 10:57:13] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.870480792800002 W\n",
            "[codecarbon INFO @ 10:57:13] Energy consumed for All CPU : 0.007770 kWh\n",
            "[codecarbon INFO @ 10:57:13] Energy consumed for all GPUs : 0.143043 kWh. Total GPU Power : 228.83250953514226 W\n",
            "[codecarbon INFO @ 10:57:13] 0.173774 kWh of electricity used since the beginning.\n",
            "Inferindo:  80%|████████  | 3380/4203 [37:45<09:52,  1.39it/s][codecarbon INFO @ 10:57:27] Energy consumed for RAM : 0.023114 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 10:57:28] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.885996396800003 W\n",
            "[codecarbon INFO @ 10:57:28] Energy consumed for All CPU : 0.007822 kWh\n",
            "[codecarbon INFO @ 10:57:28] Energy consumed for all GPUs : 0.143996 kWh. Total GPU Power : 228.770989687401 W\n",
            "[codecarbon INFO @ 10:57:28] 0.174932 kWh of electricity used since the beginning.\n",
            "Inferindo:  81%|████████  | 3403/4203 [37:59<08:10,  1.63it/s][codecarbon INFO @ 10:57:42] Energy consumed for RAM : 0.023267 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  81%|████████  | 3404/4203 [38:00<08:53,  1.50it/s][codecarbon INFO @ 10:57:43] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.874798013600001 W\n",
            "[codecarbon INFO @ 10:57:43] Energy consumed for All CPU : 0.007874 kWh\n",
            "[codecarbon INFO @ 10:57:43] Energy consumed for all GPUs : 0.144949 kWh. Total GPU Power : 228.73737113303503 W\n",
            "[codecarbon INFO @ 10:57:43] 0.176090 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 10:57:43] 0.007592 g.CO2eq/s mean an estimation of 239.43314591744627 kg.CO2eq/year\n",
            "Inferindo:  82%|████████▏ | 3426/4203 [38:14<08:18,  1.56it/s][codecarbon INFO @ 10:57:57] Energy consumed for RAM : 0.023420 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  82%|████████▏ | 3427/4203 [38:15<07:56,  1.63it/s][codecarbon INFO @ 10:57:58] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.897920180000002 W\n",
            "[codecarbon INFO @ 10:57:58] Energy consumed for All CPU : 0.007926 kWh\n",
            "[codecarbon INFO @ 10:57:58] Energy consumed for all GPUs : 0.145901 kWh. Total GPU Power : 228.5512684505535 W\n",
            "[codecarbon INFO @ 10:57:58] 0.177247 kWh of electricity used since the beginning.\n",
            "Inferindo:  82%|████████▏ | 3451/4203 [38:29<07:50,  1.60it/s][codecarbon INFO @ 10:58:12] Energy consumed for RAM : 0.023573 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  82%|████████▏ | 3452/4203 [38:30<07:41,  1.63it/s][codecarbon INFO @ 10:58:13] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.875409041600003 W\n",
            "[codecarbon INFO @ 10:58:13] Energy consumed for All CPU : 0.007978 kWh\n",
            "[codecarbon INFO @ 10:58:13] Energy consumed for all GPUs : 0.146854 kWh. Total GPU Power : 228.76675474413287 W\n",
            "[codecarbon INFO @ 10:58:13] 0.178405 kWh of electricity used since the beginning.\n",
            "Inferindo:  83%|████████▎ | 3475/4203 [38:44<07:23,  1.64it/s][codecarbon INFO @ 10:58:27] Energy consumed for RAM : 0.023726 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  83%|████████▎ | 3476/4203 [38:45<07:16,  1.66it/s][codecarbon INFO @ 10:58:28] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.868203116000002 W\n",
            "[codecarbon INFO @ 10:58:28] Energy consumed for All CPU : 0.008029 kWh\n",
            "[codecarbon INFO @ 10:58:28] Energy consumed for all GPUs : 0.147807 kWh. Total GPU Power : 228.7116284124546 W\n",
            "[codecarbon INFO @ 10:58:28] 0.179562 kWh of electricity used since the beginning.\n",
            "Inferindo:  83%|████████▎ | 3498/4203 [38:59<07:52,  1.49it/s][codecarbon INFO @ 10:58:42] Energy consumed for RAM : 0.023879 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  83%|████████▎ | 3499/4203 [39:00<07:25,  1.58it/s][codecarbon INFO @ 10:58:43] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.852072214400003 W\n",
            "[codecarbon INFO @ 10:58:43] Energy consumed for All CPU : 0.008081 kWh\n",
            "[codecarbon INFO @ 10:58:43] Energy consumed for all GPUs : 0.148760 kWh. Total GPU Power : 228.64314425361044 W\n",
            "[codecarbon INFO @ 10:58:43] 0.180719 kWh of electricity used since the beginning.\n",
            "Inferindo:  84%|████████▍ | 3523/4203 [39:14<07:12,  1.57it/s][codecarbon INFO @ 10:58:57] Energy consumed for RAM : 0.024032 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  84%|████████▍ | 3524/4203 [39:15<07:15,  1.56it/s][codecarbon INFO @ 10:58:58] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.860961089600002 W\n",
            "[codecarbon INFO @ 10:58:58] Energy consumed for All CPU : 0.008133 kWh\n",
            "[codecarbon INFO @ 10:58:58] Energy consumed for all GPUs : 0.149711 kWh. Total GPU Power : 228.39539118167852 W\n",
            "[codecarbon INFO @ 10:58:58] 0.181876 kWh of electricity used since the beginning.\n",
            "Inferindo:  84%|████████▍ | 3545/4203 [39:29<07:35,  1.45it/s][codecarbon INFO @ 10:59:12] Energy consumed for RAM : 0.024185 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  84%|████████▍ | 3546/4203 [39:30<07:08,  1.53it/s][codecarbon INFO @ 10:59:13] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.870754083200005 W\n",
            "[codecarbon INFO @ 10:59:13] Energy consumed for All CPU : 0.008185 kWh\n",
            "[codecarbon INFO @ 10:59:13] Energy consumed for all GPUs : 0.150663 kWh. Total GPU Power : 228.47821598901277 W\n",
            "[codecarbon INFO @ 10:59:13] 0.183032 kWh of electricity used since the beginning.\n",
            "Inferindo:  85%|████████▍ | 3569/4203 [39:45<06:41,  1.58it/s][codecarbon INFO @ 10:59:27] Energy consumed for RAM : 0.024338 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 10:59:28] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.855937959200004 W\n",
            "[codecarbon INFO @ 10:59:28] Energy consumed for All CPU : 0.008236 kWh\n",
            "[codecarbon INFO @ 10:59:28] Energy consumed for all GPUs : 0.151617 kWh. Total GPU Power : 229.08072263952576 W\n",
            "[codecarbon INFO @ 10:59:28] 0.184192 kWh of electricity used since the beginning.\n",
            "Inferindo:  85%|████████▌ | 3592/4203 [39:59<06:40,  1.53it/s][codecarbon INFO @ 10:59:42] Energy consumed for RAM : 0.024491 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  85%|████████▌ | 3593/4203 [40:00<06:28,  1.57it/s][codecarbon INFO @ 10:59:43] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.872011786400002 W\n",
            "[codecarbon INFO @ 10:59:43] Energy consumed for All CPU : 0.008288 kWh\n",
            "[codecarbon INFO @ 10:59:43] Energy consumed for all GPUs : 0.152574 kWh. Total GPU Power : 229.77726915291373 W\n",
            "[codecarbon INFO @ 10:59:43] 0.185354 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 10:59:43] 0.007592 g.CO2eq/s mean an estimation of 239.42937424456485 kg.CO2eq/year\n",
            "Inferindo:  86%|████████▌ | 3616/4203 [40:14<05:58,  1.64it/s][codecarbon INFO @ 10:59:57] Energy consumed for RAM : 0.024644 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 10:59:58] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.935842133600001 W\n",
            "[codecarbon INFO @ 10:59:58] Energy consumed for All CPU : 0.008340 kWh\n",
            "[codecarbon INFO @ 10:59:58] Energy consumed for all GPUs : 0.153527 kWh. Total GPU Power : 228.560095882685 W\n",
            "[codecarbon INFO @ 10:59:58] 0.186511 kWh of electricity used since the beginning.\n",
            "Inferindo:  87%|████████▋ | 3639/4203 [40:30<05:36,  1.68it/s][codecarbon INFO @ 11:00:12] Energy consumed for RAM : 0.024797 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 11:00:13] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.908668541600003 W\n",
            "[codecarbon INFO @ 11:00:13] Energy consumed for All CPU : 0.008392 kWh\n",
            "[codecarbon INFO @ 11:00:13] Energy consumed for all GPUs : 0.154481 kWh. Total GPU Power : 229.03367520170147 W\n",
            "[codecarbon INFO @ 11:00:13] 0.187670 kWh of electricity used since the beginning.\n",
            "Inferindo:  87%|████████▋ | 3663/4203 [40:45<06:26,  1.40it/s][codecarbon INFO @ 11:00:27] Energy consumed for RAM : 0.024950 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  87%|████████▋ | 3664/4203 [40:45<05:42,  1.57it/s][codecarbon INFO @ 11:00:28] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.873762228800002 W\n",
            "[codecarbon INFO @ 11:00:28] Energy consumed for All CPU : 0.008444 kWh\n",
            "[codecarbon INFO @ 11:00:28] Energy consumed for all GPUs : 0.155434 kWh. Total GPU Power : 228.71944702616995 W\n",
            "[codecarbon INFO @ 11:00:28] 0.188828 kWh of electricity used since the beginning.\n",
            "Inferindo:  88%|████████▊ | 3686/4203 [40:59<06:10,  1.40it/s][codecarbon INFO @ 11:00:42] Energy consumed for RAM : 0.025103 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  88%|████████▊ | 3687/4203 [41:00<05:44,  1.50it/s][codecarbon INFO @ 11:00:43] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.8589392 W\n",
            "[codecarbon INFO @ 11:00:43] Energy consumed for All CPU : 0.008496 kWh\n",
            "[codecarbon INFO @ 11:00:43] Energy consumed for all GPUs : 0.156386 kWh. Total GPU Power : 228.62510842165761 W\n",
            "[codecarbon INFO @ 11:00:43] 0.189985 kWh of electricity used since the beginning.\n",
            "Inferindo:  88%|████████▊ | 3709/4203 [41:14<05:25,  1.52it/s][codecarbon INFO @ 11:00:57] Energy consumed for RAM : 0.025256 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  88%|████████▊ | 3710/4203 [41:15<05:40,  1.45it/s][codecarbon INFO @ 11:00:58] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.860999156000002 W\n",
            "[codecarbon INFO @ 11:00:58] Energy consumed for All CPU : 0.008548 kWh\n",
            "[codecarbon INFO @ 11:00:58] Energy consumed for all GPUs : 0.157338 kWh. Total GPU Power : 228.43980559088618 W\n",
            "[codecarbon INFO @ 11:00:58] 0.191142 kWh of electricity used since the beginning.\n",
            "Inferindo:  89%|████████▉ | 3732/4203 [41:29<05:08,  1.53it/s][codecarbon INFO @ 11:01:12] Energy consumed for RAM : 0.025409 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  89%|████████▉ | 3733/4203 [41:30<05:01,  1.56it/s][codecarbon INFO @ 11:01:13] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.870349421600002 W\n",
            "[codecarbon INFO @ 11:01:13] Energy consumed for All CPU : 0.008600 kWh\n",
            "[codecarbon INFO @ 11:01:13] Energy consumed for all GPUs : 0.158294 kWh. Total GPU Power : 229.53362242804837 W\n",
            "[codecarbon INFO @ 11:01:13] 0.192303 kWh of electricity used since the beginning.\n",
            "Inferindo:  89%|████████▉ | 3755/4203 [41:44<05:29,  1.36it/s][codecarbon INFO @ 11:01:27] Energy consumed for RAM : 0.025562 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  89%|████████▉ | 3756/4203 [41:45<04:58,  1.50it/s][codecarbon INFO @ 11:01:28] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.842693091200003 W\n",
            "[codecarbon INFO @ 11:01:28] Energy consumed for All CPU : 0.008651 kWh\n",
            "[codecarbon INFO @ 11:01:28] Energy consumed for all GPUs : 0.159248 kWh. Total GPU Power : 229.0894619797341 W\n",
            "[codecarbon INFO @ 11:01:28] 0.193462 kWh of electricity used since the beginning.\n",
            "Inferindo:  90%|████████▉ | 3779/4203 [41:59<04:40,  1.51it/s][codecarbon INFO @ 11:01:42] Energy consumed for RAM : 0.025715 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  90%|████████▉ | 3780/4203 [42:00<04:57,  1.42it/s][codecarbon INFO @ 11:01:43] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.8476828136 W\n",
            "[codecarbon INFO @ 11:01:43] Energy consumed for All CPU : 0.008703 kWh\n",
            "[codecarbon INFO @ 11:01:43] Energy consumed for all GPUs : 0.160204 kWh. Total GPU Power : 229.24937351320256 W\n",
            "[codecarbon INFO @ 11:01:43] 0.194622 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 11:01:43] 0.007595 g.CO2eq/s mean an estimation of 239.5301733405678 kg.CO2eq/year\n",
            "Inferindo:  90%|█████████ | 3803/4203 [42:14<03:40,  1.81it/s][codecarbon INFO @ 11:01:57] Energy consumed for RAM : 0.025868 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 11:01:58] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.842017047200002 W\n",
            "[codecarbon INFO @ 11:01:58] Energy consumed for All CPU : 0.008755 kWh\n",
            "[codecarbon INFO @ 11:01:58] Energy consumed for all GPUs : 0.161157 kWh. Total GPU Power : 228.8201480564885 W\n",
            "[codecarbon INFO @ 11:01:58] 0.195780 kWh of electricity used since the beginning.\n",
            "Inferindo:  91%|█████████ | 3824/4203 [42:29<04:00,  1.58it/s][codecarbon INFO @ 11:02:12] Energy consumed for RAM : 0.026021 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  91%|█████████ | 3825/4203 [42:30<04:34,  1.38it/s][codecarbon INFO @ 11:02:13] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.854335520000001 W\n",
            "[codecarbon INFO @ 11:02:13] Energy consumed for All CPU : 0.008807 kWh\n",
            "[codecarbon INFO @ 11:02:13] Energy consumed for all GPUs : 0.162111 kWh. Total GPU Power : 228.97511911298176 W\n",
            "[codecarbon INFO @ 11:02:13] 0.196938 kWh of electricity used since the beginning.\n",
            "Inferindo:  92%|█████████▏| 3848/4203 [42:44<03:17,  1.80it/s][codecarbon INFO @ 11:02:27] Energy consumed for RAM : 0.026174 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  92%|█████████▏| 3849/4203 [42:45<03:28,  1.69it/s][codecarbon INFO @ 11:02:28] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.844403228000001 W\n",
            "[codecarbon INFO @ 11:02:28] Energy consumed for All CPU : 0.008858 kWh\n",
            "[codecarbon INFO @ 11:02:28] Energy consumed for all GPUs : 0.163064 kWh. Total GPU Power : 228.86078694167776 W\n",
            "[codecarbon INFO @ 11:02:28] 0.198096 kWh of electricity used since the beginning.\n",
            "Inferindo:  92%|█████████▏| 3870/4203 [42:59<03:27,  1.61it/s][codecarbon INFO @ 11:02:42] Energy consumed for RAM : 0.026327 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  92%|█████████▏| 3871/4203 [43:00<03:23,  1.63it/s][codecarbon INFO @ 11:02:43] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.845631094399998 W\n",
            "[codecarbon INFO @ 11:02:43] Energy consumed for All CPU : 0.008910 kWh\n",
            "[codecarbon INFO @ 11:02:43] Energy consumed for all GPUs : 0.164018 kWh. Total GPU Power : 228.84675570565489 W\n",
            "[codecarbon INFO @ 11:02:43] 0.199254 kWh of electricity used since the beginning.\n",
            "Inferindo:  93%|█████████▎| 3893/4203 [43:14<03:03,  1.69it/s][codecarbon INFO @ 11:02:57] Energy consumed for RAM : 0.026480 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 11:02:58] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.856312928000003 W\n",
            "[codecarbon INFO @ 11:02:58] Energy consumed for All CPU : 0.008962 kWh\n",
            "[codecarbon INFO @ 11:02:58] Energy consumed for all GPUs : 0.164970 kWh. Total GPU Power : 228.60986592065467 W\n",
            "[codecarbon INFO @ 11:02:58] 0.200412 kWh of electricity used since the beginning.\n",
            "Inferindo:  93%|█████████▎| 3916/4203 [43:29<03:00,  1.59it/s][codecarbon INFO @ 11:03:12] Energy consumed for RAM : 0.026633 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  93%|█████████▎| 3917/4203 [43:30<02:56,  1.62it/s][codecarbon INFO @ 11:03:13] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.8543604392 W\n",
            "[codecarbon INFO @ 11:03:13] Energy consumed for All CPU : 0.009014 kWh\n",
            "[codecarbon INFO @ 11:03:13] Energy consumed for all GPUs : 0.165923 kWh. Total GPU Power : 228.61948293999674 W\n",
            "[codecarbon INFO @ 11:03:13] 0.201569 kWh of electricity used since the beginning.\n",
            "Inferindo:  94%|█████████▎| 3939/4203 [43:44<02:42,  1.63it/s][codecarbon INFO @ 11:03:27] Energy consumed for RAM : 0.026786 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  94%|█████████▎| 3940/4203 [43:45<02:42,  1.61it/s][codecarbon INFO @ 11:03:28] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.854987444000002 W\n",
            "[codecarbon INFO @ 11:03:28] Energy consumed for All CPU : 0.009065 kWh\n",
            "[codecarbon INFO @ 11:03:28] Energy consumed for all GPUs : 0.166876 kWh. Total GPU Power : 228.87530687814916 W\n",
            "[codecarbon INFO @ 11:03:28] 0.202727 kWh of electricity used since the beginning.\n",
            "Inferindo:  94%|█████████▍| 3962/4203 [43:59<02:29,  1.61it/s][codecarbon INFO @ 11:03:42] Energy consumed for RAM : 0.026939 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  94%|█████████▍| 3963/4203 [44:00<02:35,  1.54it/s][codecarbon INFO @ 11:03:43] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.858682059200005 W\n",
            "[codecarbon INFO @ 11:03:43] Energy consumed for All CPU : 0.009117 kWh\n",
            "[codecarbon INFO @ 11:03:43] Energy consumed for all GPUs : 0.167828 kWh. Total GPU Power : 228.62438789137676 W\n",
            "[codecarbon INFO @ 11:03:43] 0.203884 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 11:03:43] 0.007591 g.CO2eq/s mean an estimation of 239.39141031152076 kg.CO2eq/year\n",
            "Inferindo:  95%|█████████▍| 3986/4203 [44:15<02:24,  1.50it/s][codecarbon INFO @ 11:03:57] Energy consumed for RAM : 0.027092 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 11:03:58] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.8487304928 W\n",
            "[codecarbon INFO @ 11:03:58] Energy consumed for All CPU : 0.009169 kWh\n",
            "[codecarbon INFO @ 11:03:58] Energy consumed for all GPUs : 0.168782 kWh. Total GPU Power : 228.8553151419408 W\n",
            "[codecarbon INFO @ 11:03:58] 0.205042 kWh of electricity used since the beginning.\n",
            "Inferindo:  95%|█████████▌| 4008/4203 [44:29<01:59,  1.63it/s][codecarbon INFO @ 11:04:12] Energy consumed for RAM : 0.027245 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  95%|█████████▌| 4009/4203 [44:30<01:58,  1.63it/s][codecarbon INFO @ 11:04:13] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.846726625280002 W\n",
            "[codecarbon INFO @ 11:04:13] Energy consumed for All CPU : 0.009221 kWh\n",
            "[codecarbon INFO @ 11:04:13] Energy consumed for all GPUs : 0.169734 kWh. Total GPU Power : 228.65858726802998 W\n",
            "[codecarbon INFO @ 11:04:13] 0.206200 kWh of electricity used since the beginning.\n",
            "Inferindo:  96%|█████████▌| 4032/4203 [44:44<01:40,  1.70it/s][codecarbon INFO @ 11:04:27] Energy consumed for RAM : 0.027398 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 11:04:28] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.840477795200002 W\n",
            "[codecarbon INFO @ 11:04:28] Energy consumed for All CPU : 0.009272 kWh\n",
            "[codecarbon INFO @ 11:04:28] Energy consumed for all GPUs : 0.170687 kWh. Total GPU Power : 228.71639294594826 W\n",
            "[codecarbon INFO @ 11:04:28] 0.207357 kWh of electricity used since the beginning.\n",
            "Inferindo:  97%|█████████▋| 4057/4203 [44:59<01:29,  1.64it/s][codecarbon INFO @ 11:04:42] Energy consumed for RAM : 0.027551 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 11:04:43] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.844121492000001 W\n",
            "[codecarbon INFO @ 11:04:43] Energy consumed for All CPU : 0.009324 kWh\n",
            "[codecarbon INFO @ 11:04:43] Energy consumed for all GPUs : 0.171646 kWh. Total GPU Power : 230.27343287737907 W\n",
            "[codecarbon INFO @ 11:04:43] 0.208521 kWh of electricity used since the beginning.\n",
            "Inferindo:  97%|█████████▋| 4080/4203 [45:14<01:12,  1.70it/s][codecarbon INFO @ 11:04:57] Energy consumed for RAM : 0.027704 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  97%|█████████▋| 4081/4203 [45:15<01:14,  1.65it/s][codecarbon INFO @ 11:04:58] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.845932500800004 W\n",
            "[codecarbon INFO @ 11:04:58] Energy consumed for All CPU : 0.009376 kWh\n",
            "[codecarbon INFO @ 11:04:58] Energy consumed for all GPUs : 0.172600 kWh. Total GPU Power : 228.9375486755663 W\n",
            "[codecarbon INFO @ 11:04:58] 0.209679 kWh of electricity used since the beginning.\n",
            "Inferindo:  98%|█████████▊| 4104/4203 [45:29<01:03,  1.55it/s][codecarbon INFO @ 11:05:12] Energy consumed for RAM : 0.027857 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  98%|█████████▊| 4105/4203 [45:30<01:01,  1.60it/s][codecarbon INFO @ 11:05:13] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.857111292800003 W\n",
            "[codecarbon INFO @ 11:05:13] Energy consumed for All CPU : 0.009427 kWh\n",
            "[codecarbon INFO @ 11:05:13] Energy consumed for all GPUs : 0.173552 kWh. Total GPU Power : 228.67219182389647 W\n",
            "[codecarbon INFO @ 11:05:13] 0.210837 kWh of electricity used since the beginning.\n",
            "Inferindo:  98%|█████████▊| 4127/4203 [45:44<00:51,  1.48it/s][codecarbon INFO @ 11:05:27] Energy consumed for RAM : 0.028010 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  98%|█████████▊| 4128/4203 [45:45<00:52,  1.43it/s][codecarbon INFO @ 11:05:28] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.857634473600001 W\n",
            "[codecarbon INFO @ 11:05:28] Energy consumed for All CPU : 0.009479 kWh\n",
            "[codecarbon INFO @ 11:05:28] Energy consumed for all GPUs : 0.174506 kWh. Total GPU Power : 228.85749064154007 W\n",
            "[codecarbon INFO @ 11:05:28] 0.211995 kWh of electricity used since the beginning.\n",
            "Inferindo:  99%|█████████▊| 4150/4203 [45:59<00:29,  1.79it/s][codecarbon INFO @ 11:05:42] Energy consumed for RAM : 0.028163 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  99%|█████████▉| 4151/4203 [46:00<00:30,  1.71it/s][codecarbon INFO @ 11:05:43] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.858045672800001 W\n",
            "[codecarbon INFO @ 11:05:43] Energy consumed for All CPU : 0.009531 kWh\n",
            "[codecarbon INFO @ 11:05:43] Energy consumed for all GPUs : 0.175459 kWh. Total GPU Power : 228.87240727741295 W\n",
            "[codecarbon INFO @ 11:05:43] 0.213153 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 11:05:43] 0.007596 g.CO2eq/s mean an estimation of 239.55895212116414 kg.CO2eq/year\n",
            "Inferindo:  99%|█████████▉| 4174/4203 [46:14<00:17,  1.62it/s][codecarbon INFO @ 11:05:57] Energy consumed for RAM : 0.028316 kWh. RAM Power : 38.0 W\n",
            "Inferindo:  99%|█████████▉| 4175/4203 [46:15<00:16,  1.67it/s][codecarbon INFO @ 11:05:58] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.874741148 W\n",
            "[codecarbon INFO @ 11:05:58] Energy consumed for All CPU : 0.009583 kWh\n",
            "[codecarbon INFO @ 11:05:58] Energy consumed for all GPUs : 0.176412 kWh. Total GPU Power : 228.7486860165 W\n",
            "[codecarbon INFO @ 11:05:58] 0.214311 kWh of electricity used since the beginning.\n",
            "Inferindo: 100%|█████████▉| 4195/4203 [46:29<00:06,  1.30it/s][codecarbon INFO @ 11:06:12] Energy consumed for RAM : 0.028469 kWh. RAM Power : 38.0 W\n",
            "Inferindo: 100%|█████████▉| 4196/4203 [46:30<00:05,  1.27it/s][codecarbon INFO @ 11:06:13] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.859131872000003 W\n",
            "[codecarbon INFO @ 11:06:13] Energy consumed for All CPU : 0.009635 kWh\n",
            "[codecarbon INFO @ 11:06:13] Energy consumed for all GPUs : 0.177366 kWh. Total GPU Power : 228.81635689259357 W\n",
            "[codecarbon INFO @ 11:06:13] 0.215469 kWh of electricity used since the beginning.\n",
            "Inferindo: 100%|██████████| 4203/4203 [46:35<00:00,  1.50it/s]\n",
            "[codecarbon INFO @ 11:06:17] Energy consumed for RAM : 0.028516 kWh. RAM Power : 38.0 W\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Tempo total de execução: 2795.04 segundos\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[codecarbon INFO @ 11:06:18] Delta energy consumed for CPU with cpu_load : 0.000016 kWh, power : 12.8688250688 W\n",
            "[codecarbon INFO @ 11:06:18] Energy consumed for All CPU : 0.009651 kWh\n",
            "[codecarbon INFO @ 11:06:18] Energy consumed for all GPUs : 0.177664 kWh. Total GPU Power : 216.4959582380612 W\n",
            "[codecarbon INFO @ 11:06:18] 0.215830 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Total de emissões (detalhes em emissions.csv):  0.02122645239535029\n",
            "Acurácia: 0.6176540566262194\n",
            "F1-macro: 0.5982838430439305\n",
            "F1-weighted: 0.621307467904316\n",
            "\n",
            "Relatório de classificação:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       BAIXA       0.73      0.72      0.73      2056\n",
            "       MÉDIA       0.43      0.50      0.47      1284\n",
            "        ALTA       0.69      0.53      0.60       863\n",
            "\n",
            "    accuracy                           0.62      4203\n",
            "   macro avg       0.62      0.59      0.60      4203\n",
            "weighted avg       0.63      0.62      0.62      4203\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "from tqdm import tqdm\n",
        "from codecarbon import EmissionsTracker # para calcular emissões de CO2\n",
        "\n",
        "tracker = EmissionsTracker( output_file='balanced_fine_tuning_emissions.csv' )\n",
        "tracker.start()\n",
        "\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "# .select(range(30))\n",
        "\n",
        "for example in tqdm(split_test, desc=\"Inferindo\"):  # percorre todo o dataset de teste\n",
        "    # ---------------------\n",
        "    # Prepara prompt\n",
        "    processed_key_words = '\\n- '.join(example[\"descricao_keyword\"].split(';'))\n",
        "    example_prompt = PROMPT_TMPL.format(\n",
        "        title=example[\"nome_producao\"],\n",
        "        abstract=example[\"descricao_abstract\"],\n",
        "        keywords=processed_key_words,\n",
        "        category=example[\"tema\"]\n",
        "    )\n",
        "\n",
        "    # Predição\n",
        "    pred = predict_class(example_prompt)\n",
        "    y_pred.append([\"0\",\"1\",\"2\"].index(pred[0]))\n",
        "\n",
        "    # Rótulo real\n",
        "    gold = str(example[\"modelo_nivel\"]).strip().upper()\n",
        "    if gold == \"MEDIA\":\n",
        "        gold = \"MÉDIA\"\n",
        "    assert gold in LABELS\n",
        "    y_true.append(LABELS.index(gold))\n",
        "\n",
        "# Marca o tempo final\n",
        "end_time = time.time()\n",
        "\n",
        "# Tempo total em segundos\n",
        "elapsed_time = end_time - start_time\n",
        "print(f\"\\nTempo total de execução: {elapsed_time:.2f} segundos\")\n",
        "\n",
        "\n",
        "emissions: float = tracker.stop()\n",
        "print(\"\\n\\nTotal de emissões (detalhes em emissions.csv): \",emissions)\n",
        "\n",
        "# ---------------------\n",
        "# Métricas\n",
        "acc = accuracy_score(y_true, y_pred)\n",
        "f1_macro = f1_score(y_true, y_pred, average=\"macro\")\n",
        "f1_weighted = f1_score(y_true, y_pred, average=\"weighted\")\n",
        "\n",
        "print(\"Acurácia:\", acc)\n",
        "print(\"F1-macro:\", f1_macro)\n",
        "print(\"F1-weighted:\", f1_weighted)\n",
        "\n",
        "# Relatório detalhado (por classe)\n",
        "print(\"\\nRelatório de classificação:\")\n",
        "print(classification_report(y_true, y_pred, target_names=LABELS))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "79395d0a",
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(\"balanced_loss_llm_predictions.pickle\", \"wb\") as file:\n",
        "    pickle.dump((y_true,y_pred), file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "35124305",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 600x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "\n",
        "# Rótulos originais e nomes legíveis\n",
        "labels = [0, 1, 2]\n",
        "names = [\"Low\", \"Medium\", \"High\"]\n",
        "\n",
        "# Gera a matriz de confusão\n",
        "cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
        "\n",
        "# Normaliza cada linha para obter porcentagem\n",
        "cm_percent = cm.astype('float') / cm.sum(axis=1)[:, None] * 100\n",
        "\n",
        "# Converte para DataFrame para salvar em arquivo\n",
        "cm_df = pd.DataFrame(cm, index=[f\"True_{n}\" for n in names],\n",
        "                        columns=[f\"Pred_{n}\" for n in names])\n",
        "\n",
        "# Salva em CSV\n",
        "cm_df.to_csv(\"balanced_loss_llm_confusion_matrix.csv\", index=True)\n",
        "\n",
        "# ---------- Gráfico ----------\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm_percent, annot=True, fmt=\".1f\", cmap=\"Blues\",\n",
        "            xticklabels=names, yticklabels=names)\n",
        "\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.tight_layout()\n",
        "\n",
        "# Salva como imagem\n",
        "plt.savefig(\"balanced_loss_llm_confusion_matrix.png\")\n",
        "\n",
        "# Mostra na tela\n",
        "plt.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ddc5c679",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "challenge_bonito",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "007f9b1462b1473fbe645d9a1c94bd2d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "01dc79b2d3c34ddbbb084b18ef67b111": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "033b17e2bc4442389a3a1aef5619fc01": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93f96d6817df48d692d0a5c5b25a3fa4",
            "max": 3957900840,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a7fec9b99a054f308891d298de041ca0",
            "value": 3957900840
          }
        },
        "04ba89b9b9624801b5c8a2586c24ac90": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "04feba0e345242d9883e0b33203eaab8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1b89bf8b6daa437094bfb7f4873454a3",
              "IPY_MODEL_19390a9e95ac4b5d8cccab413c4e5dd4",
              "IPY_MODEL_3700b3f0aa094403bd2366da95dac0c3"
            ],
            "layout": "IPY_MODEL_1239cfe4f16e434685495c8a7f0c0e5c"
          }
        },
        "0516ec4344174223867fde3350443eb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de630557ac2e4f5098b5f7b19022efdf",
            "placeholder": "​",
            "style": "IPY_MODEL_97cf4ddc161d4b5d8f5548111a21beb3",
            "value": " 3.99G/3.99G [05:16&lt;00:00, 11.4MB/s]"
          }
        },
        "051e4b9ed34e43c3a3b795e0b63dd30c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "07945a5ba4384b7f94b47d9b7c903a68": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea0890a3f1df43d78cc8adf84ab38136",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_61624bcbb70e40d9833d911bdd03e28e",
            "value": 1
          }
        },
        "0a9b870b079043baa8c7b10d483ce8f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1294404f6bed412b83d8d49ecb9ae969",
            "placeholder": "​",
            "style": "IPY_MODEL_f4bf0bfa96534b7892b95bbe5a75a89e",
            "value": " 11.4M/11.4M [00:00&lt;00:00, 4.96MB/s]"
          }
        },
        "0b3c3b22ef664176a54d842b28eafbfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0e0299929f0b4814ad28ce34416b12ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "10de747dc423495498a41d3ea4a7769f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1239cfe4f16e434685495c8a7f0c0e5c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1294404f6bed412b83d8d49ecb9ae969": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "167c34f54d444d4ba5e6ca4c9723c7c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b6907d916be9433dba1f58b48d045980",
              "IPY_MODEL_45dd4555dd58442dac028284f8a33618",
              "IPY_MODEL_8e046ab0b188487e8739ffb888d548bc"
            ],
            "layout": "IPY_MODEL_d8cbb59e87374f02a9479b3bd4d1495e"
          }
        },
        "176a9f9fc14a481186c88766f1f5f2ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b82bf42d45964c1b9f6f5764911f47dd",
              "IPY_MODEL_f9a0e78836894835987784872a7ae8f7",
              "IPY_MODEL_0a9b870b079043baa8c7b10d483ce8f3"
            ],
            "layout": "IPY_MODEL_74aa864307134ff29a2279ef83749662"
          }
        },
        "188a4f8436e640ff856d9ed36eba4c49": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "19390a9e95ac4b5d8cccab413c4e5dd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6eb4260f54fc4a89b2a78978c12efb1e",
            "max": 99630640,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0b3c3b22ef664176a54d842b28eafbfc",
            "value": 99630640
          }
        },
        "1b89bf8b6daa437094bfb7f4873454a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c9a21cadb794bdfb13ad3e660fce2f1",
            "placeholder": "​",
            "style": "IPY_MODEL_b89812119d8f4ff4b9a783b5a90ae3ba",
            "value": "model-00003-of-00003.safetensors: 100%"
          }
        },
        "1f3ff3abcb5545e9827a640beee918ec": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "211ff35c877e4b56ad2398996a7bd2dd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21797ddf4a5d48a68c0ad7e86d8146d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee0dce3af4574ee1b9027f687ddbe5f7",
            "placeholder": "​",
            "style": "IPY_MODEL_f9c7f8a2647d48ee80e364aaca9ac031",
            "value": "model.safetensors.index.json: "
          }
        },
        "22ca97439fb1431b9daaa32789677cdd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "270ed96109554d0a90c256e900d1f924": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_729572d7d5544c4386d5ad63197c4614",
            "placeholder": "​",
            "style": "IPY_MODEL_ce81530776494b948bc2040b58f1b083",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "2756ec20c6d24499991f7aae42b5a7d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_72eaaa9cac08446f8e20c6f9f09a46b4",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f8748cbf0bfa43a48ac8fd29dbd8b9d9",
            "value": 3
          }
        },
        "29ec63675b4d431e8431ebfd261eb358": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_211ff35c877e4b56ad2398996a7bd2dd",
            "placeholder": "​",
            "style": "IPY_MODEL_44fc2783929e479bb2f5d2c584edaa1f",
            "value": " 3.96G/3.96G [05:22&lt;00:00, 25.9MB/s]"
          }
        },
        "2aa23ea235094bf48d1f4c911436bbc8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2cc6cdb7b19d41ea9991766e81c5ca83": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "30b49286f0d44b11a0a77e65ab539a50": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3700b3f0aa094403bd2366da95dac0c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_386fc12d51fa44369b1b947f0ee8a7c4",
            "placeholder": "​",
            "style": "IPY_MODEL_051e4b9ed34e43c3a3b795e0b63dd30c",
            "value": " 99.6M/99.6M [00:10&lt;00:00, 7.81MB/s]"
          }
        },
        "37371984cc79422eb1eeca3c0af9b35f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "386fc12d51fa44369b1b947f0ee8a7c4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c439de359724f489222b6980797cf89": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3e1ed8aad69b45239b21bae373dc2fd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b0b63af12d44799b640fb1a40bfff9b",
            "placeholder": "​",
            "style": "IPY_MODEL_a243d5e70c51432d8ba21ec930a005ab",
            "value": " 2.78M/? [00:00&lt;00:00, 17.3MB/s]"
          }
        },
        "44fc2783929e479bb2f5d2c584edaa1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "456b931744634e87b3a0dc04d3542f6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c74cc6566984a8b90753e687063fb90",
            "placeholder": "​",
            "style": "IPY_MODEL_a5616c54f8a64836b7cbd7becee68bb5",
            "value": "model-00001-of-00003.safetensors: 100%"
          }
        },
        "45b95727622446edac1efddcf104e3dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_21797ddf4a5d48a68c0ad7e86d8146d5",
              "IPY_MODEL_b63770007f1a461d9806b75e49c3e30e",
              "IPY_MODEL_89ea70f913204402b91bb508e13a5973"
            ],
            "layout": "IPY_MODEL_7f7ea8af54854ef3b6cf653fa5ceb608"
          }
        },
        "45dd4555dd58442dac028284f8a33618": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_47060b5d8d4342feaddc686bea37e0bb",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_59fc937981f54905917ef2aee632a09a",
            "value": 1
          }
        },
        "46e3639d80674dee9c3b6898b680d060": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47060b5d8d4342feaddc686bea37e0bb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "4c9a21cadb794bdfb13ad3e660fce2f1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50a3a69cb468491e9b9d77e003ae2ee7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "517053eb19b54fec84b1cc87ec029824": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3c7c816e2334d6da48e7c1c8dc05245",
            "placeholder": "​",
            "style": "IPY_MODEL_bfb8e2ebc54749bfa05a2e63473da6d9",
            "value": "model-00002-of-00003.safetensors: 100%"
          }
        },
        "5462995a9ae74d2fbbb43245833ead88": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56a2407fbbc548fc976777c4f0ac1cab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "59fc937981f54905917ef2aee632a09a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5a8df03b257a48c499aab92ded08e6ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46e3639d80674dee9c3b6898b680d060",
            "max": 3987450520,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e50a0fb3151c48b49ccdb2dfdbdbf79f",
            "value": 3987450520
          }
        },
        "5cb3b31802d54dafb7b2579992e230fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_007f9b1462b1473fbe645d9a1c94bd2d",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_30b49286f0d44b11a0a77e65ab539a50",
            "value": 1
          }
        },
        "5e8153af9c124fbaafd1c4cbe581d05a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5ecc6c7f9c90450580db05aef0c651b5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f95edd924a94bba8a429d6756d8318d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_517053eb19b54fec84b1cc87ec029824",
              "IPY_MODEL_5a8df03b257a48c499aab92ded08e6ec",
              "IPY_MODEL_0516ec4344174223867fde3350443eb5"
            ],
            "layout": "IPY_MODEL_a157e07b055847d78e992438bdb30fcf"
          }
        },
        "5fb30df11ddb43469b4d5dfa43e77423": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "603e854dff2349f586395b2f15b44249": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "60b72e9cea00455793a988eb64eea951": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5462995a9ae74d2fbbb43245833ead88",
            "max": 726,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7869058e529b40309a9b836c2b92e594",
            "value": 726
          }
        },
        "60e86a8ba9b34b9381c4ddd0a4768f7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37371984cc79422eb1eeca3c0af9b35f",
            "placeholder": "​",
            "style": "IPY_MODEL_b54a9b521fd947c8a5fe1ed23d6ff1a4",
            "value": " 3/3 [05:22&lt;00:00, 322.89s/it]"
          }
        },
        "61624bcbb70e40d9833d911bdd03e28e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6707fbae22a344cb87b864b70339dfaf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b0b63af12d44799b640fb1a40bfff9b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c74cc6566984a8b90753e687063fb90": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6cb350e14708487b9f4bd8e2f1b6bd96": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6eb4260f54fc4a89b2a78978c12efb1e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fb537dc678b47fb86ec6afa277c3140": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "729572d7d5544c4386d5ad63197c4614": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72b387b63a4b4df9b7d9e84ec9538da5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72eaaa9cac08446f8e20c6f9f09a46b4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72f8dafa824b42cb9149d2376fee1f5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a158b6c753994b289865bb25343e88ce",
            "max": 239,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9fef704c9a584aed9a52cda274281913",
            "value": 239
          }
        },
        "74aa864307134ff29a2279ef83749662": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7869058e529b40309a9b836c2b92e594": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7ccd4242cb424e9f881e1b5bdffa210a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7d7da81238ed489596b39c9ff1f587c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_270ed96109554d0a90c256e900d1f924",
              "IPY_MODEL_2756ec20c6d24499991f7aae42b5a7d6",
              "IPY_MODEL_a75634b3ffaa42a6811b69b668dd394b"
            ],
            "layout": "IPY_MODEL_5fb30df11ddb43469b4d5dfa43e77423"
          }
        },
        "7f7ea8af54854ef3b6cf653fa5ceb608": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "821eb341730a4f6aafb7aac55105223e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22ca97439fb1431b9daaa32789677cdd",
            "placeholder": "​",
            "style": "IPY_MODEL_188a4f8436e640ff856d9ed36eba4c49",
            "value": "Fetching 3 files: 100%"
          }
        },
        "835fe3175ceb447cb4900774aa605660": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_821eb341730a4f6aafb7aac55105223e",
              "IPY_MODEL_eb29ecaa5c61431c9ef7298f103e9279",
              "IPY_MODEL_60e86a8ba9b34b9381c4ddd0a4768f7e"
            ],
            "layout": "IPY_MODEL_bc77292cef4b47178f5bcf97cc23cad5"
          }
        },
        "83cdd81580d6404b81b26e8fa3a48909": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d53b8ccb9d5446b4be4c73dd3486a7ff",
              "IPY_MODEL_07945a5ba4384b7f94b47d9b7c903a68",
              "IPY_MODEL_96adb6e7525743b998e25ee96ca0d0d9"
            ],
            "layout": "IPY_MODEL_f0ae4face26e4d33aa8bb05a7de109cd"
          }
        },
        "85605463ef87454c91fdbea36427cd80": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89ea70f913204402b91bb508e13a5973": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_72b387b63a4b4df9b7d9e84ec9538da5",
            "placeholder": "​",
            "style": "IPY_MODEL_6fb537dc678b47fb86ec6afa277c3140",
            "value": " 32.8k/? [00:00&lt;00:00, 915kB/s]"
          }
        },
        "8e046ab0b188487e8739ffb888d548bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6707fbae22a344cb87b864b70339dfaf",
            "placeholder": "​",
            "style": "IPY_MODEL_7ccd4242cb424e9f881e1b5bdffa210a",
            "value": " 1.67M/? [00:00&lt;00:00, 29.8MB/s]"
          }
        },
        "913d194daf034c3aa044c41c83d44641": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "91de8eb74d464733938dbf8cd64a3630": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93f96d6817df48d692d0a5c5b25a3fa4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94046340f41f47c194b8aff435df3354": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9629dd5dc30646d6b33e3336bc82af82": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cac6e561ad5449eb9c2dc1aef3cfb276",
            "placeholder": "​",
            "style": "IPY_MODEL_913d194daf034c3aa044c41c83d44641",
            "value": "vocab.json: "
          }
        },
        "96adb6e7525743b998e25ee96ca0d0d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_10de747dc423495498a41d3ea4a7769f",
            "placeholder": "​",
            "style": "IPY_MODEL_fb784053b12847f7b72dd60c873ef4c6",
            "value": " 9.73k/? [00:00&lt;00:00, 224kB/s]"
          }
        },
        "97cf4ddc161d4b5d8f5548111a21beb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9fef704c9a584aed9a52cda274281913": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a157e07b055847d78e992438bdb30fcf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a158b6c753994b289865bb25343e88ce": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a243d5e70c51432d8ba21ec930a005ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a38c6300f00f4ac985c7545d5edc66a6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5616c54f8a64836b7cbd7becee68bb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a6fb1ef8fc794120b07365178c332516": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a75634b3ffaa42a6811b69b668dd394b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a91d82cda1db41bf91c03b76c462af50",
            "placeholder": "​",
            "style": "IPY_MODEL_56a2407fbbc548fc976777c4f0ac1cab",
            "value": " 3/3 [00:32&lt;00:00,  8.97s/it]"
          }
        },
        "a7fec9b99a054f308891d298de041ca0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a91d82cda1db41bf91c03b76c462af50": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b02830a704b2463586108e30659dfb52": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4fbcb7585704170a2435cdfc14d1f31": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d305135c77ff41deae5c408aac44ef25",
            "placeholder": "​",
            "style": "IPY_MODEL_0e0299929f0b4814ad28ce34416b12ef",
            "value": "generation_config.json: 100%"
          }
        },
        "b54a9b521fd947c8a5fe1ed23d6ff1a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b63770007f1a461d9806b75e49c3e30e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_603e854dff2349f586395b2f15b44249",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_04ba89b9b9624801b5c8a2586c24ac90",
            "value": 1
          }
        },
        "b6907d916be9433dba1f58b48d045980": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6fb1ef8fc794120b07365178c332516",
            "placeholder": "​",
            "style": "IPY_MODEL_f7581ad6c71a41298e9d8a060186ab5a",
            "value": "merges.txt: "
          }
        },
        "b82bf42d45964c1b9f6f5764911f47dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2aa23ea235094bf48d1f4c911436bbc8",
            "placeholder": "​",
            "style": "IPY_MODEL_5e8153af9c124fbaafd1c4cbe581d05a",
            "value": "tokenizer.json: 100%"
          }
        },
        "b89812119d8f4ff4b9a783b5a90ae3ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ba9dc18a4a354bb0a26c1b756a482b03": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bc77292cef4b47178f5bcf97cc23cad5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfb8e2ebc54749bfa05a2e63473da6d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c003c4188035454986689b3a1f802a74": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_456b931744634e87b3a0dc04d3542f6c",
              "IPY_MODEL_033b17e2bc4442389a3a1aef5619fc01",
              "IPY_MODEL_29ec63675b4d431e8431ebfd261eb358"
            ],
            "layout": "IPY_MODEL_a38c6300f00f4ac985c7545d5edc66a6"
          }
        },
        "c0ca8b288d924d95a79446228c1549fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b4fbcb7585704170a2435cdfc14d1f31",
              "IPY_MODEL_72f8dafa824b42cb9149d2376fee1f5b",
              "IPY_MODEL_d248ea933814404c9adb35aae076a86b"
            ],
            "layout": "IPY_MODEL_6cb350e14708487b9f4bd8e2f1b6bd96"
          }
        },
        "c3c7c816e2334d6da48e7c1c8dc05245": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cac6e561ad5449eb9c2dc1aef3cfb276": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce81530776494b948bc2040b58f1b083": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d248ea933814404c9adb35aae076a86b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50a3a69cb468491e9b9d77e003ae2ee7",
            "placeholder": "​",
            "style": "IPY_MODEL_2cc6cdb7b19d41ea9991766e81c5ca83",
            "value": " 239/239 [00:00&lt;00:00, 21.8kB/s]"
          }
        },
        "d2901dd9564e4dad87e4a1503bffb128": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e9f140621c9d42d09d468bb890319a73",
              "IPY_MODEL_60b72e9cea00455793a988eb64eea951",
              "IPY_MODEL_e00be6aafbee493eabd903669c13ae97"
            ],
            "layout": "IPY_MODEL_b02830a704b2463586108e30659dfb52"
          }
        },
        "d305135c77ff41deae5c408aac44ef25": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d53b8ccb9d5446b4be4c73dd3486a7ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85605463ef87454c91fdbea36427cd80",
            "placeholder": "​",
            "style": "IPY_MODEL_f0a163078a2c4f889b47322b0c7da18a",
            "value": "tokenizer_config.json: "
          }
        },
        "d5fb27352bc14d22be28f0abca99cb9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9629dd5dc30646d6b33e3336bc82af82",
              "IPY_MODEL_5cb3b31802d54dafb7b2579992e230fc",
              "IPY_MODEL_3e1ed8aad69b45239b21bae373dc2fd2"
            ],
            "layout": "IPY_MODEL_ddb1c96d7b8d4ba8892086c9dbf88e76"
          }
        },
        "d8cbb59e87374f02a9479b3bd4d1495e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ddb1c96d7b8d4ba8892086c9dbf88e76": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de630557ac2e4f5098b5f7b19022efdf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e00be6aafbee493eabd903669c13ae97": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ecc6c7f9c90450580db05aef0c651b5",
            "placeholder": "​",
            "style": "IPY_MODEL_3c439de359724f489222b6980797cf89",
            "value": " 726/726 [00:00&lt;00:00, 33.2kB/s]"
          }
        },
        "e50a0fb3151c48b49ccdb2dfdbdbf79f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e9f140621c9d42d09d468bb890319a73": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f3ff3abcb5545e9827a640beee918ec",
            "placeholder": "​",
            "style": "IPY_MODEL_ba9dc18a4a354bb0a26c1b756a482b03",
            "value": "config.json: 100%"
          }
        },
        "ea0890a3f1df43d78cc8adf84ab38136": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "eb29ecaa5c61431c9ef7298f103e9279": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91de8eb74d464733938dbf8cd64a3630",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_94046340f41f47c194b8aff435df3354",
            "value": 3
          }
        },
        "ee0dce3af4574ee1b9027f687ddbe5f7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0a163078a2c4f889b47322b0c7da18a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f0ae4face26e4d33aa8bb05a7de109cd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4bf0bfa96534b7892b95bbe5a75a89e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f7581ad6c71a41298e9d8a060186ab5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f8748cbf0bfa43a48ac8fd29dbd8b9d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f87c46e30ab54745a040bec84145c6cc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9a0e78836894835987784872a7ae8f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f87c46e30ab54745a040bec84145c6cc",
            "max": 11422654,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_01dc79b2d3c34ddbbb084b18ef67b111",
            "value": 11422654
          }
        },
        "f9c7f8a2647d48ee80e364aaca9ac031": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fb784053b12847f7b72dd60c873ef4c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
